{
    "dataset_revision": "None",
    "task_name": "QuoraRetrieval",
    "evaluation_time": NaN,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "map_at_1": 24.016000000000002,
                "map_at_10": 28.977999999999998,
                "map_at_100": 29.579,
                "map_at_1000": 29.648999999999997,
                "map_at_3": 27.673,
                "map_at_5": 28.427000000000003,
                "mrr_at_1": 27.93,
                "mrr_at_10": 32.462999999999994,
                "mrr_at_100": 32.993,
                "mrr_at_1000": 33.044000000000004,
                "mrr_at_3": 31.252000000000002,
                "mrr_at_5": 31.968999999999998,
                "ndcg_at_1": 27.96,
                "ndcg_at_10": 31.954,
                "ndcg_at_100": 34.882000000000005,
                "ndcg_at_1000": 36.751,
                "ndcg_at_3": 29.767,
                "ndcg_at_5": 30.816,
                "precision_at_1": 27.96,
                "precision_at_10": 4.826,
                "precision_at_100": 0.697,
                "precision_at_1000": 0.093,
                "precision_at_3": 12.837000000000002,
                "precision_at_5": 8.559999999999999,
                "recall_at_1": 24.016000000000002,
                "recall_at_10": 37.574999999999996,
                "recall_at_100": 50.843,
                "recall_at_1000": 64.654,
                "recall_at_3": 31.182,
                "recall_at_5": 34.055,
                "main_score": 31.954
            }
        ]
    }
}