{
    "dataset_revision": "None",
    "task_name": "CQADupstackMathematicaRetrieval",
    "evaluation_time": NaN,
    "mteb_version": "unknown",
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "map_at_1": 9.762,
                "map_at_10": 15.495000000000001,
                "map_at_100": 16.637,
                "map_at_1000": 16.786,
                "map_at_3": 13.62,
                "map_at_5": 14.655999999999999,
                "mrr_at_1": 12.934999999999999,
                "mrr_at_10": 18.985,
                "mrr_at_100": 20.079,
                "mrr_at_1000": 20.177999999999997,
                "mrr_at_3": 16.977999999999998,
                "mrr_at_5": 18.197,
                "ndcg_at_1": 12.934999999999999,
                "ndcg_at_10": 19.444,
                "ndcg_at_100": 25.108999999999998,
                "ndcg_at_1000": 28.804999999999996,
                "ndcg_at_3": 15.93,
                "ndcg_at_5": 17.57,
                "precision_at_1": 12.934999999999999,
                "precision_at_10": 3.856,
                "precision_at_100": 0.765,
                "precision_at_1000": 0.124,
                "precision_at_3": 8.043,
                "precision_at_5": 6.095,
                "recall_at_1": 9.762,
                "recall_at_10": 28.216,
                "recall_at_100": 53.28000000000001,
                "recall_at_1000": 79.64099999999999,
                "recall_at_3": 18.335,
                "recall_at_5": 22.435,
                "main_score": 19.444
            }
        ]
    }
}