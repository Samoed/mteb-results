{
    "dataset_revision": "3c62f26bafdc4c4e1c16401ad4b32f0a94b46612",
    "task_name": "SweRecClassification",
    "evaluation_time": -1,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 68.4716796875,
                "f1": 59.865730786092364,
                "main_score": 68.4716796875
            }
        ]
    }
}