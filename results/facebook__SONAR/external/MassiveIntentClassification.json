{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": -1,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 58.14727639542704,
                "f1": 55.58745169431752,
                "main_score": 58.14727639542704
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 57.91190316072628,
                "f1": 55.46589962622107,
                "main_score": 57.91190316072628
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 57.22932078009414,
                "f1": 53.661218041561334,
                "main_score": 57.22932078009414
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 57.16543375924681,
                "f1": 55.16504653263189,
                "main_score": 57.16543375924681
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 62.239408204438476,
                "f1": 58.941991707183874,
                "main_score": 62.239408204438476
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 51.186953597848,
                "f1": 49.59432722397084,
                "main_score": 51.186953597848
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 62.030934767989244,
                "f1": 58.836302050830966,
                "main_score": 62.030934767989244
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 61.314727639542696,
                "f1": 57.80700293522655,
                "main_score": 61.314727639542696
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 64.20645595158037,
                "f1": 61.36755812840151,
                "main_score": 64.20645595158037
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 64.36785474108943,
                "f1": 61.15645935863754,
                "main_score": 64.36785474108943
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 63.97108271687962,
                "f1": 62.07352472659557,
                "main_score": 63.97108271687962
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 66.67114996637525,
                "f1": 63.420170447126324,
                "main_score": 66.67114996637525
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 62.864828513786144,
                "f1": 59.655860488861926,
                "main_score": 62.864828513786144
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 58.55077336919974,
                "f1": 55.28215385204243,
                "main_score": 58.55077336919974
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 63.453261600538,
                "f1": 59.991998820039186,
                "main_score": 63.453261600538
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 61.32145258910558,
                "f1": 58.9676667104426,
                "main_score": 61.32145258910558
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 62.905178211163424,
                "f1": 59.645126480791674,
                "main_score": 62.905178211163424
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 60.03026227303295,
                "f1": 56.68905593909442,
                "main_score": 60.03026227303295
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 63.28850033624749,
                "f1": 60.21862015326403,
                "main_score": 63.28850033624749
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 56.0221923335575,
                "f1": 53.388473451598315,
                "main_score": 56.0221923335575
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 64.44182918628111,
                "f1": 62.14806714489123,
                "main_score": 64.44182918628111
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 63.69535978480162,
                "f1": 62.40231098840202,
                "main_score": 63.69535978480162
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 52.00067249495628,
                "f1": 48.871263427511984,
                "main_score": 52.00067249495628
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 54.088769334229994,
                "f1": 52.68998451556,
                "main_score": 54.088769334229994
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 43.34229993275051,
                "f1": 40.578510490463024,
                "main_score": 43.34229993275051
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 57.87491593813046,
                "f1": 55.19579071673386,
                "main_score": 57.87491593813046
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 62.69334229993275,
                "f1": 60.90210922623679,
                "main_score": 62.69334229993275
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 56.240753194351036,
                "f1": 54.137519761157485,
                "main_score": 56.240753194351036
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 62.81439139206457,
                "f1": 60.46554841337619,
                "main_score": 62.81439139206457
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 58.49361129791527,
                "f1": 55.12919894175168,
                "main_score": 58.49361129791527
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 61.55682582380633,
                "f1": 58.81763499302702,
                "main_score": 61.55682582380633
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 59.3981170141224,
                "f1": 56.31810441546048,
                "main_score": 59.3981170141224
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 59.89576328177538,
                "f1": 57.35130066022407,
                "main_score": 59.89576328177538
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 64.55951580363148,
                "f1": 61.50868742463585,
                "main_score": 64.55951580363148
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 65.86079354404842,
                "f1": 61.94702597578807,
                "main_score": 65.86079354404842
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 63.49024882313383,
                "f1": 60.796412851533454,
                "main_score": 63.49024882313383
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 62.53194351042366,
                "f1": 59.9167382336848,
                "main_score": 62.53194351042366
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 62.62945527908541,
                "f1": 59.195444230665096,
                "main_score": 62.62945527908541
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 63.43308675184935,
                "f1": 60.605749901316145,
                "main_score": 63.43308675184935
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 61.44586415601883,
                "f1": 58.635066561729396,
                "main_score": 61.44586415601883
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 62.86482851378615,
                "f1": 59.75440194153033,
                "main_score": 62.86482851378615
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 56.250840618695364,
                "f1": 54.84944007944625,
                "main_score": 56.250840618695364
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 59.747814391392076,
                "f1": 56.83761137925043,
                "main_score": 59.747814391392076
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 59.60995292535306,
                "f1": 57.106776457430705,
                "main_score": 59.60995292535306
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 59.421654337592464,
                "f1": 57.81013790437749,
                "main_score": 59.421654337592464
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 58.120376597175515,
                "f1": 55.27690756097837,
                "main_score": 58.120376597175515
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 60.907868190988566,
                "f1": 57.43015543162361,
                "main_score": 60.907868190988566
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 59.492266308002705,
                "f1": 56.885590563156455,
                "main_score": 59.492266308002705
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 60.477471418964356,
                "f1": 57.87047944039945,
                "main_score": 60.477471418964356
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 62.07800941492938,
                "f1": 59.340232908410265,
                "main_score": 62.07800941492938
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 56.73167451244117,
                "f1": 55.29236319279749,
                "main_score": 56.73167451244117
            }
        ]
    }
}