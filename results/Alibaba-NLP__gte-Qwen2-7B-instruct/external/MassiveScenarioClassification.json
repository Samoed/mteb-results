{
    "dataset_revision": "7d571f92784cd94a019292a1f45445077d0ef634",
    "task_name": "MassiveScenarioClassification",
    "evaluation_time": -1,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 89.77135171486215,
                "f1": 88.89843747468366,
                "main_score": 89.77135171486215
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 86.05917955615332,
                "f1": 85.05279279434997,
                "main_score": 86.05917955615332
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 86.64425016812373,
                "f1": 85.4912728670017,
                "main_score": 86.64425016812373
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 85.54472091459313,
                "f1": 84.29498563572106,
                "main_score": 85.54472091459313
            }
        ]
    }
}