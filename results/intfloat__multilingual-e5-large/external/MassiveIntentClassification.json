{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": 0,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 62.38063214525892,
                "f1": 59.46463723443009,
                "main_score": 62.38063214525892
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 56.06926698049766,
                "f1": 52.49084283283562,
                "main_score": 56.06926698049766
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 60.74983187626093,
                "f1": 56.960640620165904,
                "main_score": 60.74983187626093
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 64.86550100874243,
                "f1": 62.47370548140688,
                "main_score": 64.86550100874243
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 63.971082716879636,
                "f1": 61.03812421957381,
                "main_score": 63.971082716879636
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 54.98318762609282,
                "f1": 51.51207916008392,
                "main_score": 54.98318762609282
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 69.45527908540686,
                "f1": 66.16631905400318,
                "main_score": 69.45527908540686
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 69.32750504371216,
                "f1": 66.16755288646591,
                "main_score": 69.32750504371216
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 69.09213180901143,
                "f1": 66.95654394661507,
                "main_score": 69.09213180901143
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 73.75588433086752,
                "f1": 71.79973779656923,
                "main_score": 73.75588433086752
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 70.49428379287154,
                "f1": 68.37494379215734,
                "main_score": 70.49428379287154
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 69.90921318090115,
                "f1": 66.79517376481645,
                "main_score": 69.90921318090115
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 70.12104909213181,
                "f1": 67.29448842879584,
                "main_score": 70.12104909213181
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 69.34095494283793,
                "f1": 67.01134288992947,
                "main_score": 69.34095494283793
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 67.61264290517822,
                "f1": 64.68730512660757,
                "main_score": 67.61264290517822
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 67.79757901815738,
                "f1": 65.24938539425598,
                "main_score": 67.79757901815738
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 69.68728984532616,
                "f1": 67.0487169762553,
                "main_score": 69.68728984532616
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 62.07464694014795,
                "f1": 59.183532276789286,
                "main_score": 62.07464694014795
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 70.04707464694015,
                "f1": 67.66829629003848,
                "main_score": 70.04707464694015
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 62.42434431741762,
                "f1": 59.01617226544757,
                "main_score": 62.42434431741762
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 70.53127101546738,
                "f1": 68.10033760906255,
                "main_score": 70.53127101546738
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 72.50504371217215,
                "f1": 69.74931103158923,
                "main_score": 72.50504371217215
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 57.91190316072628,
                "f1": 54.05551136648796,
                "main_score": 57.91190316072628
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 51.78211163416275,
                "f1": 49.874888544058535,
                "main_score": 51.78211163416275
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 47.017484868863484,
                "f1": 44.53364263352014,
                "main_score": 47.017484868863484
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 62.16207128446537,
                "f1": 59.01185692320829,
                "main_score": 62.16207128446537
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 69.42501681237391,
                "f1": 67.13169450166086,
                "main_score": 69.42501681237391
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 67.0780094149294,
                "f1": 64.41720167850707,
                "main_score": 67.0780094149294
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 65.57162071284466,
                "f1": 62.414138683804424,
                "main_score": 65.57162071284466
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 61.71149966375252,
                "f1": 58.594805125087234,
                "main_score": 61.71149966375252
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 66.03900470746471,
                "f1": 63.87937257883887,
                "main_score": 66.03900470746471
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 60.8776059179556,
                "f1": 57.48587618059131,
                "main_score": 60.8776059179556
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 69.87895090786819,
                "f1": 66.8141299430347,
                "main_score": 69.87895090786819
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 70.45057162071285,
                "f1": 67.46444039673516,
                "main_score": 70.45057162071285
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 71.546738399462,
                "f1": 68.63640876702655,
                "main_score": 71.546738399462
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 70.72965702757229,
                "f1": 68.54119560379115,
                "main_score": 70.72965702757229
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 68.35574983187625,
                "f1": 65.88844917691927,
                "main_score": 68.35574983187625
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 71.70477471418964,
                "f1": 69.19665697061978,
                "main_score": 71.70477471418964
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 67.0880968392737,
                "f1": 64.76962317666086,
                "main_score": 67.0880968392737
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 65.18493611297916,
                "f1": 62.49984559035371,
                "main_score": 65.18493611297916
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 71.75857431069265,
                "f1": 69.20053687623418,
                "main_score": 71.75857431069265
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 58.500336247478145,
                "f1": 55.2972398687929,
                "main_score": 58.500336247478145
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 62.68997982515132,
                "f1": 59.36848202755348,
                "main_score": 62.68997982515132
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 63.01950235373235,
                "f1": 60.09351954625423,
                "main_score": 63.01950235373235
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 68.29186281102892,
                "f1": 67.57860496703447,
                "main_score": 68.29186281102892
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 64.77471418964357,
                "f1": 61.913983147713836,
                "main_score": 64.77471418964357
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 69.87222595830532,
                "f1": 66.03679033708141,
                "main_score": 69.87222595830532
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 64.04505716207127,
                "f1": 61.28569169817908,
                "main_score": 64.04505716207127
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 69.38466711499663,
                "f1": 67.20532357036844,
                "main_score": 69.38466711499663
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 71.12306657700067,
                "f1": 68.91251226588182,
                "main_score": 71.12306657700067
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 66.20040349697378,
                "f1": 66.02657347714175,
                "main_score": 66.20040349697378
            }
        ]
    }
}