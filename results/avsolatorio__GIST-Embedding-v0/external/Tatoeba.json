{
    "dataset_revision": "9080400076fbadbb4c4dcb136ff4eddc40b42553",
    "task_name": "Tatoeba",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "sqi-eng",
                "languages": [
                    "sqi-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8,
                "f1": 6.298401229470593,
                "precision": 5.916991709050532,
                "recall": 8,
                "main_score": 6.298401229470593
            },
            {
                "hf_subset": "fry-eng",
                "languages": [
                    "fry-Latn",
                    "eng-Latn"
                ],
                "accuracy": 17.341040462427745,
                "f1": 14.621650026274303,
                "precision": 13.9250609139035,
                "recall": 17.341040462427745,
                "main_score": 14.621650026274303
            },
            {
                "hf_subset": "kur-eng",
                "languages": [
                    "kur-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.536585365853659,
                "f1": 6.30972482801751,
                "precision": 5.796517326875398,
                "recall": 8.536585365853659,
                "main_score": 6.30972482801751
            },
            {
                "hf_subset": "tur-eng",
                "languages": [
                    "tur-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.4,
                "f1": 4.221126743626743,
                "precision": 3.822815143403898,
                "recall": 6.4,
                "main_score": 4.221126743626743
            },
            {
                "hf_subset": "deu-eng",
                "languages": [
                    "deu-Latn",
                    "eng-Latn"
                ],
                "accuracy": 19.8,
                "f1": 18.13768093781855,
                "precision": 17.54646004378763,
                "recall": 19.8,
                "main_score": 18.13768093781855
            },
            {
                "hf_subset": "nld-eng",
                "languages": [
                    "nld-Latn",
                    "eng-Latn"
                ],
                "accuracy": 13.700000000000001,
                "f1": 12.367662337662336,
                "precision": 11.934237966189185,
                "recall": 13.700000000000001,
                "main_score": 12.367662337662336
            },
            {
                "hf_subset": "ron-eng",
                "languages": [
                    "ron-Latn",
                    "eng-Latn"
                ],
                "accuracy": 14.299999999999999,
                "f1": 10.942180289268338,
                "precision": 10.153968847262192,
                "recall": 14.299999999999999,
                "main_score": 10.942180289268338
            },
            {
                "hf_subset": "ang-eng",
                "languages": [
                    "ang-Latn",
                    "eng-Latn"
                ],
                "accuracy": 22.388059701492537,
                "f1": 17.00157733660433,
                "precision": 15.650551589876702,
                "recall": 22.388059701492537,
                "main_score": 17.00157733660433
            },
            {
                "hf_subset": "ido-eng",
                "languages": [
                    "ido-Latn",
                    "eng-Latn"
                ],
                "accuracy": 22,
                "f1": 17.4576947358322,
                "precision": 16.261363669827777,
                "recall": 22,
                "main_score": 17.4576947358322
            },
            {
                "hf_subset": "jav-eng",
                "languages": [
                    "jav-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.292682926829269,
                "f1": 5.544048456005624,
                "precision": 5.009506603002538,
                "recall": 8.292682926829269,
                "main_score": 5.544048456005624
            },
            {
                "hf_subset": "isl-eng",
                "languages": [
                    "isl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.4,
                "f1": 4.148897174789229,
                "precision": 3.862217259449564,
                "recall": 5.4,
                "main_score": 4.148897174789229
            },
            {
                "hf_subset": "slv-eng",
                "languages": [
                    "slv-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.5893074119076545,
                "f1": 4.375041810373159,
                "precision": 4.181207113088141,
                "recall": 5.5893074119076545,
                "main_score": 4.375041810373159
            },
            {
                "hf_subset": "cym-eng",
                "languages": [
                    "cym-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.17391304347826,
                "f1": 6.448011891490153,
                "precision": 5.9719116632160105,
                "recall": 8.17391304347826,
                "main_score": 6.448011891490153
            },
            {
                "hf_subset": "kaz-eng",
                "languages": [
                    "kaz-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 0.8695652173913043,
                "f1": 0.582815734989648,
                "precision": 0.5580885233059146,
                "recall": 0.8695652173913043,
                "main_score": 0.582815734989648
            },
            {
                "hf_subset": "est-eng",
                "languages": [
                    "est-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.1,
                "f1": 3.5000615825615826,
                "precision": 3.2073523577994707,
                "recall": 5.1,
                "main_score": 3.5000615825615826
            },
            {
                "hf_subset": "heb-eng",
                "languages": [
                    "heb-Hebr",
                    "eng-Latn"
                ],
                "accuracy": 0.3,
                "f1": 0.10109884927372195,
                "precision": 0.10055127118392897,
                "recall": 0.3,
                "main_score": 0.10109884927372195
            },
            {
                "hf_subset": "gla-eng",
                "languages": [
                    "gla-Latn",
                    "eng-Latn"
                ],
                "accuracy": 3.8600723763570564,
                "f1": 2.8177402725050493,
                "precision": 2.5662687819699213,
                "recall": 3.8600723763570564,
                "main_score": 2.8177402725050493
            },
            {
                "hf_subset": "mar-eng",
                "languages": [
                    "mar-Deva",
                    "eng-Latn"
                ],
                "accuracy": 0,
                "f1": 0,
                "precision": 0,
                "recall": 0,
                "main_score": 0
            },
            {
                "hf_subset": "lat-eng",
                "languages": [
                    "lat-Latn",
                    "eng-Latn"
                ],
                "accuracy": 15.299999999999999,
                "f1": 11.377964359824292,
                "precision": 10.361140908892764,
                "recall": 15.299999999999999,
                "main_score": 11.377964359824292
            },
            {
                "hf_subset": "bel-eng",
                "languages": [
                    "bel-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 1.3,
                "f1": 0.9600820232399179,
                "precision": 0.9151648856810397,
                "recall": 1.3,
                "main_score": 0.9600820232399179
            },
            {
                "hf_subset": "pms-eng",
                "languages": [
                    "pms-Latn",
                    "eng-Latn"
                ],
                "accuracy": 14.095238095238095,
                "f1": 11.40081541819044,
                "precision": 10.645867976820359,
                "recall": 14.095238095238095,
                "main_score": 11.40081541819044
            },
            {
                "hf_subset": "gle-eng",
                "languages": [
                    "gle-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4,
                "f1": 2.3800704501963432,
                "precision": 2.0919368034607455,
                "recall": 4,
                "main_score": 2.3800704501963432
            },
            {
                "hf_subset": "pes-eng",
                "languages": [
                    "pes-Arab",
                    "eng-Latn"
                ],
                "accuracy": 0.3,
                "f1": 0.2002053388090349,
                "precision": 0.2001027749229188,
                "recall": 0.3,
                "main_score": 0.2002053388090349
            },
            {
                "hf_subset": "nob-eng",
                "languages": [
                    "nob-Latn",
                    "eng-Latn"
                ],
                "accuracy": 11.700000000000001,
                "f1": 10.29755634495992,
                "precision": 9.876637220292393,
                "recall": 11.700000000000001,
                "main_score": 10.29755634495992
            },
            {
                "hf_subset": "bul-eng",
                "languages": [
                    "bul-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 1.7000000000000002,
                "f1": 0.985815849620051,
                "precision": 0.8884689922480621,
                "recall": 1.7000000000000002,
                "main_score": 0.985815849620051
            },
            {
                "hf_subset": "cbk-eng",
                "languages": [
                    "cbk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 17.599999999999998,
                "f1": 14.086312656126182,
                "precision": 13.192360560816125,
                "recall": 17.599999999999998,
                "main_score": 14.086312656126182
            },
            {
                "hf_subset": "hun-eng",
                "languages": [
                    "hun-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.1,
                "f1": 4.683795729173087,
                "precision": 4.31687579027912,
                "recall": 6.1,
                "main_score": 4.683795729173087
            },
            {
                "hf_subset": "uig-eng",
                "languages": [
                    "uig-Arab",
                    "eng-Latn"
                ],
                "accuracy": 0.4,
                "f1": 0.20966666666666667,
                "precision": 0.20500700280112047,
                "recall": 0.4,
                "main_score": 0.20966666666666667
            },
            {
                "hf_subset": "rus-eng",
                "languages": [
                    "rus-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 0.6,
                "f1": 0.2454665118079752,
                "precision": 0.2255125167991618,
                "recall": 0.6,
                "main_score": 0.2454665118079752
            },
            {
                "hf_subset": "spa-eng",
                "languages": [
                    "spa-Latn",
                    "eng-Latn"
                ],
                "accuracy": 21,
                "f1": 18.965901242066018,
                "precision": 18.381437375171,
                "recall": 21,
                "main_score": 18.965901242066018
            },
            {
                "hf_subset": "hye-eng",
                "languages": [
                    "hye-Armn",
                    "eng-Latn"
                ],
                "accuracy": 0.5390835579514826,
                "f1": 0.4048898457205192,
                "precision": 0.4046018763809678,
                "recall": 0.5390835579514826,
                "main_score": 0.4048898457205192
            },
            {
                "hf_subset": "tel-eng",
                "languages": [
                    "tel-Telu",
                    "eng-Latn"
                ],
                "accuracy": 1.282051282051282,
                "f1": 0.5098554872310529,
                "precision": 0.4715099715099715,
                "recall": 1.282051282051282,
                "main_score": 0.5098554872310529
            },
            {
                "hf_subset": "afr-eng",
                "languages": [
                    "afr-Latn",
                    "eng-Latn"
                ],
                "accuracy": 10.7,
                "f1": 8.045120643200706,
                "precision": 7.387598023074453,
                "recall": 10.7,
                "main_score": 8.045120643200706
            },
            {
                "hf_subset": "mon-eng",
                "languages": [
                    "mon-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 2.272727272727273,
                "f1": 1.44184724004356,
                "precision": 1.4082306862044767,
                "recall": 2.272727272727273,
                "main_score": 1.44184724004356
            },
            {
                "hf_subset": "arz-eng",
                "languages": [
                    "arz-Arab",
                    "eng-Latn"
                ],
                "accuracy": 0.20964360587002098,
                "f1": 0.001335309591528796,
                "precision": 0.0006697878781789807,
                "recall": 0.20964360587002098,
                "main_score": 0.001335309591528796
            },
            {
                "hf_subset": "hrv-eng",
                "languages": [
                    "hrv-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.1,
                "f1": 5.522254020507502,
                "precision": 5.081849426723903,
                "recall": 7.1,
                "main_score": 5.522254020507502
            },
            {
                "hf_subset": "nov-eng",
                "languages": [
                    "nov-Latn",
                    "eng-Latn"
                ],
                "accuracy": 36.57587548638132,
                "f1": 30.325515383881147,
                "precision": 28.59255854392041,
                "recall": 36.57587548638132,
                "main_score": 30.325515383881147
            },
            {
                "hf_subset": "gsw-eng",
                "languages": [
                    "gsw-Latn",
                    "eng-Latn"
                ],
                "accuracy": 16.23931623931624,
                "f1": 13.548783761549718,
                "precision": 13.0472896359184,
                "recall": 16.23931623931624,
                "main_score": 13.548783761549718
            },
            {
                "hf_subset": "nds-eng",
                "languages": [
                    "nds-Latn",
                    "eng-Latn"
                ],
                "accuracy": 16.3,
                "f1": 13.3418584934734,
                "precision": 12.506853047473756,
                "recall": 16.3,
                "main_score": 13.3418584934734
            },
            {
                "hf_subset": "ukr-eng",
                "languages": [
                    "ukr-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 1,
                "f1": 0.7764001197963462,
                "precision": 0.7551049317943337,
                "recall": 1,
                "main_score": 0.7764001197963462
            },
            {
                "hf_subset": "uzb-eng",
                "languages": [
                    "uzb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 3.9719626168224296,
                "f1": 3.190729401654313,
                "precision": 3.001159168296747,
                "recall": 3.9719626168224296,
                "main_score": 3.190729401654313
            },
            {
                "hf_subset": "lit-eng",
                "languages": [
                    "lit-Latn",
                    "eng-Latn"
                ],
                "accuracy": 3.4000000000000004,
                "f1": 2.4847456001574653,
                "precision": 2.308739271803959,
                "recall": 3.4000000000000004,
                "main_score": 2.4847456001574653
            },
            {
                "hf_subset": "ina-eng",
                "languages": [
                    "ina-Latn",
                    "eng-Latn"
                ],
                "accuracy": 36.9,
                "f1": 31.390407955063697,
                "precision": 29.631294298308614,
                "recall": 36.9,
                "main_score": 31.390407955063697
            },
            {
                "hf_subset": "lfn-eng",
                "languages": [
                    "lfn-Latn",
                    "eng-Latn"
                ],
                "accuracy": 14.2,
                "f1": 12.551591810861895,
                "precision": 12.100586917562724,
                "recall": 14.2,
                "main_score": 12.551591810861895
            },
            {
                "hf_subset": "zsm-eng",
                "languages": [
                    "zsm-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.2,
                "f1": 7.5561895648211435,
                "precision": 7.177371101110253,
                "recall": 9.2,
                "main_score": 7.5561895648211435
            },
            {
                "hf_subset": "ita-eng",
                "languages": [
                    "ita-Latn",
                    "eng-Latn"
                ],
                "accuracy": 21.2,
                "f1": 18.498268429117875,
                "precision": 17.693915156965357,
                "recall": 21.2,
                "main_score": 18.498268429117875
            },
            {
                "hf_subset": "cmn-eng",
                "languages": [
                    "cmn-Hans",
                    "eng-Latn"
                ],
                "accuracy": 4.2,
                "f1": 2.886572782530936,
                "precision": 2.5806792595351915,
                "recall": 4.2,
                "main_score": 2.886572782530936
            },
            {
                "hf_subset": "lvs-eng",
                "languages": [
                    "lvs-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.800000000000001,
                "f1": 4.881091920308238,
                "precision": 4.436731163345769,
                "recall": 6.800000000000001,
                "main_score": 4.881091920308238
            },
            {
                "hf_subset": "glg-eng",
                "languages": [
                    "glg-Latn",
                    "eng-Latn"
                ],
                "accuracy": 22.1,
                "f1": 18.493832677140738,
                "precision": 17.52055858924503,
                "recall": 22.1,
                "main_score": 18.493832677140738
            },
            {
                "hf_subset": "ceb-eng",
                "languages": [
                    "ceb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6,
                "f1": 4.58716840215435,
                "precision": 4.303119297298687,
                "recall": 6,
                "main_score": 4.58716840215435
            },
            {
                "hf_subset": "bre-eng",
                "languages": [
                    "bre-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.5,
                "f1": 3.813678559437776,
                "precision": 3.52375763382276,
                "recall": 5.5,
                "main_score": 3.813678559437776
            },
            {
                "hf_subset": "ben-eng",
                "languages": [
                    "ben-Beng",
                    "eng-Latn"
                ],
                "accuracy": 0.2,
                "f1": 0.06701509872241579,
                "precision": 0.05017452006980803,
                "recall": 0.2,
                "main_score": 0.06701509872241579
            },
            {
                "hf_subset": "swg-eng",
                "languages": [
                    "swg-Latn",
                    "eng-Latn"
                ],
                "accuracy": 12.5,
                "f1": 9.325396825396826,
                "precision": 8.681972789115646,
                "recall": 12.5,
                "main_score": 9.325396825396826
            },
            {
                "hf_subset": "arq-eng",
                "languages": [
                    "arq-Arab",
                    "eng-Latn"
                ],
                "accuracy": 0.43907793633369924,
                "f1": 0.26369680618309754,
                "precision": 0.24710650393580552,
                "recall": 0.43907793633369924,
                "main_score": 0.26369680618309754
            },
            {
                "hf_subset": "kab-eng",
                "languages": [
                    "kab-Latn",
                    "eng-Latn"
                ],
                "accuracy": 1.7000000000000002,
                "f1": 1.0240727731562105,
                "precision": 0.9379457073996874,
                "recall": 1.7000000000000002,
                "main_score": 1.0240727731562105
            },
            {
                "hf_subset": "fra-eng",
                "languages": [
                    "fra-Latn",
                    "eng-Latn"
                ],
                "accuracy": 24.6,
                "f1": 21.527732683982684,
                "precision": 20.460911398969852,
                "recall": 24.6,
                "main_score": 21.527732683982684
            },
            {
                "hf_subset": "por-eng",
                "languages": [
                    "por-Latn",
                    "eng-Latn"
                ],
                "accuracy": 23.400000000000002,
                "f1": 18.861948871033608,
                "precision": 17.469730524988158,
                "recall": 23.400000000000002,
                "main_score": 18.861948871033608
            },
            {
                "hf_subset": "tat-eng",
                "languages": [
                    "tat-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 1.3,
                "f1": 0.8081609699284277,
                "precision": 0.8041232161030668,
                "recall": 1.3,
                "main_score": 0.8081609699284277
            },
            {
                "hf_subset": "oci-eng",
                "languages": [
                    "oci-Latn",
                    "eng-Latn"
                ],
                "accuracy": 14.399999999999999,
                "f1": 11.982642360594898,
                "precision": 11.423911681034546,
                "recall": 14.399999999999999,
                "main_score": 11.982642360594898
            },
            {
                "hf_subset": "pol-eng",
                "languages": [
                    "pol-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.7,
                "f1": 6.565099922088448,
                "precision": 6.009960806394631,
                "recall": 8.7,
                "main_score": 6.565099922088448
            },
            {
                "hf_subset": "war-eng",
                "languages": [
                    "war-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.1,
                "f1": 5.483244116053285,
                "precision": 5.08036675810842,
                "recall": 7.1,
                "main_score": 5.483244116053285
            },
            {
                "hf_subset": "aze-eng",
                "languages": [
                    "aze-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.3999999999999995,
                "f1": 3.2643948695904146,
                "precision": 3.031506651474311,
                "recall": 4.3999999999999995,
                "main_score": 3.2643948695904146
            },
            {
                "hf_subset": "vie-eng",
                "languages": [
                    "vie-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.1,
                "f1": 5.2787766765398345,
                "precision": 4.883891459552525,
                "recall": 7.1,
                "main_score": 5.2787766765398345
            },
            {
                "hf_subset": "nno-eng",
                "languages": [
                    "nno-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.5,
                "f1": 7.022436974789914,
                "precision": 6.517919923571304,
                "recall": 8.5,
                "main_score": 7.022436974789914
            },
            {
                "hf_subset": "cha-eng",
                "languages": [
                    "cha-Latn",
                    "eng-Latn"
                ],
                "accuracy": 17.51824817518248,
                "f1": 14.159211038143834,
                "precision": 13.419131771033424,
                "recall": 17.51824817518248,
                "main_score": 14.159211038143834
            },
            {
                "hf_subset": "mhr-eng",
                "languages": [
                    "mhr-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 0.3,
                "f1": 0.1008802791411487,
                "precision": 0.10044111373948113,
                "recall": 0.3,
                "main_score": 0.1008802791411487
            },
            {
                "hf_subset": "dan-eng",
                "languages": [
                    "dan-Latn",
                    "eng-Latn"
                ],
                "accuracy": 11.3,
                "f1": 10.0642631078894,
                "precision": 9.714481189937882,
                "recall": 11.3,
                "main_score": 10.0642631078894
            },
            {
                "hf_subset": "ell-eng",
                "languages": [
                    "ell-Grek",
                    "eng-Latn"
                ],
                "accuracy": 0.7000000000000001,
                "f1": 0.5023625310859353,
                "precision": 0.5011883541295307,
                "recall": 0.7000000000000001,
                "main_score": 0.5023625310859353
            },
            {
                "hf_subset": "amh-eng",
                "languages": [
                    "amh-Ethi",
                    "eng-Latn"
                ],
                "accuracy": 1.7857142857142856,
                "f1": 0.6731500547238763,
                "precision": 0.6364087301587301,
                "recall": 1.7857142857142856,
                "main_score": 0.6731500547238763
            },
            {
                "hf_subset": "pam-eng",
                "languages": [
                    "pam-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.000000000000001,
                "f1": 4.850226809905071,
                "precision": 4.3549672188068485,
                "recall": 7.000000000000001,
                "main_score": 4.850226809905071
            },
            {
                "hf_subset": "hsb-eng",
                "languages": [
                    "hsb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.383022774327122,
                "f1": 4.080351427081423,
                "precision": 3.7431771127423294,
                "recall": 5.383022774327122,
                "main_score": 4.080351427081423
            },
            {
                "hf_subset": "srp-eng",
                "languages": [
                    "srp-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 3.9,
                "f1": 2.975065835065835,
                "precision": 2.7082951373488764,
                "recall": 3.9,
                "main_score": 2.975065835065835
            },
            {
                "hf_subset": "epo-eng",
                "languages": [
                    "epo-Latn",
                    "eng-Latn"
                ],
                "accuracy": 13.8,
                "f1": 10.976459812917616,
                "precision": 10.214566903851944,
                "recall": 13.8,
                "main_score": 10.976459812917616
            },
            {
                "hf_subset": "kzj-eng",
                "languages": [
                    "kzj-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.9,
                "f1": 3.5998112099809334,
                "precision": 3.391430386128988,
                "recall": 4.9,
                "main_score": 3.5998112099809334
            },
            {
                "hf_subset": "awa-eng",
                "languages": [
                    "awa-Deva",
                    "eng-Latn"
                ],
                "accuracy": 2.1645021645021645,
                "f1": 0.28969205674033943,
                "precision": 0.1648931376979724,
                "recall": 2.1645021645021645,
                "main_score": 0.28969205674033943
            },
            {
                "hf_subset": "fao-eng",
                "languages": [
                    "fao-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.541984732824428,
                "f1": 8.129327179123026,
                "precision": 7.860730567672363,
                "recall": 9.541984732824428,
                "main_score": 8.129327179123026
            },
            {
                "hf_subset": "mal-eng",
                "languages": [
                    "mal-Mlym",
                    "eng-Latn"
                ],
                "accuracy": 0.5822416302765648,
                "f1": 0.3960292169899156,
                "precision": 0.36794436357755134,
                "recall": 0.5822416302765648,
                "main_score": 0.3960292169899156
            },
            {
                "hf_subset": "ile-eng",
                "languages": [
                    "ile-Latn",
                    "eng-Latn"
                ],
                "accuracy": 25.900000000000002,
                "f1": 20.98162273769728,
                "precision": 19.591031936732236,
                "recall": 25.900000000000002,
                "main_score": 20.98162273769728
            },
            {
                "hf_subset": "bos-eng",
                "languages": [
                    "bos-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.322033898305085,
                "f1": 7.1764632211739166,
                "precision": 6.547619047619047,
                "recall": 9.322033898305085,
                "main_score": 7.1764632211739166
            },
            {
                "hf_subset": "cor-eng",
                "languages": [
                    "cor-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.3999999999999995,
                "f1": 3.0484795026022216,
                "precision": 2.8132647991077686,
                "recall": 4.3999999999999995,
                "main_score": 3.0484795026022216
            },
            {
                "hf_subset": "cat-eng",
                "languages": [
                    "cat-Latn",
                    "eng-Latn"
                ],
                "accuracy": 18.8,
                "f1": 15.52276497119774,
                "precision": 14.63296284434154,
                "recall": 18.8,
                "main_score": 15.52276497119774
            },
            {
                "hf_subset": "eus-eng",
                "languages": [
                    "eus-Latn",
                    "eng-Latn"
                ],
                "accuracy": 10,
                "f1": 7.351901305737391,
                "precision": 6.759061952118555,
                "recall": 10,
                "main_score": 7.351901305737391
            },
            {
                "hf_subset": "yue-eng",
                "languages": [
                    "yue-Hant",
                    "eng-Latn"
                ],
                "accuracy": 3.1,
                "f1": 2.1527437641723353,
                "precision": 2.0008336640383417,
                "recall": 3.1,
                "main_score": 2.1527437641723353
            },
            {
                "hf_subset": "swe-eng",
                "languages": [
                    "swe-Latn",
                    "eng-Latn"
                ],
                "accuracy": 10.6,
                "f1": 8.471815215313617,
                "precision": 7.942319409218233,
                "recall": 10.6,
                "main_score": 8.471815215313617
            },
            {
                "hf_subset": "dtp-eng",
                "languages": [
                    "dtp-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.3,
                "f1": 2.7338036427188244,
                "precision": 2.5492261384839052,
                "recall": 4.3,
                "main_score": 2.7338036427188244
            },
            {
                "hf_subset": "kat-eng",
                "languages": [
                    "kat-Geor",
                    "eng-Latn"
                ],
                "accuracy": 0.40214477211796246,
                "f1": 0.28150134048257375,
                "precision": 0.2751516861859743,
                "recall": 0.40214477211796246,
                "main_score": 0.28150134048257375
            },
            {
                "hf_subset": "jpn-eng",
                "languages": [
                    "jpn-Jpan",
                    "eng-Latn"
                ],
                "accuracy": 3,
                "f1": 1.5834901411814404,
                "precision": 1.3894010894944848,
                "recall": 3,
                "main_score": 1.5834901411814404
            },
            {
                "hf_subset": "csb-eng",
                "languages": [
                    "csb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.905138339920949,
                "f1": 6.6397047981096735,
                "precision": 6.32664437012263,
                "recall": 7.905138339920949,
                "main_score": 6.6397047981096735
            },
            {
                "hf_subset": "xho-eng",
                "languages": [
                    "xho-Latn",
                    "eng-Latn"
                ],
                "accuracy": 3.5211267605633805,
                "f1": 2.173419196807775,
                "precision": 2.14388897487489,
                "recall": 3.5211267605633805,
                "main_score": 2.173419196807775
            },
            {
                "hf_subset": "orv-eng",
                "languages": [
                    "orv-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 0.23952095808383234,
                "f1": 0.001262128032547595,
                "precision": 0.0006327654461278806,
                "recall": 0.23952095808383234,
                "main_score": 0.001262128032547595
            },
            {
                "hf_subset": "ind-eng",
                "languages": [
                    "ind-Latn",
                    "eng-Latn"
                ],
                "accuracy": 10.4,
                "f1": 8.370422351826372,
                "precision": 7.943809523809523,
                "recall": 10.4,
                "main_score": 8.370422351826372
            },
            {
                "hf_subset": "tuk-eng",
                "languages": [
                    "tuk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.41871921182266,
                "f1": 3.4763895108722696,
                "precision": 3.1331846246882176,
                "recall": 5.41871921182266,
                "main_score": 3.4763895108722696
            },
            {
                "hf_subset": "max-eng",
                "languages": [
                    "max-Deva",
                    "eng-Latn"
                ],
                "accuracy": 9.15492957746479,
                "f1": 7.267458920187794,
                "precision": 6.893803787858966,
                "recall": 9.15492957746479,
                "main_score": 7.267458920187794
            },
            {
                "hf_subset": "swh-eng",
                "languages": [
                    "swh-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.487179487179487,
                "f1": 6.902767160316073,
                "precision": 6.450346503818517,
                "recall": 9.487179487179487,
                "main_score": 6.902767160316073
            },
            {
                "hf_subset": "hin-eng",
                "languages": [
                    "hin-Deva",
                    "eng-Latn"
                ],
                "accuracy": 0.1,
                "f1": 0.0002042900919305414,
                "precision": 0.00010224948875255625,
                "recall": 0.1,
                "main_score": 0.0002042900919305414
            },
            {
                "hf_subset": "dsb-eng",
                "languages": [
                    "dsb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.010438413361169,
                "f1": 3.8116647214505277,
                "precision": 3.5454644309619634,
                "recall": 5.010438413361169,
                "main_score": 3.8116647214505277
            },
            {
                "hf_subset": "ber-eng",
                "languages": [
                    "ber-Tfng",
                    "eng-Latn"
                ],
                "accuracy": 6.2,
                "f1": 5.213158915433869,
                "precision": 5.080398110661268,
                "recall": 6.2,
                "main_score": 5.213158915433869
            },
            {
                "hf_subset": "tam-eng",
                "languages": [
                    "tam-Taml",
                    "eng-Latn"
                ],
                "accuracy": 0.9771986970684038,
                "f1": 0.5061388123277374,
                "precision": 0.43431053203040165,
                "recall": 0.9771986970684038,
                "main_score": 0.5061388123277374
            },
            {
                "hf_subset": "slk-eng",
                "languages": [
                    "slk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.3,
                "f1": 5.6313180921027755,
                "precision": 5.303887400540395,
                "recall": 7.3,
                "main_score": 5.6313180921027755
            },
            {
                "hf_subset": "tgl-eng",
                "languages": [
                    "tgl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 3.5999999999999996,
                "f1": 3.2180089485458607,
                "precision": 3.1006756756756753,
                "recall": 3.5999999999999996,
                "main_score": 3.2180089485458607
            },
            {
                "hf_subset": "ast-eng",
                "languages": [
                    "ast-Latn",
                    "eng-Latn"
                ],
                "accuracy": 22.04724409448819,
                "f1": 17.92525934258218,
                "precision": 16.48251629836593,
                "recall": 22.04724409448819,
                "main_score": 17.92525934258218
            },
            {
                "hf_subset": "mkd-eng",
                "languages": [
                    "mkd-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 0.5,
                "f1": 0.1543743186232414,
                "precision": 0.13554933572174951,
                "recall": 0.5,
                "main_score": 0.1543743186232414
            },
            {
                "hf_subset": "khm-eng",
                "languages": [
                    "khm-Khmr",
                    "eng-Latn"
                ],
                "accuracy": 0.8310249307479225,
                "f1": 0.5102255597841558,
                "precision": 0.4859595744731704,
                "recall": 0.8310249307479225,
                "main_score": 0.5102255597841558
            },
            {
                "hf_subset": "ces-eng",
                "languages": [
                    "ces-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.9,
                "f1": 4.7258390633390635,
                "precision": 4.288366570275279,
                "recall": 6.9,
                "main_score": 4.7258390633390635
            },
            {
                "hf_subset": "tzl-eng",
                "languages": [
                    "tzl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 17.307692307692307,
                "f1": 14.763313609467454,
                "precision": 14.129273504273504,
                "recall": 17.307692307692307,
                "main_score": 14.763313609467454
            },
            {
                "hf_subset": "urd-eng",
                "languages": [
                    "urd-Arab",
                    "eng-Latn"
                ],
                "accuracy": 0.3,
                "f1": 0.0022196828248667185,
                "precision": 0.0011148527298850575,
                "recall": 0.3,
                "main_score": 0.0022196828248667185
            },
            {
                "hf_subset": "ara-eng",
                "languages": [
                    "ara-Arab",
                    "eng-Latn"
                ],
                "accuracy": 0.3,
                "f1": 0.3,
                "precision": 0.3,
                "recall": 0.3,
                "main_score": 0.3
            },
            {
                "hf_subset": "kor-eng",
                "languages": [
                    "kor-Hang",
                    "eng-Latn"
                ],
                "accuracy": 0.6,
                "f1": 0.500206611570248,
                "precision": 0.5001034126163392,
                "recall": 0.6,
                "main_score": 0.500206611570248
            },
            {
                "hf_subset": "yid-eng",
                "languages": [
                    "yid-Hebr",
                    "eng-Latn"
                ],
                "accuracy": 0.4716981132075472,
                "f1": 0.2953377695417789,
                "precision": 0.2754210459668228,
                "recall": 0.4716981132075472,
                "main_score": 0.2953377695417789
            },
            {
                "hf_subset": "fin-eng",
                "languages": [
                    "fin-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.3999999999999995,
                "f1": 3.6228414442700156,
                "precision": 3.4318238993710692,
                "recall": 4.3999999999999995,
                "main_score": 3.6228414442700156
            },
            {
                "hf_subset": "tha-eng",
                "languages": [
                    "tha-Thai",
                    "eng-Latn"
                ],
                "accuracy": 1.2773722627737227,
                "f1": 1.0043318098096732,
                "precision": 0.9735777358593729,
                "recall": 1.2773722627737227,
                "main_score": 1.0043318098096732
            },
            {
                "hf_subset": "wuu-eng",
                "languages": [
                    "wuu-Hans",
                    "eng-Latn"
                ],
                "accuracy": 3.9,
                "f1": 2.6164533097276226,
                "precision": 2.3558186153594085,
                "recall": 3.9,
                "main_score": 2.6164533097276226
            }
        ]
    }
}