{
    "dataset_revision": "ed9a4403ed4adbfaf4aab56d5b2709e9f6c3ba33",
    "task_name": "NTREXBitextMining",
    "evaluation_time": NaN,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "arb_Arab-hun_Latn",
                "languages": [
                    "arb-Arab",
                    "hun-Latn"
                ],
                "accuracy": 83.07461191787682,
                "f1": 78.97012184944082,
                "main_score": 78.97012184944082,
                "precision": 77.16324486730095,
                "recall": 83.07461191787682
            },
            {
                "hf_subset": "ben_Beng-hun_Latn",
                "languages": [
                    "ben-Beng",
                    "hun-Latn"
                ],
                "accuracy": 81.2719078617927,
                "f1": 76.6133724396118,
                "main_score": 76.6133724396118,
                "precision": 74.5247633354794,
                "recall": 81.2719078617927
            },
            {
                "hf_subset": "deu_Latn-hun_Latn",
                "languages": [
                    "deu-Latn",
                    "hun-Latn"
                ],
                "accuracy": 90.78617926890335,
                "f1": 88.27073944249707,
                "main_score": 88.27073944249707,
                "precision": 87.1056584877316,
                "recall": 90.78617926890335
            },
            {
                "hf_subset": "ell_Grek-hun_Latn",
                "languages": [
                    "ell-Grek",
                    "hun-Latn"
                ],
                "accuracy": 89.08362543815723,
                "f1": 86.19429143715574,
                "main_score": 86.19429143715574,
                "precision": 84.85728592889333,
                "recall": 89.08362543815723
            },
            {
                "hf_subset": "eng_Latn-hun_Latn",
                "languages": [
                    "eng-Latn",
                    "hun-Latn"
                ],
                "accuracy": 93.23985978968453,
                "f1": 91.4087798364213,
                "main_score": 91.4087798364213,
                "precision": 90.57753296611585,
                "recall": 93.23985978968453
            },
            {
                "hf_subset": "fas_Arab-hun_Latn",
                "languages": [
                    "fas-Arab",
                    "hun-Latn"
                ],
                "accuracy": 86.37956935403105,
                "f1": 82.8442663995994,
                "main_score": 82.8442663995994,
                "precision": 81.2635620096812,
                "recall": 86.37956935403105
            },
            {
                "hf_subset": "fin_Latn-hun_Latn",
                "languages": [
                    "fin-Latn",
                    "hun-Latn"
                ],
                "accuracy": 85.42814221331997,
                "f1": 81.80031952690942,
                "main_score": 81.80031952690942,
                "precision": 80.1235186112502,
                "recall": 85.42814221331997
            },
            {
                "hf_subset": "fra_Latn-hun_Latn",
                "languages": [
                    "fra-Latn",
                    "hun-Latn"
                ],
                "accuracy": 90.83625438157236,
                "f1": 88.31079953263227,
                "main_score": 88.31079953263227,
                "precision": 87.11817726589885,
                "recall": 90.83625438157236
            },
            {
                "hf_subset": "heb_Hebr-hun_Latn",
                "languages": [
                    "heb-Hebr",
                    "hun-Latn"
                ],
                "accuracy": 81.32198297446169,
                "f1": 76.4972458688032,
                "main_score": 76.4972458688032,
                "precision": 74.3578462932494,
                "recall": 81.32198297446169
            },
            {
                "hf_subset": "hin_Deva-hun_Latn",
                "languages": [
                    "hin-Deva",
                    "hun-Latn"
                ],
                "accuracy": 86.37956935403105,
                "f1": 82.83341679185445,
                "main_score": 82.83341679185445,
                "precision": 81.21563297326942,
                "recall": 86.37956935403105
            },
            {
                "hf_subset": "hun_Latn-arb_Arab",
                "languages": [
                    "hun-Latn",
                    "arb-Arab"
                ],
                "accuracy": 82.22333500250375,
                "f1": 77.76760378663232,
                "main_score": 77.76760378663232,
                "precision": 75.81634356296348,
                "recall": 82.22333500250375
            },
            {
                "hf_subset": "hun_Latn-ben_Beng",
                "languages": [
                    "hun-Latn",
                    "ben-Beng"
                ],
                "accuracy": 77.56634952428642,
                "f1": 72.28537250319926,
                "main_score": 72.28537250319926,
                "precision": 70.02032811121445,
                "recall": 77.56634952428642
            },
            {
                "hf_subset": "hun_Latn-deu_Latn",
                "languages": [
                    "hun-Latn",
                    "deu-Latn"
                ],
                "accuracy": 91.4371557336004,
                "f1": 89.27391086629945,
                "main_score": 89.27391086629945,
                "precision": 88.24904022700719,
                "recall": 91.4371557336004
            },
            {
                "hf_subset": "hun_Latn-ell_Grek",
                "languages": [
                    "hun-Latn",
                    "ell-Grek"
                ],
                "accuracy": 88.3825738607912,
                "f1": 85.36900588978705,
                "main_score": 85.36900588978705,
                "precision": 83.98848272408614,
                "recall": 88.3825738607912
            },
            {
                "hf_subset": "hun_Latn-eng_Latn",
                "languages": [
                    "hun-Latn",
                    "eng-Latn"
                ],
                "accuracy": 94.2914371557336,
                "f1": 92.68903355032549,
                "main_score": 92.68903355032549,
                "precision": 91.92121515606743,
                "recall": 94.2914371557336
            },
            {
                "hf_subset": "hun_Latn-fas_Arab",
                "languages": [
                    "hun-Latn",
                    "fas-Arab"
                ],
                "accuracy": 84.72709063595393,
                "f1": 80.81622433650475,
                "main_score": 80.81622433650475,
                "precision": 79.05524954097814,
                "recall": 84.72709063595393
            },
            {
                "hf_subset": "hun_Latn-fin_Latn",
                "languages": [
                    "hun-Latn",
                    "fin-Latn"
                ],
                "accuracy": 83.57536304456686,
                "f1": 79.32338984667477,
                "main_score": 79.32338984667477,
                "precision": 77.45833035267187,
                "recall": 83.57536304456686
            },
            {
                "hf_subset": "hun_Latn-fra_Latn",
                "languages": [
                    "hun-Latn",
                    "fra-Latn"
                ],
                "accuracy": 90.48572859288933,
                "f1": 87.94954336266304,
                "main_score": 87.94954336266304,
                "precision": 86.75429811383744,
                "recall": 90.48572859288933
            },
            {
                "hf_subset": "hun_Latn-heb_Hebr",
                "languages": [
                    "hun-Latn",
                    "heb-Hebr"
                ],
                "accuracy": 77.21582373560341,
                "f1": 71.82277384330463,
                "main_score": 71.82277384330463,
                "precision": 69.55856403653098,
                "recall": 77.21582373560341
            },
            {
                "hf_subset": "hun_Latn-hin_Deva",
                "languages": [
                    "hun-Latn",
                    "hin-Deva"
                ],
                "accuracy": 84.77716574862293,
                "f1": 80.97423913648251,
                "main_score": 80.97423913648251,
                "precision": 79.27265898848273,
                "recall": 84.77716574862293
            },
            {
                "hf_subset": "hun_Latn-ind_Latn",
                "languages": [
                    "hun-Latn",
                    "ind-Latn"
                ],
                "accuracy": 90.0350525788683,
                "f1": 87.28592889334,
                "main_score": 87.28592889334,
                "precision": 85.99732932732432,
                "recall": 90.0350525788683
            },
            {
                "hf_subset": "hun_Latn-jpn_Jpan",
                "languages": [
                    "hun-Latn",
                    "jpn-Jpan"
                ],
                "accuracy": 84.37656484727091,
                "f1": 80.59017097074182,
                "main_score": 80.59017097074182,
                "precision": 78.94508429310633,
                "recall": 84.37656484727091
            },
            {
                "hf_subset": "hun_Latn-kor_Hang",
                "languages": [
                    "hun-Latn",
                    "kor-Hang"
                ],
                "accuracy": 80.77115673510265,
                "f1": 76.35683684256543,
                "main_score": 76.35683684256543,
                "precision": 74.47361699114327,
                "recall": 80.77115673510265
            },
            {
                "hf_subset": "hun_Latn-lav_Latn",
                "languages": [
                    "hun-Latn",
                    "lav-Latn"
                ],
                "accuracy": 76.81522283425137,
                "f1": 71.24067052960392,
                "main_score": 71.24067052960392,
                "precision": 68.94003703968652,
                "recall": 76.81522283425137
            },
            {
                "hf_subset": "hun_Latn-lit_Latn",
                "languages": [
                    "hun-Latn",
                    "lit-Latn"
                ],
                "accuracy": 77.3159739609414,
                "f1": 71.92622266733433,
                "main_score": 71.92622266733433,
                "precision": 69.58461501776473,
                "recall": 77.3159739609414
            },
            {
                "hf_subset": "hun_Latn-nld_Latn",
                "languages": [
                    "hun-Latn",
                    "nld-Latn"
                ],
                "accuracy": 90.98647971957938,
                "f1": 88.5027541311968,
                "main_score": 88.5027541311968,
                "precision": 87.33683859122017,
                "recall": 90.98647971957938
            },
            {
                "hf_subset": "hun_Latn-pol_Latn",
                "languages": [
                    "hun-Latn",
                    "pol-Latn"
                ],
                "accuracy": 88.43264897346019,
                "f1": 85.33896082218565,
                "main_score": 85.33896082218565,
                "precision": 83.90919712902688,
                "recall": 88.43264897346019
            },
            {
                "hf_subset": "hun_Latn-por_Latn",
                "languages": [
                    "hun-Latn",
                    "por-Latn"
                ],
                "accuracy": 90.68602904356536,
                "f1": 88.09046903688868,
                "main_score": 88.09046903688868,
                "precision": 86.88449340677683,
                "recall": 90.68602904356536
            },
            {
                "hf_subset": "hun_Latn-rus_Cyrl",
                "languages": [
                    "hun-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 90.0350525788683,
                "f1": 87.35770322149892,
                "main_score": 87.35770322149892,
                "precision": 86.10832916040727,
                "recall": 90.0350525788683
            },
            {
                "hf_subset": "hun_Latn-spa_Latn",
                "languages": [
                    "hun-Latn",
                    "spa-Latn"
                ],
                "accuracy": 92.58888332498748,
                "f1": 90.64763812385245,
                "main_score": 90.64763812385245,
                "precision": 89.75880487397765,
                "recall": 92.58888332498748
            },
            {
                "hf_subset": "hun_Latn-swa_Latn",
                "languages": [
                    "hun-Latn",
                    "swa-Latn"
                ],
                "accuracy": 72.60891337005508,
                "f1": 66.62728580605396,
                "main_score": 66.62728580605396,
                "precision": 64.22842597229177,
                "recall": 72.60891337005508
            },
            {
                "hf_subset": "hun_Latn-swe_Latn",
                "languages": [
                    "hun-Latn",
                    "swe-Latn"
                ],
                "accuracy": 89.03355032548824,
                "f1": 86.01569020196962,
                "main_score": 86.01569020196962,
                "precision": 84.59105324653648,
                "recall": 89.03355032548824
            },
            {
                "hf_subset": "hun_Latn-tam_Taml",
                "languages": [
                    "hun-Latn",
                    "tam-Taml"
                ],
                "accuracy": 74.66199298948423,
                "f1": 68.7971639999682,
                "main_score": 68.7971639999682,
                "precision": 66.36091041323891,
                "recall": 74.66199298948423
            },
            {
                "hf_subset": "hun_Latn-tur_Latn",
                "languages": [
                    "hun-Latn",
                    "tur-Latn"
                ],
                "accuracy": 87.08062093139709,
                "f1": 83.79736271073277,
                "main_score": 83.79736271073277,
                "precision": 82.33278489162315,
                "recall": 87.08062093139709
            },
            {
                "hf_subset": "hun_Latn-vie_Latn",
                "languages": [
                    "hun-Latn",
                    "vie-Latn"
                ],
                "accuracy": 89.78467701552329,
                "f1": 87.0288766483058,
                "main_score": 87.0288766483058,
                "precision": 85.76781839425806,
                "recall": 89.78467701552329
            },
            {
                "hf_subset": "hun_Latn-zho_Hant",
                "languages": [
                    "hun-Latn",
                    "zho-Hant"
                ],
                "accuracy": 87.33099649474211,
                "f1": 84.02103154732097,
                "main_score": 84.02103154732097,
                "precision": 82.51877816725089,
                "recall": 87.33099649474211
            },
            {
                "hf_subset": "hun_Latn-zul_Latn",
                "languages": [
                    "hun-Latn",
                    "zul-Latn"
                ],
                "accuracy": 51.92789183775663,
                "f1": 43.912175926815536,
                "main_score": 43.912175926815536,
                "precision": 41.09881091478487,
                "recall": 51.92789183775663
            },
            {
                "hf_subset": "ind_Latn-hun_Latn",
                "languages": [
                    "ind-Latn",
                    "hun-Latn"
                ],
                "accuracy": 90.1352028042063,
                "f1": 87.51722822328732,
                "main_score": 87.51722822328732,
                "precision": 86.31280253713905,
                "recall": 90.1352028042063
            },
            {
                "hf_subset": "jpn_Jpan-hun_Latn",
                "languages": [
                    "jpn-Jpan",
                    "hun-Latn"
                ],
                "accuracy": 84.37656484727091,
                "f1": 80.56084126189283,
                "main_score": 80.56084126189283,
                "precision": 78.84743782340176,
                "recall": 84.37656484727091
            },
            {
                "hf_subset": "kor_Hang-hun_Latn",
                "languages": [
                    "kor-Hang",
                    "hun-Latn"
                ],
                "accuracy": 83.47521281922884,
                "f1": 79.41519421990128,
                "main_score": 79.41519421990128,
                "precision": 77.57350311181057,
                "recall": 83.47521281922884
            },
            {
                "hf_subset": "lav_Latn-hun_Latn",
                "languages": [
                    "lav-Latn",
                    "hun-Latn"
                ],
                "accuracy": 82.12318477716575,
                "f1": 78.18656556262967,
                "main_score": 78.18656556262967,
                "precision": 76.41879485895511,
                "recall": 82.12318477716575
            },
            {
                "hf_subset": "lit_Latn-hun_Latn",
                "languages": [
                    "lit-Latn",
                    "hun-Latn"
                ],
                "accuracy": 81.67250876314472,
                "f1": 77.52628943415122,
                "main_score": 77.52628943415122,
                "precision": 75.62426973794024,
                "recall": 81.67250876314472
            },
            {
                "hf_subset": "nld_Latn-hun_Latn",
                "languages": [
                    "nld-Latn",
                    "hun-Latn"
                ],
                "accuracy": 91.03655483224837,
                "f1": 88.62404718188392,
                "main_score": 88.62404718188392,
                "precision": 87.50584209647806,
                "recall": 91.03655483224837
            },
            {
                "hf_subset": "pol_Latn-hun_Latn",
                "languages": [
                    "pol-Latn",
                    "hun-Latn"
                ],
                "accuracy": 88.73309964947421,
                "f1": 85.63869613944726,
                "main_score": 85.63869613944726,
                "precision": 84.21799365715239,
                "recall": 88.73309964947421
            },
            {
                "hf_subset": "por_Latn-hun_Latn",
                "languages": [
                    "por-Latn",
                    "hun-Latn"
                ],
                "accuracy": 91.03655483224837,
                "f1": 88.54782173259889,
                "main_score": 88.54782173259889,
                "precision": 87.39108662994491,
                "recall": 91.03655483224837
            },
            {
                "hf_subset": "rus_Cyrl-hun_Latn",
                "languages": [
                    "rus-Cyrl",
                    "hun-Latn"
                ],
                "accuracy": 88.88332498748123,
                "f1": 85.8447194601426,
                "main_score": 85.8447194601426,
                "precision": 84.45751961275246,
                "recall": 88.88332498748123
            },
            {
                "hf_subset": "spa_Latn-hun_Latn",
                "languages": [
                    "spa-Latn",
                    "hun-Latn"
                ],
                "accuracy": 92.13820731096645,
                "f1": 89.933233183108,
                "main_score": 89.933233183108,
                "precision": 88.92004673677182,
                "recall": 92.13820731096645
            },
            {
                "hf_subset": "swa_Latn-hun_Latn",
                "languages": [
                    "swa-Latn",
                    "hun-Latn"
                ],
                "accuracy": 75.7636454682023,
                "f1": 71.19297994610965,
                "main_score": 71.19297994610965,
                "precision": 69.29461652796655,
                "recall": 75.7636454682023
            },
            {
                "hf_subset": "swe_Latn-hun_Latn",
                "languages": [
                    "swe-Latn",
                    "hun-Latn"
                ],
                "accuracy": 89.83475212819229,
                "f1": 87.25779144907837,
                "main_score": 87.25779144907837,
                "precision": 86.05408112168253,
                "recall": 89.83475212819229
            },
            {
                "hf_subset": "tam_Taml-hun_Latn",
                "languages": [
                    "tam-Taml",
                    "hun-Latn"
                ],
                "accuracy": 78.01702553830746,
                "f1": 72.70886488462853,
                "main_score": 72.70886488462853,
                "precision": 70.39064549204758,
                "recall": 78.01702553830746
            },
            {
                "hf_subset": "tur_Latn-hun_Latn",
                "languages": [
                    "tur-Latn",
                    "hun-Latn"
                ],
                "accuracy": 87.33099649474211,
                "f1": 84.28094522736485,
                "main_score": 84.28094522736485,
                "precision": 82.89100317142379,
                "recall": 87.33099649474211
            },
            {
                "hf_subset": "vie_Latn-hun_Latn",
                "languages": [
                    "vie-Latn",
                    "hun-Latn"
                ],
                "accuracy": 89.23385077616425,
                "f1": 86.38290769487564,
                "main_score": 86.38290769487564,
                "precision": 85.08763144717074,
                "recall": 89.23385077616425
            },
            {
                "hf_subset": "zho_Hant-hun_Latn",
                "languages": [
                    "zho-Hant",
                    "hun-Latn"
                ],
                "accuracy": 86.52979469203805,
                "f1": 82.964446670005,
                "main_score": 82.964446670005,
                "precision": 81.4104490068436,
                "recall": 86.52979469203805
            },
            {
                "hf_subset": "zul_Latn-hun_Latn",
                "languages": [
                    "zul-Latn",
                    "hun-Latn"
                ],
                "accuracy": 54.98247371056585,
                "f1": 48.79136275731169,
                "main_score": 48.79136275731169,
                "precision": 46.53637850035387,
                "recall": 54.98247371056585
            }
        ]
    }
}