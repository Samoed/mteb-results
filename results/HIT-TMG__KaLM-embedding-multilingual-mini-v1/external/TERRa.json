{
    "dataset_revision": "7b58f24536063837d644aab9a023c62199b2a612",
    "task_name": "TERRa",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "dev": [
            {
                "hf_subset": "default",
                "languages": [
                    "rus-Cyrl"
                ],
                "cosine_accuracy": 60.91205211726385,
                "cosine_accuracy_threshold": 68.15387606620789,
                "cosine_ap": 57.705995373862805,
                "cosine_f1": 67.57990867579909,
                "cosine_f1_threshold": 54.87680435180664,
                "cosine_precision": 51.92982456140351,
                "cosine_recall": 96.73202614379085,
                "dot_accuracy": 60.91205211726385,
                "dot_accuracy_threshold": 68.15387010574341,
                "dot_ap": 57.705995373862805,
                "dot_f1": 67.57990867579909,
                "dot_f1_threshold": 54.87680435180664,
                "dot_precision": 51.92982456140351,
                "dot_recall": 96.73202614379085,
                "euclidean_accuracy": 60.91205211726385,
                "euclidean_accuracy_threshold": 79.80742454528809,
                "euclidean_ap": 57.705995373862805,
                "euclidean_f1": 67.57990867579909,
                "euclidean_f1_threshold": 94.99809741973877,
                "euclidean_precision": 51.92982456140351,
                "euclidean_recall": 96.73202614379085,
                "main_score": 57.705995373862805,
                "manhattan_accuracy": 60.586319218241044,
                "manhattan_accuracy_threshold": 1858.333969116211,
                "manhattan_ap": 57.53277048517774,
                "manhattan_f1": 67.59259259259261,
                "manhattan_f1_threshold": 2154.4769287109375,
                "manhattan_precision": 52.32974910394266,
                "manhattan_recall": 95.42483660130719,
                "max_ap": 57.705995373862805,
                "max_f1": 67.59259259259261,
                "max_precision": 52.32974910394266,
                "max_recall": 96.73202614379085,
                "similarity_accuracy": 60.91205211726385,
                "similarity_accuracy_threshold": 68.15387606620789,
                "similarity_ap": 57.705995373862805,
                "similarity_f1": 67.57990867579909,
                "similarity_f1_threshold": 54.87680435180664,
                "similarity_precision": 51.92982456140351,
                "similarity_recall": 96.73202614379085
            }
        ]
    }
}