{
    "dataset_revision": "d66bd1f72af766a5cc4b0ca5e00c162f89e8cc46",
    "task_name": "SprintDuplicateQuestions",
    "evaluation_time": NaN,
    "mteb_version": "unknown",
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "cosine_accuracy": 99.71386138613862,
                "cosine_accuracy_threshold": 78.56961662426235,
                "cosine_ap": 90.20131927652946,
                "cosine_f1": 84.7749114820435,
                "cosine_f1_threshold": 75.7768544371973,
                "cosine_precision": 85.7727737973388,
                "cosine_recall": 83.8,
                "dot_accuracy": 99.71386138613862,
                "dot_accuracy_threshold": 78.56961780669964,
                "dot_ap": 90.20131927652946,
                "dot_f1": 84.7749114820435,
                "dot_f1_threshold": 75.77685228378391,
                "dot_precision": 85.7727737973388,
                "dot_recall": 83.8,
                "euclidean_accuracy": 99.71386138613862,
                "euclidean_accuracy_threshold": 65.46813529720524,
                "euclidean_ap": 90.20131927652946,
                "euclidean_f1": 84.7749114820435,
                "euclidean_f1_threshold": 69.60336608830053,
                "euclidean_precision": 85.7727737973388,
                "euclidean_recall": 83.8,
                "main_score": 90.20131927652946,
                "manhattan_accuracy": 99.7059405940594,
                "manhattan_accuracy_threshold": 804.8100425289704,
                "manhattan_ap": 90.00682250828237,
                "manhattan_f1": 84.44211629125196,
                "manhattan_f1_threshold": 828.8486447498144,
                "manhattan_precision": 88.66886688668868,
                "manhattan_recall": 80.60000000000001,
                "max_accuracy": 99.71386138613862,
                "max_ap": 90.20131927652946,
                "max_f1": 84.7749114820435,
                "max_precision": 88.66886688668868,
                "max_recall": 83.8,
                "similarity_accuracy": 99.71386138613862,
                "similarity_accuracy_threshold": 78.56961662426235,
                "similarity_ap": 90.20131927652946,
                "similarity_f1": 84.7749114820435,
                "similarity_f1_threshold": 75.7768544371973,
                "similarity_precision": 85.7727737973388,
                "similarity_recall": 83.8
            }
        ]
    }
}