{
    "dataset_revision": "9080400076fbadbb4c4dcb136ff4eddc40b42553",
    "task_name": "Tatoeba",
    "evaluation_time": -1,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "sqi-eng",
                "languages": [
                    "sqi-Latn",
                    "eng-Latn"
                ],
                "accuracy": 92.10000000000001,
                "f1": 90.06,
                "precision": 89.17333333333333,
                "recall": 92.10000000000001,
                "main_score": 90.06
            },
            {
                "hf_subset": "fry-eng",
                "languages": [
                    "fry-Latn",
                    "eng-Latn"
                ],
                "accuracy": 56.06936416184971,
                "f1": 50.87508028259473,
                "precision": 48.97398843930635,
                "recall": 56.06936416184971,
                "main_score": 50.87508028259473
            },
            {
                "hf_subset": "kur-eng",
                "languages": [
                    "kur-Latn",
                    "eng-Latn"
                ],
                "accuracy": 57.3170731707317,
                "f1": 52.96080139372822,
                "precision": 51.67861124382864,
                "recall": 57.3170731707317,
                "main_score": 52.96080139372822
            },
            {
                "hf_subset": "tur-eng",
                "languages": [
                    "tur-Latn",
                    "eng-Latn"
                ],
                "accuracy": 94.3,
                "f1": 92.67333333333333,
                "precision": 91.90833333333333,
                "recall": 94.3,
                "main_score": 92.67333333333333
            },
            {
                "hf_subset": "deu-eng",
                "languages": [
                    "deu-Latn",
                    "eng-Latn"
                ],
                "accuracy": 97.7,
                "f1": 97.07333333333332,
                "precision": 96.79500000000002,
                "recall": 97.7,
                "main_score": 97.07333333333332
            },
            {
                "hf_subset": "nld-eng",
                "languages": [
                    "nld-Latn",
                    "eng-Latn"
                ],
                "accuracy": 94.69999999999999,
                "f1": 93.2,
                "precision": 92.48333333333333,
                "recall": 94.69999999999999,
                "main_score": 93.2
            },
            {
                "hf_subset": "ron-eng",
                "languages": [
                    "ron-Latn",
                    "eng-Latn"
                ],
                "accuracy": 92.9,
                "f1": 91.26666666666667,
                "precision": 90.59444444444445,
                "recall": 92.9,
                "main_score": 91.26666666666667
            },
            {
                "hf_subset": "ang-eng",
                "languages": [
                    "ang-Latn",
                    "eng-Latn"
                ],
                "accuracy": 34.32835820895522,
                "f1": 29.074180380150533,
                "precision": 28.068207322920596,
                "recall": 34.32835820895522,
                "main_score": 29.074180380150533
            },
            {
                "hf_subset": "ido-eng",
                "languages": [
                    "ido-Latn",
                    "eng-Latn"
                ],
                "accuracy": 78.5,
                "f1": 74.3945115995116,
                "precision": 72.82967843459222,
                "recall": 78.5,
                "main_score": 74.3945115995116
            },
            {
                "hf_subset": "jav-eng",
                "languages": [
                    "jav-Latn",
                    "eng-Latn"
                ],
                "accuracy": 66.34146341463415,
                "f1": 61.2469400518181,
                "precision": 59.63977756660683,
                "recall": 66.34146341463415,
                "main_score": 61.2469400518181
            },
            {
                "hf_subset": "isl-eng",
                "languages": [
                    "isl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 80.9,
                "f1": 76.90349206349207,
                "precision": 75.32921568627451,
                "recall": 80.9,
                "main_score": 76.90349206349207
            },
            {
                "hf_subset": "slv-eng",
                "languages": [
                    "slv-Latn",
                    "eng-Latn"
                ],
                "accuracy": 84.93317132442284,
                "f1": 81.92519105034295,
                "precision": 80.71283920615635,
                "recall": 84.93317132442284,
                "main_score": 81.92519105034295
            },
            {
                "hf_subset": "cym-eng",
                "languages": [
                    "cym-Latn",
                    "eng-Latn"
                ],
                "accuracy": 71.1304347826087,
                "f1": 65.22394755003451,
                "precision": 62.912422360248435,
                "recall": 71.1304347826087,
                "main_score": 65.22394755003451
            },
            {
                "hf_subset": "kaz-eng",
                "languages": [
                    "kaz-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 79.82608695652173,
                "f1": 75.55693581780538,
                "precision": 73.79420289855072,
                "recall": 79.82608695652173,
                "main_score": 75.55693581780538
            },
            {
                "hf_subset": "est-eng",
                "languages": [
                    "est-Latn",
                    "eng-Latn"
                ],
                "accuracy": 74,
                "f1": 70.51022222222223,
                "precision": 69.29673599347512,
                "recall": 74,
                "main_score": 70.51022222222223
            },
            {
                "hf_subset": "heb-eng",
                "languages": [
                    "heb-Hebr",
                    "eng-Latn"
                ],
                "accuracy": 78.7,
                "f1": 74.14238095238095,
                "precision": 72.27214285714285,
                "recall": 78.7,
                "main_score": 74.14238095238095
            },
            {
                "hf_subset": "gla-eng",
                "languages": [
                    "gla-Latn",
                    "eng-Latn"
                ],
                "accuracy": 48.97466827503016,
                "f1": 43.080330405420874,
                "precision": 41.36505499593557,
                "recall": 48.97466827503016,
                "main_score": 43.080330405420874
            },
            {
                "hf_subset": "mar-eng",
                "languages": [
                    "mar-Deva",
                    "eng-Latn"
                ],
                "accuracy": 89.60000000000001,
                "f1": 86.62333333333333,
                "precision": 85.225,
                "recall": 89.60000000000001,
                "main_score": 86.62333333333333
            },
            {
                "hf_subset": "lat-eng",
                "languages": [
                    "lat-Latn",
                    "eng-Latn"
                ],
                "accuracy": 45.2,
                "f1": 39.5761253006253,
                "precision": 37.991358436312,
                "recall": 45.2,
                "main_score": 39.5761253006253
            },
            {
                "hf_subset": "bel-eng",
                "languages": [
                    "bel-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 89.5,
                "f1": 86.70333333333333,
                "precision": 85.53166666666667,
                "recall": 89.5,
                "main_score": 86.70333333333333
            },
            {
                "hf_subset": "pms-eng",
                "languages": [
                    "pms-Latn",
                    "eng-Latn"
                ],
                "accuracy": 50.095238095238095,
                "f1": 44.60650460650461,
                "precision": 42.774116796477045,
                "recall": 50.095238095238095,
                "main_score": 44.60650460650461
            },
            {
                "hf_subset": "gle-eng",
                "languages": [
                    "gle-Latn",
                    "eng-Latn"
                ],
                "accuracy": 63.4,
                "f1": 58.35967261904762,
                "precision": 56.54857142857143,
                "recall": 63.4,
                "main_score": 58.35967261904762
            },
            {
                "hf_subset": "pes-eng",
                "languages": [
                    "pes-Arab",
                    "eng-Latn"
                ],
                "accuracy": 89.2,
                "f1": 87.075,
                "precision": 86.12095238095239,
                "recall": 89.2,
                "main_score": 87.075
            },
            {
                "hf_subset": "nob-eng",
                "languages": [
                    "nob-Latn",
                    "eng-Latn"
                ],
                "accuracy": 96.8,
                "f1": 95.90333333333334,
                "precision": 95.50833333333333,
                "recall": 96.8,
                "main_score": 95.90333333333334
            },
            {
                "hf_subset": "bul-eng",
                "languages": [
                    "bul-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 90.9,
                "f1": 88.6288888888889,
                "precision": 87.61607142857142,
                "recall": 90.9,
                "main_score": 88.6288888888889
            },
            {
                "hf_subset": "cbk-eng",
                "languages": [
                    "cbk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 65.2,
                "f1": 60.54377630539395,
                "precision": 58.89434482711381,
                "recall": 65.2,
                "main_score": 60.54377630539395
            },
            {
                "hf_subset": "hun-eng",
                "languages": [
                    "hun-Latn",
                    "eng-Latn"
                ],
                "accuracy": 87,
                "f1": 84.32412698412699,
                "precision": 83.25527777777778,
                "recall": 87,
                "main_score": 84.32412698412699
            },
            {
                "hf_subset": "uig-eng",
                "languages": [
                    "uig-Arab",
                    "eng-Latn"
                ],
                "accuracy": 68.7,
                "f1": 63.07883541295306,
                "precision": 61.06117424242426,
                "recall": 68.7,
                "main_score": 63.07883541295306
            },
            {
                "hf_subset": "rus-eng",
                "languages": [
                    "rus-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 93.7,
                "f1": 91.78333333333335,
                "precision": 90.86666666666667,
                "recall": 93.7,
                "main_score": 91.78333333333335
            },
            {
                "hf_subset": "spa-eng",
                "languages": [
                    "spa-Latn",
                    "eng-Latn"
                ],
                "accuracy": 97.7,
                "f1": 96.96666666666667,
                "precision": 96.61666666666667,
                "recall": 97.7,
                "main_score": 96.96666666666667
            },
            {
                "hf_subset": "hye-eng",
                "languages": [
                    "hye-Armn",
                    "eng-Latn"
                ],
                "accuracy": 88.27493261455525,
                "f1": 85.90745732255168,
                "precision": 84.91389637616052,
                "recall": 88.27493261455525,
                "main_score": 85.90745732255168
            },
            {
                "hf_subset": "tel-eng",
                "languages": [
                    "tel-Telu",
                    "eng-Latn"
                ],
                "accuracy": 90.5982905982906,
                "f1": 88.4900284900285,
                "precision": 87.57122507122507,
                "recall": 90.5982905982906,
                "main_score": 88.4900284900285
            },
            {
                "hf_subset": "afr-eng",
                "languages": [
                    "afr-Latn",
                    "eng-Latn"
                ],
                "accuracy": 89.5,
                "f1": 86.90769841269842,
                "precision": 85.80178571428571,
                "recall": 89.5,
                "main_score": 86.90769841269842
            },
            {
                "hf_subset": "mon-eng",
                "languages": [
                    "mon-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 82.5,
                "f1": 78.36796536796538,
                "precision": 76.82196969696969,
                "recall": 82.5,
                "main_score": 78.36796536796538
            },
            {
                "hf_subset": "arz-eng",
                "languages": [
                    "arz-Arab",
                    "eng-Latn"
                ],
                "accuracy": 71.48846960167715,
                "f1": 66.78771089148448,
                "precision": 64.98302885095339,
                "recall": 71.48846960167715,
                "main_score": 66.78771089148448
            },
            {
                "hf_subset": "hrv-eng",
                "languages": [
                    "hrv-Latn",
                    "eng-Latn"
                ],
                "accuracy": 94.1,
                "f1": 92.50333333333333,
                "precision": 91.77499999999999,
                "recall": 94.1,
                "main_score": 92.50333333333333
            },
            {
                "hf_subset": "nov-eng",
                "languages": [
                    "nov-Latn",
                    "eng-Latn"
                ],
                "accuracy": 71.20622568093385,
                "f1": 66.83278891450098,
                "precision": 65.35065777283677,
                "recall": 71.20622568093385,
                "main_score": 66.83278891450098
            },
            {
                "hf_subset": "gsw-eng",
                "languages": [
                    "gsw-Latn",
                    "eng-Latn"
                ],
                "accuracy": 48.717948717948715,
                "f1": 43.53146853146853,
                "precision": 42.04721204721204,
                "recall": 48.717948717948715,
                "main_score": 43.53146853146853
            },
            {
                "hf_subset": "nds-eng",
                "languages": [
                    "nds-Latn",
                    "eng-Latn"
                ],
                "accuracy": 58.5,
                "f1": 53.8564991863928,
                "precision": 52.40329436122275,
                "recall": 58.5,
                "main_score": 53.8564991863928
            },
            {
                "hf_subset": "ukr-eng",
                "languages": [
                    "ukr-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 90.8,
                "f1": 88.29,
                "precision": 87.09166666666667,
                "recall": 90.8,
                "main_score": 88.29
            },
            {
                "hf_subset": "uzb-eng",
                "languages": [
                    "uzb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 67.28971962616822,
                "f1": 62.63425307817832,
                "precision": 60.98065939771546,
                "recall": 67.28971962616822,
                "main_score": 62.63425307817832
            },
            {
                "hf_subset": "lit-eng",
                "languages": [
                    "lit-Latn",
                    "eng-Latn"
                ],
                "accuracy": 78.7,
                "f1": 75.5264472455649,
                "precision": 74.38205086580086,
                "recall": 78.7,
                "main_score": 75.5264472455649
            },
            {
                "hf_subset": "ina-eng",
                "languages": [
                    "ina-Latn",
                    "eng-Latn"
                ],
                "accuracy": 88.7,
                "f1": 86.10809523809525,
                "precision": 85.07602564102565,
                "recall": 88.7,
                "main_score": 86.10809523809525
            },
            {
                "hf_subset": "lfn-eng",
                "languages": [
                    "lfn-Latn",
                    "eng-Latn"
                ],
                "accuracy": 56.99999999999999,
                "f1": 52.85487521402737,
                "precision": 51.53985162713104,
                "recall": 56.99999999999999,
                "main_score": 52.85487521402737
            },
            {
                "hf_subset": "zsm-eng",
                "languages": [
                    "zsm-Latn",
                    "eng-Latn"
                ],
                "accuracy": 94,
                "f1": 92.45333333333333,
                "precision": 91.79166666666667,
                "recall": 94,
                "main_score": 92.45333333333333
            },
            {
                "hf_subset": "ita-eng",
                "languages": [
                    "ita-Latn",
                    "eng-Latn"
                ],
                "accuracy": 92.30000000000001,
                "f1": 90.61333333333333,
                "precision": 89.83333333333331,
                "recall": 92.30000000000001,
                "main_score": 90.61333333333333
            },
            {
                "hf_subset": "cmn-eng",
                "languages": [
                    "cmn-Hans",
                    "eng-Latn"
                ],
                "accuracy": 94.69999999999999,
                "f1": 93.34555555555555,
                "precision": 92.75416666666668,
                "recall": 94.69999999999999,
                "main_score": 93.34555555555555
            },
            {
                "hf_subset": "lvs-eng",
                "languages": [
                    "lvs-Latn",
                    "eng-Latn"
                ],
                "accuracy": 80.2,
                "f1": 76.6563035113035,
                "precision": 75.3014652014652,
                "recall": 80.2,
                "main_score": 76.6563035113035
            },
            {
                "hf_subset": "glg-eng",
                "languages": [
                    "glg-Latn",
                    "eng-Latn"
                ],
                "accuracy": 84.7,
                "f1": 82.78689263765207,
                "precision": 82.06705086580087,
                "recall": 84.7,
                "main_score": 82.78689263765207
            },
            {
                "hf_subset": "ceb-eng",
                "languages": [
                    "ceb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 50.33333333333333,
                "f1": 45.461523661523664,
                "precision": 43.93545574795575,
                "recall": 50.33333333333333,
                "main_score": 45.461523661523664
            },
            {
                "hf_subset": "bre-eng",
                "languages": [
                    "bre-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.6000000000000005,
                "f1": 5.442121400446441,
                "precision": 5.146630385487529,
                "recall": 6.6000000000000005,
                "main_score": 5.442121400446441
            },
            {
                "hf_subset": "ben-eng",
                "languages": [
                    "ben-Beng",
                    "eng-Latn"
                ],
                "accuracy": 85,
                "f1": 81.04666666666667,
                "precision": 79.25,
                "recall": 85,
                "main_score": 81.04666666666667
            },
            {
                "hf_subset": "swg-eng",
                "languages": [
                    "swg-Latn",
                    "eng-Latn"
                ],
                "accuracy": 47.32142857142857,
                "f1": 42.333333333333336,
                "precision": 40.69196428571429,
                "recall": 47.32142857142857,
                "main_score": 42.333333333333336
            },
            {
                "hf_subset": "arq-eng",
                "languages": [
                    "arq-Arab",
                    "eng-Latn"
                ],
                "accuracy": 30.735455543358945,
                "f1": 26.73616790022338,
                "precision": 25.397823220451283,
                "recall": 30.735455543358945,
                "main_score": 26.73616790022338
            },
            {
                "hf_subset": "kab-eng",
                "languages": [
                    "kab-Latn",
                    "eng-Latn"
                ],
                "accuracy": 25.1,
                "f1": 21.975989896371022,
                "precision": 21.059885632257203,
                "recall": 25.1,
                "main_score": 21.975989896371022
            },
            {
                "hf_subset": "fra-eng",
                "languages": [
                    "fra-Latn",
                    "eng-Latn"
                ],
                "accuracy": 94.3,
                "f1": 92.75666666666666,
                "precision": 92.06166666666665,
                "recall": 94.3,
                "main_score": 92.75666666666666
            },
            {
                "hf_subset": "por-eng",
                "languages": [
                    "por-Latn",
                    "eng-Latn"
                ],
                "accuracy": 94.1,
                "f1": 92.74,
                "precision": 92.09166666666667,
                "recall": 94.1,
                "main_score": 92.74
            },
            {
                "hf_subset": "tat-eng",
                "languages": [
                    "tat-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 71.3,
                "f1": 66.922442002442,
                "precision": 65.38249567099568,
                "recall": 71.3,
                "main_score": 66.922442002442
            },
            {
                "hf_subset": "oci-eng",
                "languages": [
                    "oci-Latn",
                    "eng-Latn"
                ],
                "accuracy": 40.300000000000004,
                "f1": 35.78682789299971,
                "precision": 34.66425128716588,
                "recall": 40.300000000000004,
                "main_score": 35.78682789299971
            },
            {
                "hf_subset": "pol-eng",
                "languages": [
                    "pol-Latn",
                    "eng-Latn"
                ],
                "accuracy": 96,
                "f1": 94.82333333333334,
                "precision": 94.27833333333334,
                "recall": 96,
                "main_score": 94.82333333333334
            },
            {
                "hf_subset": "war-eng",
                "languages": [
                    "war-Latn",
                    "eng-Latn"
                ],
                "accuracy": 51.1,
                "f1": 47.179074753133584,
                "precision": 46.06461044702424,
                "recall": 51.1,
                "main_score": 47.179074753133584
            },
            {
                "hf_subset": "aze-eng",
                "languages": [
                    "aze-Latn",
                    "eng-Latn"
                ],
                "accuracy": 87.7,
                "f1": 84.71,
                "precision": 83.46166666666667,
                "recall": 87.7,
                "main_score": 84.71
            },
            {
                "hf_subset": "vie-eng",
                "languages": [
                    "vie-Latn",
                    "eng-Latn"
                ],
                "accuracy": 95.8,
                "f1": 94.68333333333334,
                "precision": 94.13333333333334,
                "recall": 95.8,
                "main_score": 94.68333333333334
            },
            {
                "hf_subset": "nno-eng",
                "languages": [
                    "nno-Latn",
                    "eng-Latn"
                ],
                "accuracy": 85.39999999999999,
                "f1": 82.5577380952381,
                "precision": 81.36833333333334,
                "recall": 85.39999999999999,
                "main_score": 82.5577380952381
            },
            {
                "hf_subset": "cha-eng",
                "languages": [
                    "cha-Latn",
                    "eng-Latn"
                ],
                "accuracy": 21.16788321167883,
                "f1": 16.948865627297987,
                "precision": 15.971932568647897,
                "recall": 21.16788321167883,
                "main_score": 16.948865627297987
            },
            {
                "hf_subset": "mhr-eng",
                "languages": [
                    "mhr-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 6.9,
                "f1": 5.515526831658907,
                "precision": 5.141966366966367,
                "recall": 6.9,
                "main_score": 5.515526831658907
            },
            {
                "hf_subset": "dan-eng",
                "languages": [
                    "dan-Latn",
                    "eng-Latn"
                ],
                "accuracy": 93.2,
                "f1": 91.39666666666668,
                "precision": 90.58666666666667,
                "recall": 93.2,
                "main_score": 91.39666666666668
            },
            {
                "hf_subset": "ell-eng",
                "languages": [
                    "ell-Grek",
                    "eng-Latn"
                ],
                "accuracy": 92.2,
                "f1": 89.95666666666666,
                "precision": 88.92833333333333,
                "recall": 92.2,
                "main_score": 89.95666666666666
            },
            {
                "hf_subset": "amh-eng",
                "languages": [
                    "amh-Ethi",
                    "eng-Latn"
                ],
                "accuracy": 79.76190476190477,
                "f1": 74.93386243386244,
                "precision": 73.11011904761904,
                "recall": 79.76190476190477,
                "main_score": 74.93386243386244
            },
            {
                "hf_subset": "pam-eng",
                "languages": [
                    "pam-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.799999999999999,
                "f1": 6.921439712248537,
                "precision": 6.489885109680683,
                "recall": 8.799999999999999,
                "main_score": 6.921439712248537
            },
            {
                "hf_subset": "hsb-eng",
                "languages": [
                    "hsb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 45.75569358178054,
                "f1": 40.34699501312631,
                "precision": 38.57886764719063,
                "recall": 45.75569358178054,
                "main_score": 40.34699501312631
            },
            {
                "hf_subset": "srp-eng",
                "languages": [
                    "srp-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 91.4,
                "f1": 89.08333333333333,
                "precision": 88.01666666666668,
                "recall": 91.4,
                "main_score": 89.08333333333333
            },
            {
                "hf_subset": "epo-eng",
                "languages": [
                    "epo-Latn",
                    "eng-Latn"
                ],
                "accuracy": 93.60000000000001,
                "f1": 92.06690476190477,
                "precision": 91.45095238095239,
                "recall": 93.60000000000001,
                "main_score": 92.06690476190477
            },
            {
                "hf_subset": "kzj-eng",
                "languages": [
                    "kzj-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.5,
                "f1": 6.200363129378736,
                "precision": 5.89115314822466,
                "recall": 7.5,
                "main_score": 6.200363129378736
            },
            {
                "hf_subset": "awa-eng",
                "languages": [
                    "awa-Deva",
                    "eng-Latn"
                ],
                "accuracy": 73.59307359307358,
                "f1": 68.38933553219267,
                "precision": 66.62698412698413,
                "recall": 73.59307359307358,
                "main_score": 68.38933553219267
            },
            {
                "hf_subset": "fao-eng",
                "languages": [
                    "fao-Latn",
                    "eng-Latn"
                ],
                "accuracy": 69.8473282442748,
                "f1": 64.72373682297346,
                "precision": 62.82834214131924,
                "recall": 69.8473282442748,
                "main_score": 64.72373682297346
            },
            {
                "hf_subset": "mal-eng",
                "languages": [
                    "mal-Mlym",
                    "eng-Latn"
                ],
                "accuracy": 97.5254730713246,
                "f1": 96.72489082969432,
                "precision": 96.33672974284326,
                "recall": 97.5254730713246,
                "main_score": 96.72489082969432
            },
            {
                "hf_subset": "ile-eng",
                "languages": [
                    "ile-Latn",
                    "eng-Latn"
                ],
                "accuracy": 75.6,
                "f1": 72.42746031746033,
                "precision": 71.14036630036631,
                "recall": 75.6,
                "main_score": 72.42746031746033
            },
            {
                "hf_subset": "bos-eng",
                "languages": [
                    "bos-Latn",
                    "eng-Latn"
                ],
                "accuracy": 91.24293785310734,
                "f1": 88.86064030131826,
                "precision": 87.73540489642184,
                "recall": 91.24293785310734,
                "main_score": 88.86064030131826
            },
            {
                "hf_subset": "cor-eng",
                "languages": [
                    "cor-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.2,
                "f1": 4.383083659794954,
                "precision": 4.027861324289673,
                "recall": 6.2,
                "main_score": 4.383083659794954
            },
            {
                "hf_subset": "cat-eng",
                "languages": [
                    "cat-Latn",
                    "eng-Latn"
                ],
                "accuracy": 86.8,
                "f1": 84.09428571428572,
                "precision": 83.00333333333333,
                "recall": 86.8,
                "main_score": 84.09428571428572
            },
            {
                "hf_subset": "eus-eng",
                "languages": [
                    "eus-Latn",
                    "eng-Latn"
                ],
                "accuracy": 60.699999999999996,
                "f1": 56.1584972394755,
                "precision": 54.713456330903135,
                "recall": 60.699999999999996,
                "main_score": 56.1584972394755
            },
            {
                "hf_subset": "yue-eng",
                "languages": [
                    "yue-Hant",
                    "eng-Latn"
                ],
                "accuracy": 84.2,
                "f1": 80.66190476190475,
                "precision": 79.19690476190476,
                "recall": 84.2,
                "main_score": 80.66190476190475
            },
            {
                "hf_subset": "swe-eng",
                "languages": [
                    "swe-Latn",
                    "eng-Latn"
                ],
                "accuracy": 93.2,
                "f1": 91.33,
                "precision": 90.45,
                "recall": 93.2,
                "main_score": 91.33
            },
            {
                "hf_subset": "dtp-eng",
                "languages": [
                    "dtp-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.3,
                "f1": 5.126828976748276,
                "precision": 4.853614328966668,
                "recall": 6.3,
                "main_score": 5.126828976748276
            },
            {
                "hf_subset": "kat-eng",
                "languages": [
                    "kat-Geor",
                    "eng-Latn"
                ],
                "accuracy": 81.76943699731903,
                "f1": 77.82873739308057,
                "precision": 76.27622452019234,
                "recall": 81.76943699731903,
                "main_score": 77.82873739308057
            },
            {
                "hf_subset": "jpn-eng",
                "languages": [
                    "jpn-Jpan",
                    "eng-Latn"
                ],
                "accuracy": 92.30000000000001,
                "f1": 90.29666666666665,
                "precision": 89.40333333333334,
                "recall": 92.30000000000001,
                "main_score": 90.29666666666665
            },
            {
                "hf_subset": "csb-eng",
                "languages": [
                    "csb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 29.249011857707508,
                "f1": 24.561866096392947,
                "precision": 23.356583740215456,
                "recall": 29.249011857707508,
                "main_score": 24.561866096392947
            },
            {
                "hf_subset": "xho-eng",
                "languages": [
                    "xho-Latn",
                    "eng-Latn"
                ],
                "accuracy": 77.46478873239437,
                "f1": 73.23943661971832,
                "precision": 71.66666666666667,
                "recall": 77.46478873239437,
                "main_score": 73.23943661971832
            },
            {
                "hf_subset": "orv-eng",
                "languages": [
                    "orv-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 20.35928143712575,
                "f1": 15.997867865075824,
                "precision": 14.882104658301346,
                "recall": 20.35928143712575,
                "main_score": 15.997867865075824
            },
            {
                "hf_subset": "ind-eng",
                "languages": [
                    "ind-Latn",
                    "eng-Latn"
                ],
                "accuracy": 92.2,
                "f1": 90.25999999999999,
                "precision": 89.45333333333335,
                "recall": 92.2,
                "main_score": 90.25999999999999
            },
            {
                "hf_subset": "tuk-eng",
                "languages": [
                    "tuk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 23.15270935960591,
                "f1": 19.65673625772148,
                "precision": 18.793705293464992,
                "recall": 23.15270935960591,
                "main_score": 19.65673625772148
            },
            {
                "hf_subset": "max-eng",
                "languages": [
                    "max-Deva",
                    "eng-Latn"
                ],
                "accuracy": 59.154929577464785,
                "f1": 52.3868463305083,
                "precision": 50.14938113529662,
                "recall": 59.154929577464785,
                "main_score": 52.3868463305083
            },
            {
                "hf_subset": "swh-eng",
                "languages": [
                    "swh-Latn",
                    "eng-Latn"
                ],
                "accuracy": 70.51282051282051,
                "f1": 66.8089133089133,
                "precision": 65.37645687645687,
                "recall": 70.51282051282051,
                "main_score": 66.8089133089133
            },
            {
                "hf_subset": "hin-eng",
                "languages": [
                    "hin-Deva",
                    "eng-Latn"
                ],
                "accuracy": 94.6,
                "f1": 93,
                "precision": 92.23333333333333,
                "recall": 94.6,
                "main_score": 93
            },
            {
                "hf_subset": "dsb-eng",
                "languages": [
                    "dsb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 38.62212943632568,
                "f1": 34.3278276962583,
                "precision": 33.07646935732408,
                "recall": 38.62212943632568,
                "main_score": 34.3278276962583
            },
            {
                "hf_subset": "ber-eng",
                "languages": [
                    "ber-Tfng",
                    "eng-Latn"
                ],
                "accuracy": 28.1,
                "f1": 23.579609223054604,
                "precision": 22.39622774921555,
                "recall": 28.1,
                "main_score": 23.579609223054604
            },
            {
                "hf_subset": "tam-eng",
                "languages": [
                    "tam-Taml",
                    "eng-Latn"
                ],
                "accuracy": 88.27361563517914,
                "f1": 85.12486427795874,
                "precision": 83.71335504885994,
                "recall": 88.27361563517914,
                "main_score": 85.12486427795874
            },
            {
                "hf_subset": "slk-eng",
                "languages": [
                    "slk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 88.6,
                "f1": 86.39928571428571,
                "precision": 85.4947557997558,
                "recall": 88.6,
                "main_score": 86.39928571428571
            },
            {
                "hf_subset": "tgl-eng",
                "languages": [
                    "tgl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 86.5,
                "f1": 83.77952380952381,
                "precision": 82.67602564102565,
                "recall": 86.5,
                "main_score": 83.77952380952381
            },
            {
                "hf_subset": "ast-eng",
                "languages": [
                    "ast-Latn",
                    "eng-Latn"
                ],
                "accuracy": 79.52755905511812,
                "f1": 75.3055868016498,
                "precision": 73.81889763779527,
                "recall": 79.52755905511812,
                "main_score": 75.3055868016498
            },
            {
                "hf_subset": "mkd-eng",
                "languages": [
                    "mkd-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 77.9,
                "f1": 73.76261904761905,
                "precision": 72.11670995670995,
                "recall": 77.9,
                "main_score": 73.76261904761905
            },
            {
                "hf_subset": "khm-eng",
                "languages": [
                    "khm-Khmr",
                    "eng-Latn"
                ],
                "accuracy": 53.8781163434903,
                "f1": 47.25804051288816,
                "precision": 45.0603482390186,
                "recall": 53.8781163434903,
                "main_score": 47.25804051288816
            },
            {
                "hf_subset": "ces-eng",
                "languages": [
                    "ces-Latn",
                    "eng-Latn"
                ],
                "accuracy": 91.10000000000001,
                "f1": 88.88,
                "precision": 87.96333333333334,
                "recall": 91.10000000000001,
                "main_score": 88.88
            },
            {
                "hf_subset": "tzl-eng",
                "languages": [
                    "tzl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 38.46153846153847,
                "f1": 34.43978243978244,
                "precision": 33.429487179487175,
                "recall": 38.46153846153847,
                "main_score": 34.43978243978244
            },
            {
                "hf_subset": "urd-eng",
                "languages": [
                    "urd-Arab",
                    "eng-Latn"
                ],
                "accuracy": 88.9,
                "f1": 86.19888888888887,
                "precision": 85.07440476190476,
                "recall": 88.9,
                "main_score": 86.19888888888887
            },
            {
                "hf_subset": "ara-eng",
                "languages": [
                    "ara-Arab",
                    "eng-Latn"
                ],
                "accuracy": 85.9,
                "f1": 82.58857142857143,
                "precision": 81.15666666666667,
                "recall": 85.9,
                "main_score": 82.58857142857143
            },
            {
                "hf_subset": "kor-eng",
                "languages": [
                    "kor-Hang",
                    "eng-Latn"
                ],
                "accuracy": 86.8,
                "f1": 83.36999999999999,
                "precision": 81.86833333333333,
                "recall": 86.8,
                "main_score": 83.36999999999999
            },
            {
                "hf_subset": "yid-eng",
                "languages": [
                    "yid-Hebr",
                    "eng-Latn"
                ],
                "accuracy": 68.51415094339622,
                "f1": 63.195000099481234,
                "precision": 61.394033442972116,
                "recall": 68.51415094339622,
                "main_score": 63.195000099481234
            },
            {
                "hf_subset": "fin-eng",
                "languages": [
                    "fin-Latn",
                    "eng-Latn"
                ],
                "accuracy": 88.5,
                "f1": 86.14603174603175,
                "precision": 85.1162037037037,
                "recall": 88.5,
                "main_score": 86.14603174603175
            },
            {
                "hf_subset": "tha-eng",
                "languages": [
                    "tha-Thai",
                    "eng-Latn"
                ],
                "accuracy": 95.62043795620438,
                "f1": 94.40389294403892,
                "precision": 93.7956204379562,
                "recall": 95.62043795620438,
                "main_score": 94.40389294403892
            },
            {
                "hf_subset": "wuu-eng",
                "languages": [
                    "wuu-Hans",
                    "eng-Latn"
                ],
                "accuracy": 81.8,
                "f1": 78.6532178932179,
                "precision": 77.46348795840176,
                "recall": 81.8,
                "main_score": 78.6532178932179
            }
        ]
    }
}