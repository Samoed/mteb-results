{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": -1,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 43.29186281102892,
                "f1": 41.83461350696014,
                "main_score": 43.29186281102892
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 23.214525891055814,
                "f1": 22.364131190189962,
                "main_score": 23.214525891055814
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 53.38264963012777,
                "f1": 50.74546702709091,
                "main_score": 53.38264963012777
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 39.55951580363147,
                "f1": 39.07769075741216,
                "main_score": 39.55951580363147
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 56.73839946200403,
                "f1": 54.36728741542025,
                "main_score": 56.73839946200403
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 39.99663752521857,
                "f1": 38.709817953652596,
                "main_score": 39.99663752521857
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 46.933422999327504,
                "f1": 45.32022679895763,
                "main_score": 46.933422999327504
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 45.820443846671154,
                "f1": 42.853155158197886,
                "main_score": 45.820443846671154
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 37.874915938130464,
                "f1": 35.9849010888881,
                "main_score": 37.874915938130464
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 66.08944182918628,
                "f1": 64.5039080809391,
                "main_score": 66.08944182918628
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 61.17350369872226,
                "f1": 60.0792530132073,
                "main_score": 61.17350369872226
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 45.652320107599195,
                "f1": 44.28182554287625,
                "main_score": 45.652320107599195
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 40.282447881640884,
                "f1": 38.79927524886836,
                "main_score": 40.282447881640884
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 62.60591795561533,
                "f1": 61.01451309609411,
                "main_score": 62.60591795561533
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 32.225958305312716,
                "f1": 30.903299940417906,
                "main_score": 32.225958305312716
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 59.46200403496974,
                "f1": 57.34556231956785,
                "main_score": 59.46200403496974
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 40.907868190988566,
                "f1": 39.74702259997524,
                "main_score": 40.907868190988566
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 29.939475453934094,
                "f1": 28.462353413371353,
                "main_score": 29.939475453934094
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 59.14256893073302,
                "f1": 57.24600767871435,
                "main_score": 59.14256893073302
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 39.620040349697376,
                "f1": 38.414866180464735,
                "main_score": 39.620040349697376
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 51.772024209818426,
                "f1": 51.05050942366993,
                "main_score": 51.772024209818426
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 53.749159381304636,
                "f1": 52.04563008527909,
                "main_score": 53.749159381304636
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 46.29455279085406,
                "f1": 43.84047527739209,
                "main_score": 46.29455279085406
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 25.107599193006045,
                "f1": 24.58731463875415,
                "main_score": 25.107599193006045
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 27.21923335574984,
                "f1": 25.964338481976796,
                "main_score": 27.21923335574984
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 47.96906523201077,
                "f1": 45.32239408435578,
                "main_score": 47.96906523201077
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 40.53799596503026,
                "f1": 39.15655510771227,
                "main_score": 40.53799596503026
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 43.140551445864155,
                "f1": 42.12232733095163,
                "main_score": 43.140551445864155
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 53.69199731002017,
                "f1": 50.67085509122796,
                "main_score": 53.69199731002017
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 33.37256220578346,
                "f1": 33.39335560955231,
                "main_score": 33.37256220578346
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 51.94014794889038,
                "f1": 50.6207021226521,
                "main_score": 51.94014794889038
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 25.322797579018157,
                "f1": 23.94164121951907,
                "main_score": 25.322797579018157
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 44.11903160726294,
                "f1": 43.016752983579536,
                "main_score": 44.11903160726294
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 44.03496973772697,
                "f1": 42.322828283176754,
                "main_score": 44.03496973772697
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 41.63080026899798,
                "f1": 39.58824644978166,
                "main_score": 41.63080026899798
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 61.7350369872226,
                "f1": 59.956752206079386,
                "main_score": 61.7350369872226
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 45.72629455279086,
                "f1": 44.731249269647826,
                "main_score": 45.72629455279086
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 47.61264290517822,
                "f1": 45.5280995218491,
                "main_score": 47.61264290517822
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 42.82784129119032,
                "f1": 41.37165985220223,
                "main_score": 42.82784129119032
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 43.61466039004707,
                "f1": 43.164498227815535,
                "main_score": 43.61466039004707
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 44.64021519838602,
                "f1": 43.04775030948548,
                "main_score": 44.64021519838602
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 45.54808338937458,
                "f1": 44.011677633779975,
                "main_score": 45.54808338937458
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 51.2441156691325,
                "f1": 48.73592932403811,
                "main_score": 51.2441156691325
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 47.43443174176195,
                "f1": 45.08686598891457,
                "main_score": 47.43443174176195
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 36.87962340282448,
                "f1": 36.50540864756967,
                "main_score": 36.87962340282448
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 45.9280430396772,
                "f1": 44.57216865343283,
                "main_score": 45.9280430396772
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 38.591123066577,
                "f1": 37.886312373767446,
                "main_score": 38.591123066577
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 51.85272360457296,
                "f1": 49.43461566216979,
                "main_score": 51.85272360457296
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 58.72225958305313,
                "f1": 56.95500715299434,
                "main_score": 58.72225958305313
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 63.74915938130464,
                "f1": 62.35543158488615,
                "main_score": 63.74915938130464
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 59.95292535305985,
                "f1": 59.73499569346673,
                "main_score": 59.95292535305985
            }
        ]
    }
}