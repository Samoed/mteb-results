{
    "dataset_revision": "7d571f92784cd94a019292a1f45445077d0ef634",
    "task_name": "MassiveScenarioClassification",
    "evaluation_time": -1,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 47.42098184263618,
                "f1": 45.22541854557743,
                "main_score": 47.42098184263618
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 24.707464694014796,
                "f1": 24.033506081882468,
                "main_score": 24.707464694014796
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 62.09145931405515,
                "f1": 62.22048940230962,
                "main_score": 62.09145931405515
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 39.25016812373907,
                "f1": 38.35431952425269,
                "main_score": 39.25016812373907
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 63.37256220578345,
                "f1": 63.12728180326932,
                "main_score": 63.37256220578345
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 39.172831203765966,
                "f1": 37.078841372640234,
                "main_score": 39.172831203765966
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 49.11230665770006,
                "f1": 46.489580286547245,
                "main_score": 49.11230665770006
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 50.7128446536651,
                "f1": 48.27782602378952,
                "main_score": 50.7128446536651
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 39.46536650975118,
                "f1": 37.4365280056047,
                "main_score": 39.46536650975118
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 73.26160053799597,
                "f1": 73.4478249967817,
                "main_score": 73.26160053799597
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 68.31203765971756,
                "f1": 68.70554437788068,
                "main_score": 68.31203765971756
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 45.652320107599195,
                "f1": 44.55357745265521,
                "main_score": 45.652320107599195
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 38.94754539340955,
                "f1": 36.48927336173062,
                "main_score": 38.94754539340955
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 68.69872225958305,
                "f1": 68.81347966311543,
                "main_score": 68.69872225958305
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 32.131809011432416,
                "f1": 30.212230946937474,
                "main_score": 32.131809011432416
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 65.57498318762609,
                "f1": 65.16084751135229,
                "main_score": 65.57498318762609
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 42.965702757229316,
                "f1": 40.575896627739105,
                "main_score": 42.965702757229316
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 32.125084061869536,
                "f1": 30.708056882129476,
                "main_score": 32.125084061869536
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 65.10759919300607,
                "f1": 64.5007800119315,
                "main_score": 65.10759919300607
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 40.83725622057834,
                "f1": 37.855774705520886,
                "main_score": 40.83725622057834
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 54.55279085406859,
                "f1": 52.73318944173822,
                "main_score": 54.55279085406859
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 57.14525891055817,
                "f1": 55.96714177558203,
                "main_score": 57.14525891055817
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 49.30060524546065,
                "f1": 47.82999154670342,
                "main_score": 49.30060524546065
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 25.85743106926698,
                "f1": 24.974946990729716,
                "main_score": 25.85743106926698
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 31.180228648285137,
                "f1": 28.22387838219335,
                "main_score": 31.180228648285137
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 53.00941492938802,
                "f1": 52.39610045092559,
                "main_score": 53.00941492938802
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 40.24546065904505,
                "f1": 38.99779773215032,
                "main_score": 40.24546065904505
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 41.88298587760592,
                "f1": 39.53867071594289,
                "main_score": 41.88298587760592
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 59.078681909885674,
                "f1": 58.47368723772022,
                "main_score": 59.078681909885674
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 33.33893745796907,
                "f1": 32.113466354321226,
                "main_score": 33.33893745796907
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 57.454606590450574,
                "f1": 56.13075383338251,
                "main_score": 57.454606590450574
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 27.19569603227976,
                "f1": 26.300773160344015,
                "main_score": 27.19569603227976
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 46.78547410894418,
                "f1": 44.233771335183015,
                "main_score": 46.78547410894418
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 48.4196368527236,
                "f1": 45.55838648206857,
                "main_score": 48.4196368527236
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 41.63080026899798,
                "f1": 40.77775839499525,
                "main_score": 41.63080026899798
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 66.408876933423,
                "f1": 66.7358693871042,
                "main_score": 66.408876933423
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 50.077336919973106,
                "f1": 48.572749739090014,
                "main_score": 50.077336919973106
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 49.942837928715534,
                "f1": 49.34771836662566,
                "main_score": 49.942837928715534
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 43.43308675184936,
                "f1": 41.818008297000986,
                "main_score": 43.43308675184936
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 44.082044384667114,
                "f1": 43.25002746432129,
                "main_score": 44.082044384667114
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 46.45258910558171,
                "f1": 44.00958237591922,
                "main_score": 46.45258910558171
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 49.53261600537996,
                "f1": 48.01969699634672,
                "main_score": 49.53261600537996
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 56.792199058507066,
                "f1": 56.54421925671813,
                "main_score": 56.792199058507066
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 54.0114324142569,
                "f1": 52.29830350891558,
                "main_score": 54.0114324142569
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 38.584398117014125,
                "f1": 36.551426239639575,
                "main_score": 38.584398117014125
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 48.07330195023538,
                "f1": 46.463553675519975,
                "main_score": 48.07330195023538
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 40.645595158036315,
                "f1": 40.21280676607986,
                "main_score": 40.645595158036315
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 57.74714189643577,
                "f1": 56.8673027258351,
                "main_score": 57.74714189643577
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 65.83389374579693,
                "f1": 66.11273939782248,
                "main_score": 65.83389374579693
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 72.38735709482181,
                "f1": 72.89481650271512,
                "main_score": 72.38735709482181
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 69.63685272360458,
                "f1": 70.72285841806938,
                "main_score": 69.63685272360458
            }
        ]
    }
}