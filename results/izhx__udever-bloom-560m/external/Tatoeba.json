{
    "dataset_revision": "9080400076fbadbb4c4dcb136ff4eddc40b42553",
    "task_name": "Tatoeba",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "sqi-eng",
                "languages": [
                    "sqi-Latn",
                    "eng-Latn"
                ],
                "accuracy": 11.0,
                "f1": 8.487309997179562,
                "precision": 7.935185890268856,
                "recall": 11.0,
                "main_score": 8.487309997179562
            },
            {
                "hf_subset": "fry-eng",
                "languages": [
                    "fry-Latn",
                    "eng-Latn"
                ],
                "accuracy": 23.699421965317917,
                "f1": 18.09982567208001,
                "precision": 16.582017825552963,
                "recall": 23.699421965317917,
                "main_score": 18.09982567208001
            },
            {
                "hf_subset": "kur-eng",
                "languages": [
                    "kur-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.780487804878048,
                "f1": 6.484836753129436,
                "precision": 5.916220801747723,
                "recall": 8.780487804878048,
                "main_score": 6.484836753129436
            },
            {
                "hf_subset": "tur-eng",
                "languages": [
                    "tur-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.0,
                "f1": 3.493223480735001,
                "precision": 3.1492116349139385,
                "recall": 5.0,
                "main_score": 3.493223480735001
            },
            {
                "hf_subset": "deu-eng",
                "languages": [
                    "deu-Latn",
                    "eng-Latn"
                ],
                "accuracy": 33.6,
                "f1": 29.339340352229065,
                "precision": 27.997920626374693,
                "recall": 33.6,
                "main_score": 29.339340352229065
            },
            {
                "hf_subset": "nld-eng",
                "languages": [
                    "nld-Latn",
                    "eng-Latn"
                ],
                "accuracy": 20.200000000000003,
                "f1": 16.330981736231458,
                "precision": 15.250949969794044,
                "recall": 20.200000000000003,
                "main_score": 16.330981736231458
            },
            {
                "hf_subset": "ron-eng",
                "languages": [
                    "ron-Latn",
                    "eng-Latn"
                ],
                "accuracy": 19.6,
                "f1": 14.951120083366323,
                "precision": 13.617335362707001,
                "recall": 19.6,
                "main_score": 14.951120083366323
            },
            {
                "hf_subset": "ang-eng",
                "languages": [
                    "ang-Latn",
                    "eng-Latn"
                ],
                "accuracy": 20.149253731343283,
                "f1": 13.312899786780385,
                "precision": 11.979388770433545,
                "recall": 20.149253731343283,
                "main_score": 13.312899786780385
            },
            {
                "hf_subset": "ido-eng",
                "languages": [
                    "ido-Latn",
                    "eng-Latn"
                ],
                "accuracy": 31.4,
                "f1": 26.21323201417634,
                "precision": 24.607830064672168,
                "recall": 31.4,
                "main_score": 26.21323201417634
            },
            {
                "hf_subset": "jav-eng",
                "languages": [
                    "jav-Latn",
                    "eng-Latn"
                ],
                "accuracy": 18.048780487804876,
                "f1": 14.347798542920492,
                "precision": 13.301672920575362,
                "recall": 18.048780487804876,
                "main_score": 14.347798542920492
            },
            {
                "hf_subset": "isl-eng",
                "languages": [
                    "isl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.2,
                "f1": 3.2713297295122503,
                "precision": 2.978548911585725,
                "recall": 5.2,
                "main_score": 3.2713297295122503
            },
            {
                "hf_subset": "slv-eng",
                "languages": [
                    "slv-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.411907654921021,
                "f1": 5.412915976323278,
                "precision": 4.975402373122839,
                "recall": 7.411907654921021,
                "main_score": 5.412915976323278
            },
            {
                "hf_subset": "cym-eng",
                "languages": [
                    "cym-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.521739130434783,
                "f1": 5.871393789897329,
                "precision": 5.350472658912557,
                "recall": 8.521739130434783,
                "main_score": 5.871393789897329
            },
            {
                "hf_subset": "kaz-eng",
                "languages": [
                    "kaz-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 1.565217391304348,
                "f1": 0.7422394530145001,
                "precision": 0.7201734373569025,
                "recall": 1.565217391304348,
                "main_score": 0.7422394530145001
            },
            {
                "hf_subset": "est-eng",
                "languages": [
                    "est-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.3,
                "f1": 3.0838354401589694,
                "precision": 2.709942839090994,
                "recall": 5.3,
                "main_score": 3.0838354401589694
            },
            {
                "hf_subset": "heb-eng",
                "languages": [
                    "heb-Hebr",
                    "eng-Latn"
                ],
                "accuracy": 0.8,
                "f1": 0.24583802742178057,
                "precision": 0.18710578268453032,
                "recall": 0.8,
                "main_score": 0.24583802742178057
            },
            {
                "hf_subset": "gla-eng",
                "languages": [
                    "gla-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.945717732207479,
                "f1": 2.7266734043909437,
                "precision": 2.3247505400014186,
                "recall": 4.945717732207479,
                "main_score": 2.7266734043909437
            },
            {
                "hf_subset": "mar-eng",
                "languages": [
                    "mar-Deva",
                    "eng-Latn"
                ],
                "accuracy": 54.2,
                "f1": 47.22780366692132,
                "precision": 44.740178571428565,
                "recall": 54.2,
                "main_score": 47.22780366692132
            },
            {
                "hf_subset": "lat-eng",
                "languages": [
                    "lat-Latn",
                    "eng-Latn"
                ],
                "accuracy": 25.8,
                "f1": 19.547406382656526,
                "precision": 17.80766233766234,
                "recall": 25.8,
                "main_score": 19.547406382656526
            },
            {
                "hf_subset": "bel-eng",
                "languages": [
                    "bel-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 4.9,
                "f1": 3.283031457969928,
                "precision": 3.0361515007649467,
                "recall": 4.9,
                "main_score": 3.283031457969928
            },
            {
                "hf_subset": "pms-eng",
                "languages": [
                    "pms-Latn",
                    "eng-Latn"
                ],
                "accuracy": 22.476190476190478,
                "f1": 17.494204011570957,
                "precision": 16.16236240785113,
                "recall": 22.476190476190478,
                "main_score": 17.494204011570957
            },
            {
                "hf_subset": "gle-eng",
                "languages": [
                    "gle-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.3,
                "f1": 3.461898170471662,
                "precision": 2.975546957350575,
                "recall": 6.3,
                "main_score": 3.461898170471662
            },
            {
                "hf_subset": "pes-eng",
                "languages": [
                    "pes-Arab",
                    "eng-Latn"
                ],
                "accuracy": 8.6,
                "f1": 5.874235156578609,
                "precision": 5.201352547725499,
                "recall": 8.6,
                "main_score": 5.874235156578609
            },
            {
                "hf_subset": "nob-eng",
                "languages": [
                    "nob-Latn",
                    "eng-Latn"
                ],
                "accuracy": 15.2,
                "f1": 11.908986787697534,
                "precision": 11.090628985937808,
                "recall": 15.2,
                "main_score": 11.908986787697534
            },
            {
                "hf_subset": "bul-eng",
                "languages": [
                    "bul-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 6.9,
                "f1": 4.58348360335125,
                "precision": 4.183620994869927,
                "recall": 6.9,
                "main_score": 4.58348360335125
            },
            {
                "hf_subset": "cbk-eng",
                "languages": [
                    "cbk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 62.1,
                "f1": 55.70845598845599,
                "precision": 53.22281746031747,
                "recall": 62.1,
                "main_score": 55.70845598845599
            },
            {
                "hf_subset": "hun-eng",
                "languages": [
                    "hun-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.8,
                "f1": 3.246932234432234,
                "precision": 2.9738765839703265,
                "recall": 4.8,
                "main_score": 3.246932234432234
            },
            {
                "hf_subset": "uig-eng",
                "languages": [
                    "uig-Arab",
                    "eng-Latn"
                ],
                "accuracy": 0.8999999999999999,
                "f1": 0.5331481481481481,
                "precision": 0.4918990604783396,
                "recall": 0.8999999999999999,
                "main_score": 0.5331481481481481
            },
            {
                "hf_subset": "rus-eng",
                "languages": [
                    "rus-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 31.7,
                "f1": 25.22406237037816,
                "precision": 23.27273155929038,
                "recall": 31.7,
                "main_score": 25.22406237037816
            },
            {
                "hf_subset": "spa-eng",
                "languages": [
                    "spa-Latn",
                    "eng-Latn"
                ],
                "accuracy": 96.5,
                "f1": 95.48333333333333,
                "precision": 95.0,
                "recall": 96.5,
                "main_score": 95.48333333333333
            },
            {
                "hf_subset": "hye-eng",
                "languages": [
                    "hye-Armn",
                    "eng-Latn"
                ],
                "accuracy": 0.40431266846361186,
                "f1": 0.22521185350542844,
                "precision": 0.20245384171411912,
                "recall": 0.40431266846361186,
                "main_score": 0.22521185350542844
            },
            {
                "hf_subset": "tel-eng",
                "languages": [
                    "tel-Telu",
                    "eng-Latn"
                ],
                "accuracy": 43.162393162393165,
                "f1": 35.83662064431295,
                "precision": 33.66590199923534,
                "recall": 43.162393162393165,
                "main_score": 35.83662064431295
            },
            {
                "hf_subset": "afr-eng",
                "languages": [
                    "afr-Latn",
                    "eng-Latn"
                ],
                "accuracy": 12.2,
                "f1": 9.007009351120605,
                "precision": 8.26509907921979,
                "recall": 12.2,
                "main_score": 9.007009351120605
            },
            {
                "hf_subset": "mon-eng",
                "languages": [
                    "mon-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 2.0454545454545454,
                "f1": 0.846869670733307,
                "precision": 0.719285857023819,
                "recall": 2.0454545454545454,
                "main_score": 0.846869670733307
            },
            {
                "hf_subset": "arz-eng",
                "languages": [
                    "arz-Arab",
                    "eng-Latn"
                ],
                "accuracy": 56.18448637316562,
                "f1": 49.41850369523325,
                "precision": 46.84486373165618,
                "recall": 56.18448637316562,
                "main_score": 49.41850369523325
            },
            {
                "hf_subset": "hrv-eng",
                "languages": [
                    "hrv-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.4,
                "f1": 6.274306734742452,
                "precision": 5.854786915151029,
                "recall": 8.4,
                "main_score": 6.274306734742452
            },
            {
                "hf_subset": "nov-eng",
                "languages": [
                    "nov-Latn",
                    "eng-Latn"
                ],
                "accuracy": 45.13618677042802,
                "f1": 38.784818726452976,
                "precision": 36.65848310789945,
                "recall": 45.13618677042802,
                "main_score": 38.784818726452976
            },
            {
                "hf_subset": "gsw-eng",
                "languages": [
                    "gsw-Latn",
                    "eng-Latn"
                ],
                "accuracy": 23.076923076923077,
                "f1": 17.501757501757503,
                "precision": 16.06289721674337,
                "recall": 23.076923076923077,
                "main_score": 17.501757501757503
            },
            {
                "hf_subset": "nds-eng",
                "languages": [
                    "nds-Latn",
                    "eng-Latn"
                ],
                "accuracy": 15.8,
                "f1": 11.834682187321722,
                "precision": 10.871016304088595,
                "recall": 15.8,
                "main_score": 11.834682187321722
            },
            {
                "hf_subset": "ukr-eng",
                "languages": [
                    "ukr-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 7.3,
                "f1": 4.929314970921539,
                "precision": 4.427714750128542,
                "recall": 7.3,
                "main_score": 4.929314970921539
            },
            {
                "hf_subset": "uzb-eng",
                "languages": [
                    "uzb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.14018691588785,
                "f1": 2.543797914741945,
                "precision": 2.1476927403586066,
                "recall": 5.14018691588785,
                "main_score": 2.543797914741945
            },
            {
                "hf_subset": "lit-eng",
                "languages": [
                    "lit-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.0,
                "f1": 3.173243817101591,
                "precision": 2.8643206769285485,
                "recall": 5.0,
                "main_score": 3.173243817101591
            },
            {
                "hf_subset": "ina-eng",
                "languages": [
                    "ina-Latn",
                    "eng-Latn"
                ],
                "accuracy": 69.5,
                "f1": 63.89614902641219,
                "precision": 61.628650793650785,
                "recall": 69.5,
                "main_score": 63.89614902641219
            },
            {
                "hf_subset": "lfn-eng",
                "languages": [
                    "lfn-Latn",
                    "eng-Latn"
                ],
                "accuracy": 41.8,
                "f1": 37.523909714712914,
                "precision": 36.054581750900766,
                "recall": 41.8,
                "main_score": 37.523909714712914
            },
            {
                "hf_subset": "zsm-eng",
                "languages": [
                    "zsm-Latn",
                    "eng-Latn"
                ],
                "accuracy": 79.2,
                "f1": 74.88805555555554,
                "precision": 73.05083333333333,
                "recall": 79.2,
                "main_score": 74.88805555555554
            },
            {
                "hf_subset": "ita-eng",
                "languages": [
                    "ita-Latn",
                    "eng-Latn"
                ],
                "accuracy": 43.5,
                "f1": 37.28660019590605,
                "precision": 35.18067447433519,
                "recall": 43.5,
                "main_score": 37.28660019590605
            },
            {
                "hf_subset": "cmn-eng",
                "languages": [
                    "cmn-Hans",
                    "eng-Latn"
                ],
                "accuracy": 94.5,
                "f1": 92.95,
                "precision": 92.2,
                "recall": 94.5,
                "main_score": 92.95
            },
            {
                "hf_subset": "lvs-eng",
                "languages": [
                    "lvs-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.2,
                "f1": 3.5297755651484026,
                "precision": 3.190013722690584,
                "recall": 5.2,
                "main_score": 3.5297755651484026
            },
            {
                "hf_subset": "glg-eng",
                "languages": [
                    "glg-Latn",
                    "eng-Latn"
                ],
                "accuracy": 74.7,
                "f1": 69.2602380952381,
                "precision": 67.03261904761905,
                "recall": 74.7,
                "main_score": 69.2602380952381
            },
            {
                "hf_subset": "ceb-eng",
                "languages": [
                    "ceb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.0,
                "f1": 5.639611303143687,
                "precision": 5.209856824277429,
                "recall": 8.0,
                "main_score": 5.639611303143687
            },
            {
                "hf_subset": "bre-eng",
                "languages": [
                    "bre-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.1,
                "f1": 3.847611167634209,
                "precision": 3.3324923687423693,
                "recall": 6.1,
                "main_score": 3.847611167634209
            },
            {
                "hf_subset": "ben-eng",
                "languages": [
                    "ben-Beng",
                    "eng-Latn"
                ],
                "accuracy": 75.5,
                "f1": 70.14214285714286,
                "precision": 67.88761904761904,
                "recall": 75.5,
                "main_score": 70.14214285714286
            },
            {
                "hf_subset": "swg-eng",
                "languages": [
                    "swg-Latn",
                    "eng-Latn"
                ],
                "accuracy": 20.535714285714285,
                "f1": 16.437074829931973,
                "precision": 15.459837781266353,
                "recall": 20.535714285714285,
                "main_score": 16.437074829931973
            },
            {
                "hf_subset": "arq-eng",
                "languages": [
                    "arq-Arab",
                    "eng-Latn"
                ],
                "accuracy": 21.405049396267835,
                "f1": 16.162968480476714,
                "precision": 14.506603642481391,
                "recall": 21.405049396267835,
                "main_score": 16.162968480476714
            },
            {
                "hf_subset": "kab-eng",
                "languages": [
                    "kab-Latn",
                    "eng-Latn"
                ],
                "accuracy": 1.4000000000000001,
                "f1": 0.8861559696342305,
                "precision": 0.7898232323232323,
                "recall": 1.4000000000000001,
                "main_score": 0.8861559696342305
            },
            {
                "hf_subset": "fra-eng",
                "languages": [
                    "fra-Latn",
                    "eng-Latn"
                ],
                "accuracy": 93.5,
                "f1": 91.65333333333334,
                "precision": 90.80833333333332,
                "recall": 93.5,
                "main_score": 91.65333333333334
            },
            {
                "hf_subset": "por-eng",
                "languages": [
                    "por-Latn",
                    "eng-Latn"
                ],
                "accuracy": 93.8,
                "f1": 92.08333333333333,
                "precision": 91.23333333333333,
                "recall": 93.8,
                "main_score": 92.08333333333333
            },
            {
                "hf_subset": "tat-eng",
                "languages": [
                    "tat-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 1.3,
                "f1": 0.9654912597950575,
                "precision": 0.911237853823405,
                "recall": 1.3,
                "main_score": 0.9654912597950575
            },
            {
                "hf_subset": "oci-eng",
                "languages": [
                    "oci-Latn",
                    "eng-Latn"
                ],
                "accuracy": 35.5,
                "f1": 29.385868020868024,
                "precision": 27.38218614718615,
                "recall": 35.5,
                "main_score": 29.385868020868024
            },
            {
                "hf_subset": "pol-eng",
                "languages": [
                    "pol-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.3,
                "f1": 5.625495291471218,
                "precision": 5.006352187769519,
                "recall": 8.3,
                "main_score": 5.625495291471218
            },
            {
                "hf_subset": "war-eng",
                "languages": [
                    "war-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.3,
                "f1": 7.188871139201601,
                "precision": 6.68110313042221,
                "recall": 9.3,
                "main_score": 7.188871139201601
            },
            {
                "hf_subset": "aze-eng",
                "languages": [
                    "aze-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.9,
                "f1": 3.4368196711816386,
                "precision": 3.1516575755476186,
                "recall": 4.9,
                "main_score": 3.4368196711816386
            },
            {
                "hf_subset": "vie-eng",
                "languages": [
                    "vie-Latn",
                    "eng-Latn"
                ],
                "accuracy": 94.5,
                "f1": 92.85666666666667,
                "precision": 92.07499999999999,
                "recall": 94.5,
                "main_score": 92.85666666666667
            },
            {
                "hf_subset": "nno-eng",
                "languages": [
                    "nno-Latn",
                    "eng-Latn"
                ],
                "accuracy": 10.9,
                "f1": 8.052880589619718,
                "precision": 7.2833020438680816,
                "recall": 10.9,
                "main_score": 8.052880589619718
            },
            {
                "hf_subset": "cha-eng",
                "languages": [
                    "cha-Latn",
                    "eng-Latn"
                ],
                "accuracy": 21.897810218978105,
                "f1": 16.459096459096457,
                "precision": 14.99391727493917,
                "recall": 21.897810218978105,
                "main_score": 16.459096459096457
            },
            {
                "hf_subset": "mhr-eng",
                "languages": [
                    "mhr-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 0.8,
                "f1": 0.43900258600589265,
                "precision": 0.42151473277789064,
                "recall": 0.8,
                "main_score": 0.43900258600589265
            },
            {
                "hf_subset": "dan-eng",
                "languages": [
                    "dan-Latn",
                    "eng-Latn"
                ],
                "accuracy": 14.899999999999999,
                "f1": 11.403181682754628,
                "precision": 10.506373051667312,
                "recall": 14.899999999999999,
                "main_score": 11.403181682754628
            },
            {
                "hf_subset": "ell-eng",
                "languages": [
                    "ell-Grek",
                    "eng-Latn"
                ],
                "accuracy": 1.9,
                "f1": 0.8872641689515834,
                "precision": 0.7857231069685399,
                "recall": 1.9,
                "main_score": 0.8872641689515834
            },
            {
                "hf_subset": "amh-eng",
                "languages": [
                    "amh-Ethi",
                    "eng-Latn"
                ],
                "accuracy": 1.1904761904761905,
                "f1": 0.20847048496818082,
                "precision": 0.11904761904761904,
                "recall": 1.1904761904761905,
                "main_score": 0.20847048496818082
            },
            {
                "hf_subset": "pam-eng",
                "languages": [
                    "pam-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.3,
                "f1": 3.784571880595977,
                "precision": 3.4556477020719782,
                "recall": 5.3,
                "main_score": 3.784571880595977
            },
            {
                "hf_subset": "hsb-eng",
                "languages": [
                    "hsb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.316770186335404,
                "f1": 6.80343720685027,
                "precision": 6.316650292717499,
                "recall": 9.316770186335404,
                "main_score": 6.80343720685027
            },
            {
                "hf_subset": "srp-eng",
                "languages": [
                    "srp-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 5.8999999999999995,
                "f1": 4.5486926228313695,
                "precision": 4.311121913612427,
                "recall": 5.8999999999999995,
                "main_score": 4.5486926228313695
            },
            {
                "hf_subset": "epo-eng",
                "languages": [
                    "epo-Latn",
                    "eng-Latn"
                ],
                "accuracy": 18.099999999999998,
                "f1": 13.4170874831821,
                "precision": 12.178193046524806,
                "recall": 18.099999999999998,
                "main_score": 13.4170874831821
            },
            {
                "hf_subset": "kzj-eng",
                "languages": [
                    "kzj-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.3999999999999995,
                "f1": 3.3905735425765524,
                "precision": 3.2588935800436625,
                "recall": 4.3999999999999995,
                "main_score": 3.3905735425765524
            },
            {
                "hf_subset": "awa-eng",
                "languages": [
                    "awa-Deva",
                    "eng-Latn"
                ],
                "accuracy": 37.66233766233766,
                "f1": 30.539579468150897,
                "precision": 28.60288100547841,
                "recall": 37.66233766233766,
                "main_score": 30.539579468150897
            },
            {
                "hf_subset": "fao-eng",
                "languages": [
                    "fao-Latn",
                    "eng-Latn"
                ],
                "accuracy": 12.213740458015266,
                "f1": 8.297822182308039,
                "precision": 7.463649581970193,
                "recall": 12.213740458015266,
                "main_score": 8.297822182308039
            },
            {
                "hf_subset": "mal-eng",
                "languages": [
                    "mal-Mlym",
                    "eng-Latn"
                ],
                "accuracy": 78.31149927219796,
                "f1": 73.35759340126152,
                "precision": 71.26394953905871,
                "recall": 78.31149927219796,
                "main_score": 73.35759340126152
            },
            {
                "hf_subset": "ile-eng",
                "languages": [
                    "ile-Latn",
                    "eng-Latn"
                ],
                "accuracy": 51.800000000000004,
                "f1": 44.24010323010323,
                "precision": 41.450707972582975,
                "recall": 51.800000000000004,
                "main_score": 44.24010323010323
            },
            {
                "hf_subset": "bos-eng",
                "languages": [
                    "bos-Latn",
                    "eng-Latn"
                ],
                "accuracy": 13.27683615819209,
                "f1": 9.167320569156727,
                "precision": 8.200402665583079,
                "recall": 13.27683615819209,
                "main_score": 9.167320569156727
            },
            {
                "hf_subset": "cor-eng",
                "languages": [
                    "cor-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.8,
                "f1": 3.1268763352790283,
                "precision": 2.84393718699601,
                "recall": 4.8,
                "main_score": 3.1268763352790283
            },
            {
                "hf_subset": "cat-eng",
                "languages": [
                    "cat-Latn",
                    "eng-Latn"
                ],
                "accuracy": 85.1,
                "f1": 81.55,
                "precision": 79.98166666666665,
                "recall": 85.1,
                "main_score": 81.55
            },
            {
                "hf_subset": "eus-eng",
                "languages": [
                    "eus-Latn",
                    "eng-Latn"
                ],
                "accuracy": 48.3,
                "f1": 42.347894491129786,
                "precision": 40.36040404040404,
                "recall": 48.3,
                "main_score": 42.347894491129786
            },
            {
                "hf_subset": "yue-eng",
                "languages": [
                    "yue-Hant",
                    "eng-Latn"
                ],
                "accuracy": 78.8,
                "f1": 74.35484848484847,
                "precision": 72.43277777777777,
                "recall": 78.8,
                "main_score": 74.35484848484847
            },
            {
                "hf_subset": "swe-eng",
                "languages": [
                    "swe-Latn",
                    "eng-Latn"
                ],
                "accuracy": 13.900000000000002,
                "f1": 10.718252991153888,
                "precision": 9.835761434404196,
                "recall": 13.900000000000002,
                "main_score": 10.718252991153888
            },
            {
                "hf_subset": "dtp-eng",
                "languages": [
                    "dtp-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.9,
                "f1": 3.371714825002496,
                "precision": 3.085928254003479,
                "recall": 4.9,
                "main_score": 3.371714825002496
            },
            {
                "hf_subset": "kat-eng",
                "languages": [
                    "kat-Geor",
                    "eng-Latn"
                ],
                "accuracy": 0.5361930294906166,
                "f1": 0.40389703692021933,
                "precision": 0.40302666854804575,
                "recall": 0.5361930294906166,
                "main_score": 0.40389703692021933
            },
            {
                "hf_subset": "jpn-eng",
                "languages": [
                    "jpn-Jpan",
                    "eng-Latn"
                ],
                "accuracy": 55.300000000000004,
                "f1": 48.83353113553113,
                "precision": 46.48630659536542,
                "recall": 55.300000000000004,
                "main_score": 48.83353113553113
            },
            {
                "hf_subset": "csb-eng",
                "languages": [
                    "csb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.300395256916996,
                "f1": 5.261552988548536,
                "precision": 4.724388115499655,
                "recall": 8.300395256916996,
                "main_score": 5.261552988548536
            },
            {
                "hf_subset": "xho-eng",
                "languages": [
                    "xho-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.450704225352112,
                "f1": 4.829974470478787,
                "precision": 4.337585798478816,
                "recall": 8.450704225352112,
                "main_score": 4.829974470478787
            },
            {
                "hf_subset": "orv-eng",
                "languages": [
                    "orv-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 1.0778443113772456,
                "f1": 0.5373251562068135,
                "precision": 0.5107640721914694,
                "recall": 1.0778443113772456,
                "main_score": 0.5373251562068135
            },
            {
                "hf_subset": "ind-eng",
                "languages": [
                    "ind-Latn",
                    "eng-Latn"
                ],
                "accuracy": 88.5,
                "f1": 85.46333333333334,
                "precision": 84.1,
                "recall": 88.5,
                "main_score": 85.46333333333334
            },
            {
                "hf_subset": "tuk-eng",
                "languages": [
                    "tuk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.41871921182266,
                "f1": 2.8063639248802965,
                "precision": 2.2699550039451513,
                "recall": 5.41871921182266,
                "main_score": 2.8063639248802965
            },
            {
                "hf_subset": "max-eng",
                "languages": [
                    "max-Deva",
                    "eng-Latn"
                ],
                "accuracy": 40.49295774647887,
                "f1": 33.455454951933824,
                "precision": 31.4339393461183,
                "recall": 40.49295774647887,
                "main_score": 33.455454951933824
            },
            {
                "hf_subset": "swh-eng",
                "languages": [
                    "swh-Latn",
                    "eng-Latn"
                ],
                "accuracy": 18.974358974358974,
                "f1": 14.517578026097205,
                "precision": 13.3510327465177,
                "recall": 18.974358974358974,
                "main_score": 14.517578026097205
            },
            {
                "hf_subset": "hin-eng",
                "languages": [
                    "hin-Deva",
                    "eng-Latn"
                ],
                "accuracy": 88.5,
                "f1": 85.34666666666666,
                "precision": 83.89999999999999,
                "recall": 88.5,
                "main_score": 85.34666666666666
            },
            {
                "hf_subset": "dsb-eng",
                "languages": [
                    "dsb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.1419624217119,
                "f1": 5.830783012763732,
                "precision": 5.4408714223116545,
                "recall": 8.1419624217119,
                "main_score": 5.830783012763732
            },
            {
                "hf_subset": "ber-eng",
                "languages": [
                    "ber-Tfng",
                    "eng-Latn"
                ],
                "accuracy": 5.800000000000001,
                "f1": 3.9245687335866406,
                "precision": 3.5535667824951584,
                "recall": 5.800000000000001,
                "main_score": 3.9245687335866406
            },
            {
                "hf_subset": "tam-eng",
                "languages": [
                    "tam-Taml",
                    "eng-Latn"
                ],
                "accuracy": 68.40390879478826,
                "f1": 62.25738069386277,
                "precision": 60.10935318752908,
                "recall": 68.40390879478826,
                "main_score": 62.25738069386277
            },
            {
                "hf_subset": "slk-eng",
                "languages": [
                    "slk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.1,
                "f1": 5.4876787833762135,
                "precision": 5.126663482701374,
                "recall": 7.1,
                "main_score": 5.4876787833762135
            },
            {
                "hf_subset": "tgl-eng",
                "languages": [
                    "tgl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.9,
                "f1": 6.519531004112515,
                "precision": 5.987707404636394,
                "recall": 8.9,
                "main_score": 6.519531004112515
            },
            {
                "hf_subset": "ast-eng",
                "languages": [
                    "ast-Latn",
                    "eng-Latn"
                ],
                "accuracy": 66.92913385826772,
                "f1": 59.96062992125984,
                "precision": 57.13348331458567,
                "recall": 66.92913385826772,
                "main_score": 59.96062992125984
            },
            {
                "hf_subset": "mkd-eng",
                "languages": [
                    "mkd-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 4.3,
                "f1": 2.765805343607201,
                "precision": 2.5247851243177144,
                "recall": 4.3,
                "main_score": 2.765805343607201
            },
            {
                "hf_subset": "khm-eng",
                "languages": [
                    "khm-Khmr",
                    "eng-Latn"
                ],
                "accuracy": 0.41551246537396125,
                "f1": 0.1497838495760933,
                "precision": 0.14429034844729552,
                "recall": 0.41551246537396125,
                "main_score": 0.1497838495760933
            },
            {
                "hf_subset": "ces-eng",
                "languages": [
                    "ces-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.800000000000001,
                "f1": 3.761224995516873,
                "precision": 3.2689210175496086,
                "recall": 5.800000000000001,
                "main_score": 3.761224995516873
            },
            {
                "hf_subset": "tzl-eng",
                "languages": [
                    "tzl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 16.346153846153847,
                "f1": 14.524291497975709,
                "precision": 13.995726495726496,
                "recall": 16.346153846153847,
                "main_score": 14.524291497975709
            },
            {
                "hf_subset": "urd-eng",
                "languages": [
                    "urd-Arab",
                    "eng-Latn"
                ],
                "accuracy": 67.80000000000001,
                "f1": 61.615800865800864,
                "precision": 59.12333333333334,
                "recall": 67.80000000000001,
                "main_score": 61.615800865800864
            },
            {
                "hf_subset": "ara-eng",
                "languages": [
                    "ara-Arab",
                    "eng-Latn"
                ],
                "accuracy": 83.8,
                "f1": 80.08857142857143,
                "precision": 78.46666666666667,
                "recall": 83.8,
                "main_score": 80.08857142857143
            },
            {
                "hf_subset": "kor-eng",
                "languages": [
                    "kor-Hang",
                    "eng-Latn"
                ],
                "accuracy": 4.2,
                "f1": 2.6507751588440254,
                "precision": 2.335273168189835,
                "recall": 4.2,
                "main_score": 2.6507751588440254
            },
            {
                "hf_subset": "yid-eng",
                "languages": [
                    "yid-Hebr",
                    "eng-Latn"
                ],
                "accuracy": 0.4716981132075472,
                "f1": 0.19293763102725367,
                "precision": 0.1622040325564188,
                "recall": 0.4716981132075472,
                "main_score": 0.19293763102725367
            },
            {
                "hf_subset": "fin-eng",
                "languages": [
                    "fin-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.9,
                "f1": 3.5001791555125235,
                "precision": 3.277940522301425,
                "recall": 4.9,
                "main_score": 3.5001791555125235
            },
            {
                "hf_subset": "tha-eng",
                "languages": [
                    "tha-Thai",
                    "eng-Latn"
                ],
                "accuracy": 0.9124087591240875,
                "f1": 0.5083420229405631,
                "precision": 0.4674562188049969,
                "recall": 0.9124087591240875,
                "main_score": 0.5083420229405631
            },
            {
                "hf_subset": "wuu-eng",
                "languages": [
                    "wuu-Hans",
                    "eng-Latn"
                ],
                "accuracy": 79.4,
                "f1": 74.62333333333333,
                "precision": 72.52333333333334,
                "recall": 79.4,
                "main_score": 74.62333333333333
            }
        ]
    }
}