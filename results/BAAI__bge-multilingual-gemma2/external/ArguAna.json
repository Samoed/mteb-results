{
    "dataset_revision": "c22ab2a51041ffd869aaddef7af8d8215647e41a",
    "task_name": "ArguAna",
    "evaluation_time": NaN,
    "mteb_version": "unknown",
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "main_score": 77.36555747844541,
                "ndcg_at_1": 57.681365576102415,
                "ndcg_at_3": 72.01664798084765,
                "ndcg_at_5": 75.26345973082836,
                "ndcg_at_10": 77.36555747844541,
                "ndcg_at_100": 78.15567833673768,
                "ndcg_at_1000": 78.16528851292641,
                "map_at_1": 57.681365576102415,
                "map_at_3": 68.59886201991475,
                "map_at_5": 70.38051209103858,
                "map_at_10": 71.26684955632336,
                "map_at_100": 71.4637216600468,
                "map_at_1000": 71.46414501573332,
                "precision_at_1": 57.681365576102415,
                "precision_at_3": 27.287814129919084,
                "precision_at_5": 17.965860597439132,
                "precision_at_10": 9.623044096728066,
                "precision_at_100": 0.995732574679925,
                "precision_at_1000": 0.09964438122332549,
                "recall_at_1": 57.681365576102415,
                "recall_at_3": 81.86344238975818,
                "recall_at_5": 89.82930298719772,
                "recall_at_10": 96.23044096728307,
                "recall_at_100": 99.57325746799431,
                "recall_at_1000": 99.6443812233286
            }
        ]
    }
}