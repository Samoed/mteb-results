{
    "dataset_revision": "7d571f92784cd94a019292a1f45445077d0ef634",
    "task_name": "MassiveScenarioClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 84.40147948890383,
                "accuracy_stderr": 1.2939587629143627,
                "f1": 83.97779287582267,
                "f1_stderr": 0.9970599222060901,
                "main_score": 84.40147948890383
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 82.58238063214526,
                "accuracy_stderr": 1.0999970213165273,
                "f1": 81.94734854057064,
                "f1_stderr": 1.248633855872851,
                "main_score": 82.58238063214526
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 82.182246133154,
                "f1": 81.68006668655397,
                "f1_weighted": 81.94775072858566,
                "main_score": 82.182246133154
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 81.9334229993275,
                "f1": 81.40628785444537,
                "f1_weighted": 81.79807477693303,
                "main_score": 81.9334229993275
            }
        ]
    }
}