{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": NaN,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 47.59919300605245,
                "f1": 44.27505749600044,
                "main_score": 47.59919300605245
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 31.56691324815064,
                "f1": 30.34952276390722,
                "main_score": 31.56691324815064
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 52.62945527908541,
                "f1": 49.689536347222386,
                "main_score": 52.62945527908541
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 50.0941492938803,
                "f1": 48.47831879848094,
                "main_score": 50.0941492938803
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 46.540013449899135,
                "f1": 44.25663324630171,
                "main_score": 46.540013449899135
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 44.25689307330195,
                "f1": 42.06066077477426,
                "main_score": 44.25689307330195
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 55.05716207128446,
                "f1": 52.41516089202158,
                "main_score": 55.05716207128446
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 61.86953597848015,
                "f1": 58.45989820228606,
                "main_score": 61.86953597848015
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 47.02084734364493,
                "f1": 45.21525882986924,
                "main_score": 47.02084734364493
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 69.24008069939475,
                "f1": 68.27971089998472,
                "main_score": 69.24008069939475
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 62.53530598520511,
                "f1": 61.83588971206536,
                "main_score": 62.53530598520511
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 55.19166106254204,
                "f1": 52.335787325774,
                "main_score": 55.19166106254204
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 48.43308675184936,
                "f1": 45.841102061239184,
                "main_score": 48.43308675184936
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 64.26698049764627,
                "f1": 62.25607481996241,
                "main_score": 64.26698049764627
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 57.619367854741085,
                "f1": 54.93671211092237,
                "main_score": 57.619367854741085
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 57.53530598520511,
                "f1": 55.36413211751344,
                "main_score": 57.53530598520511
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 45.66913248150638,
                "f1": 42.52092657926257,
                "main_score": 45.66913248150638
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 39.19973100201749,
                "f1": 37.194613407773566,
                "main_score": 39.19973100201749
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 54.99663752521856,
                "f1": 53.875181150315356,
                "main_score": 54.99663752521856
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 43.143913920645595,
                "f1": 41.756257561394456,
                "main_score": 43.143913920645595
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 60.99529253530599,
                "f1": 59.103812128183705,
                "main_score": 60.99529253530599
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 64.29051782111634,
                "f1": 62.5268914542489,
                "main_score": 64.29051782111634
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 43.69199731002017,
                "f1": 41.71651113018154,
                "main_score": 43.69199731002017
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 38.34566240753194,
                "f1": 36.935911015227894,
                "main_score": 38.34566240753194
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 34.21654337592467,
                "f1": 32.067289455027755,
                "main_score": 34.21654337592467
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 51.785474108944186,
                "f1": 49.29285691779668,
                "main_score": 51.785474108944186
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 59.58977807666444,
                "f1": 57.81630371862734,
                "main_score": 59.58977807666444
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 46.53665097511768,
                "f1": 44.8386852929464,
                "main_score": 46.53665097511768
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 54.468728984532625,
                "f1": 52.13613631138983,
                "main_score": 54.468728984532625
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 40.67921990585071,
                "f1": 39.87218130311539,
                "main_score": 40.67921990585071
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 51.2441156691325,
                "f1": 48.93351041227674,
                "main_score": 51.2441156691325
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 31.76193678547411,
                "f1": 29.917012787908785,
                "main_score": 31.76193678547411
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 54.40820443846671,
                "f1": 51.232049156874396,
                "main_score": 54.40820443846671
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 60.8170813718897,
                "f1": 57.74887572270486,
                "main_score": 60.8170813718897
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 60.067249495628786,
                "f1": 57.60151669462318,
                "main_score": 60.067249495628786
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 62.73705447209146,
                "f1": 61.14377989075874,
                "main_score": 62.73705447209146
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 49.68392737054472,
                "f1": 48.07062918679129,
                "main_score": 49.68392737054472
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 60.85406859448555,
                "f1": 58.48852652838252,
                "main_score": 60.85406859448555
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 48.58776059179556,
                "f1": 46.92163099241966,
                "main_score": 48.58776059179556
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 47.16879623402824,
                "f1": 45.8155066134247,
                "main_score": 47.16879623402824
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 62.41425689307329,
                "f1": 60.097954878192574,
                "main_score": 62.41425689307329
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 45.97175521183591,
                "f1": 44.29275283000346,
                "main_score": 45.97175521183591
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 53.597848016139885,
                "f1": 51.54318966923094,
                "main_score": 53.597848016139885
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 53.44653665097512,
                "f1": 51.60095623356469,
                "main_score": 53.44653665097512
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 46.173503698722264,
                "f1": 46.311285276929105,
                "main_score": 46.173503698722264
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 49.47881640887693,
                "f1": 46.63989802589145,
                "main_score": 49.47881640887693
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 58.02958977807666,
                "f1": 55.34728796730868,
                "main_score": 58.02958977807666
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 39.26361802286483,
                "f1": 37.61201358829197,
                "main_score": 39.26361802286483
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 52.15534633490249,
                "f1": 50.438951980623145,
                "main_score": 52.15534633490249
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 63.39946200403498,
                "f1": 62.152249150179664,
                "main_score": 63.39946200403498
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 58.207800941492934,
                "f1": 58.318584465398104,
                "main_score": 58.207800941492934
            }
        ]
    }
}