{
    "dataset_revision": "9080400076fbadbb4c4dcb136ff4eddc40b42553",
    "task_name": "Tatoeba",
    "evaluation_time": -1,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "sqi-eng",
                "languages": [
                    "sqi-Latn",
                    "eng-Latn"
                ],
                "accuracy": 19.400000000000002,
                "f1": 15.386076064970075,
                "precision": 14.253878834615676,
                "recall": 19.400000000000002,
                "main_score": 15.386076064970075
            },
            {
                "hf_subset": "fry-eng",
                "languages": [
                    "fry-Latn",
                    "eng-Latn"
                ],
                "accuracy": 42.19653179190752,
                "f1": 37.726396917148364,
                "precision": 36.14643545279384,
                "recall": 42.19653179190752,
                "main_score": 37.726396917148364
            },
            {
                "hf_subset": "kur-eng",
                "languages": [
                    "kur-Latn",
                    "eng-Latn"
                ],
                "accuracy": 18.536585365853657,
                "f1": 13.512010347376199,
                "precision": 12.034068912117693,
                "recall": 18.536585365853657,
                "main_score": 13.512010347376199
            },
            {
                "hf_subset": "tur-eng",
                "languages": [
                    "tur-Latn",
                    "eng-Latn"
                ],
                "accuracy": 81.69999999999999,
                "f1": 77.37888888888888,
                "precision": 75.49583333333332,
                "recall": 81.69999999999999,
                "main_score": 77.37888888888888
            },
            {
                "hf_subset": "deu-eng",
                "languages": [
                    "deu-Latn",
                    "eng-Latn"
                ],
                "accuracy": 97.39999999999999,
                "f1": 96.56666666666666,
                "precision": 96.16666666666667,
                "recall": 97.39999999999999,
                "main_score": 96.56666666666666
            },
            {
                "hf_subset": "nld-eng",
                "languages": [
                    "nld-Latn",
                    "eng-Latn"
                ],
                "accuracy": 90.0,
                "f1": 87.22333333333333,
                "precision": 85.89166666666667,
                "recall": 90.0,
                "main_score": 87.22333333333333
            },
            {
                "hf_subset": "ron-eng",
                "languages": [
                    "ron-Latn",
                    "eng-Latn"
                ],
                "accuracy": 64.7,
                "f1": 59.10904761904763,
                "precision": 56.91968253968254,
                "recall": 64.7,
                "main_score": 59.10904761904763
            },
            {
                "hf_subset": "ang-eng",
                "languages": [
                    "ang-Latn",
                    "eng-Latn"
                ],
                "accuracy": 38.80597014925373,
                "f1": 30.890784174366264,
                "precision": 28.327114427860696,
                "recall": 38.80597014925373,
                "main_score": 30.890784174366264
            },
            {
                "hf_subset": "ido-eng",
                "languages": [
                    "ido-Latn",
                    "eng-Latn"
                ],
                "accuracy": 53.900000000000006,
                "f1": 48.294138583638585,
                "precision": 46.333495670995674,
                "recall": 53.900000000000006,
                "main_score": 48.294138583638585
            },
            {
                "hf_subset": "jav-eng",
                "languages": [
                    "jav-Latn",
                    "eng-Latn"
                ],
                "accuracy": 11.707317073170733,
                "f1": 8.999999999999998,
                "precision": 8.175377468060395,
                "recall": 11.707317073170733,
                "main_score": 8.999999999999998
            },
            {
                "hf_subset": "isl-eng",
                "languages": [
                    "isl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 15.9,
                "f1": 12.451226269430602,
                "precision": 11.404807799760325,
                "recall": 15.9,
                "main_score": 12.451226269430602
            },
            {
                "hf_subset": "slv-eng",
                "languages": [
                    "slv-Latn",
                    "eng-Latn"
                ],
                "accuracy": 41.919805589307416,
                "f1": 35.880619060297064,
                "precision": 33.77682308241239,
                "recall": 41.919805589307416,
                "main_score": 35.880619060297064
            },
            {
                "hf_subset": "cym-eng",
                "languages": [
                    "cym-Latn",
                    "eng-Latn"
                ],
                "accuracy": 10.956521739130434,
                "f1": 9.098715976676996,
                "precision": 8.659935858401333,
                "recall": 10.956521739130434,
                "main_score": 9.098715976676996
            },
            {
                "hf_subset": "kaz-eng",
                "languages": [
                    "kaz-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 11.652173913043478,
                "f1": 9.154324883225136,
                "precision": 8.505898125360801,
                "recall": 11.652173913043478,
                "main_score": 9.154324883225136
            },
            {
                "hf_subset": "est-eng",
                "languages": [
                    "est-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.700000000000001,
                "f1": 7.431679431679432,
                "precision": 6.799925118740907,
                "recall": 9.700000000000001,
                "main_score": 7.431679431679432
            },
            {
                "hf_subset": "heb-eng",
                "languages": [
                    "heb-Hebr",
                    "eng-Latn"
                ],
                "accuracy": 77.5,
                "f1": 72.39999999999999,
                "precision": 70.13444444444444,
                "recall": 77.5,
                "main_score": 72.39999999999999
            },
            {
                "hf_subset": "gla-eng",
                "languages": [
                    "gla-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.548854041013269,
                "f1": 4.233155465362944,
                "precision": 3.948150869646547,
                "recall": 5.548854041013269,
                "main_score": 4.233155465362944
            },
            {
                "hf_subset": "mar-eng",
                "languages": [
                    "mar-Deva",
                    "eng-Latn"
                ],
                "accuracy": 73.5,
                "f1": 67.35333333333332,
                "precision": 64.63666666666666,
                "recall": 73.5,
                "main_score": 67.35333333333332
            },
            {
                "hf_subset": "lat-eng",
                "languages": [
                    "lat-Latn",
                    "eng-Latn"
                ],
                "accuracy": 27.700000000000003,
                "f1": 21.152765495941964,
                "precision": 19.27832403707404,
                "recall": 27.700000000000003,
                "main_score": 21.152765495941964
            },
            {
                "hf_subset": "bel-eng",
                "languages": [
                    "bel-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 48.1,
                "f1": 41.21001443001443,
                "precision": 38.628495670995676,
                "recall": 48.1,
                "main_score": 41.21001443001443
            },
            {
                "hf_subset": "pms-eng",
                "languages": [
                    "pms-Latn",
                    "eng-Latn"
                ],
                "accuracy": 40.0,
                "f1": 34.32060003488575,
                "precision": 32.32134353741497,
                "recall": 40.0,
                "main_score": 34.32060003488575
            },
            {
                "hf_subset": "gle-eng",
                "languages": [
                    "gle-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.800000000000001,
                "f1": 4.3954389450190465,
                "precision": 3.893838027469606,
                "recall": 6.800000000000001,
                "main_score": 4.3954389450190465
            },
            {
                "hf_subset": "pes-eng",
                "languages": [
                    "pes-Arab",
                    "eng-Latn"
                ],
                "accuracy": 51.800000000000004,
                "f1": 45.04222943722944,
                "precision": 42.541984126984126,
                "recall": 51.800000000000004,
                "main_score": 45.04222943722944
            },
            {
                "hf_subset": "nob-eng",
                "languages": [
                    "nob-Latn",
                    "eng-Latn"
                ],
                "accuracy": 83.1,
                "f1": 79.20675324675324,
                "precision": 77.44944444444444,
                "recall": 83.1,
                "main_score": 79.20675324675324
            },
            {
                "hf_subset": "bul-eng",
                "languages": [
                    "bul-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 66.8,
                "f1": 60.25746031746031,
                "precision": 57.55250000000001,
                "recall": 66.8,
                "main_score": 60.25746031746031
            },
            {
                "hf_subset": "cbk-eng",
                "languages": [
                    "cbk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 63.6,
                "f1": 56.73421356421356,
                "precision": 54.02218253968254,
                "recall": 63.6,
                "main_score": 56.73421356421356
            },
            {
                "hf_subset": "hun-eng",
                "languages": [
                    "hun-Latn",
                    "eng-Latn"
                ],
                "accuracy": 17.599999999999998,
                "f1": 13.17699134199134,
                "precision": 11.77444805194805,
                "recall": 17.599999999999998,
                "main_score": 13.17699134199134
            },
            {
                "hf_subset": "uig-eng",
                "languages": [
                    "uig-Arab",
                    "eng-Latn"
                ],
                "accuracy": 2.0,
                "f1": 1.3126923076923078,
                "precision": 1.104952380952381,
                "recall": 2.0,
                "main_score": 1.3126923076923078
            },
            {
                "hf_subset": "rus-eng",
                "languages": [
                    "rus-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 88.3,
                "f1": 84.96333333333334,
                "precision": 83.38333333333333,
                "recall": 88.3,
                "main_score": 84.96333333333334
            },
            {
                "hf_subset": "spa-eng",
                "languages": [
                    "spa-Latn",
                    "eng-Latn"
                ],
                "accuracy": 94.69999999999999,
                "f1": 93.12333333333333,
                "precision": 92.375,
                "recall": 94.69999999999999,
                "main_score": 93.12333333333333
            },
            {
                "hf_subset": "hye-eng",
                "languages": [
                    "hye-Armn",
                    "eng-Latn"
                ],
                "accuracy": 0.6738544474393532,
                "f1": 0.3690849566291394,
                "precision": 0.3305452159899599,
                "recall": 0.6738544474393532,
                "main_score": 0.3690849566291394
            },
            {
                "hf_subset": "tel-eng",
                "languages": [
                    "tel-Telu",
                    "eng-Latn"
                ],
                "accuracy": 71.7948717948718,
                "f1": 65.37037037037037,
                "precision": 62.46438746438747,
                "recall": 71.7948717948718,
                "main_score": 65.37037037037037
            },
            {
                "hf_subset": "afr-eng",
                "languages": [
                    "afr-Latn",
                    "eng-Latn"
                ],
                "accuracy": 56.699999999999996,
                "f1": 50.58054945054945,
                "precision": 48.313047619047616,
                "recall": 56.699999999999996,
                "main_score": 50.58054945054945
            },
            {
                "hf_subset": "mon-eng",
                "languages": [
                    "mon-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 13.863636363636363,
                "f1": 10.948429096156369,
                "precision": 10.227287994137523,
                "recall": 13.863636363636363,
                "main_score": 10.948429096156369
            },
            {
                "hf_subset": "arz-eng",
                "languages": [
                    "arz-Arab",
                    "eng-Latn"
                ],
                "accuracy": 62.473794549266245,
                "f1": 56.04172906059699,
                "precision": 53.26694619147448,
                "recall": 62.473794549266245,
                "main_score": 56.04172906059699
            },
            {
                "hf_subset": "hrv-eng",
                "languages": [
                    "hrv-Latn",
                    "eng-Latn"
                ],
                "accuracy": 40.0,
                "f1": 34.62948179271708,
                "precision": 32.699030910609864,
                "recall": 40.0,
                "main_score": 34.62948179271708
            },
            {
                "hf_subset": "nov-eng",
                "languages": [
                    "nov-Latn",
                    "eng-Latn"
                ],
                "accuracy": 60.311284046692606,
                "f1": 54.06182447038479,
                "precision": 51.757921067259595,
                "recall": 60.311284046692606,
                "main_score": 54.06182447038479
            },
            {
                "hf_subset": "gsw-eng",
                "languages": [
                    "gsw-Latn",
                    "eng-Latn"
                ],
                "accuracy": 43.58974358974359,
                "f1": 37.042359350051655,
                "precision": 34.75783475783476,
                "recall": 43.58974358974359,
                "main_score": 37.042359350051655
            },
            {
                "hf_subset": "nds-eng",
                "languages": [
                    "nds-Latn",
                    "eng-Latn"
                ],
                "accuracy": 56.49999999999999,
                "f1": 49.471269841269844,
                "precision": 46.742182539682545,
                "recall": 56.49999999999999,
                "main_score": 49.471269841269844
            },
            {
                "hf_subset": "ukr-eng",
                "languages": [
                    "ukr-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 71.5,
                "f1": 65.32880952380951,
                "precision": 62.71261904761904,
                "recall": 71.5,
                "main_score": 65.32880952380951
            },
            {
                "hf_subset": "uzb-eng",
                "languages": [
                    "uzb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 11.448598130841122,
                "f1": 7.861361294691689,
                "precision": 6.961045509526818,
                "recall": 11.448598130841122,
                "main_score": 7.861361294691689
            },
            {
                "hf_subset": "lit-eng",
                "languages": [
                    "lit-Latn",
                    "eng-Latn"
                ],
                "accuracy": 13.5,
                "f1": 10.448586132968154,
                "precision": 9.624691955878397,
                "recall": 13.5,
                "main_score": 10.448586132968154
            },
            {
                "hf_subset": "ina-eng",
                "languages": [
                    "ina-Latn",
                    "eng-Latn"
                ],
                "accuracy": 82.19999999999999,
                "f1": 78.25366946778712,
                "precision": 76.54291666666667,
                "recall": 82.19999999999999,
                "main_score": 78.25366946778712
            },
            {
                "hf_subset": "lfn-eng",
                "languages": [
                    "lfn-Latn",
                    "eng-Latn"
                ],
                "accuracy": 53.5,
                "f1": 47.48505411255411,
                "precision": 45.29801587301587,
                "recall": 53.5,
                "main_score": 47.48505411255411
            },
            {
                "hf_subset": "zsm-eng",
                "languages": [
                    "zsm-Latn",
                    "eng-Latn"
                ],
                "accuracy": 61.1,
                "f1": 54.60758056758057,
                "precision": 52.16455433455434,
                "recall": 61.1,
                "main_score": 54.60758056758057
            },
            {
                "hf_subset": "ita-eng",
                "languages": [
                    "ita-Latn",
                    "eng-Latn"
                ],
                "accuracy": 85.1,
                "f1": 81.98506715506716,
                "precision": 80.64754901960784,
                "recall": 85.1,
                "main_score": 81.98506715506716
            },
            {
                "hf_subset": "cmn-eng",
                "languages": [
                    "cmn-Hans",
                    "eng-Latn"
                ],
                "accuracy": 89.2,
                "f1": 86.13333333333333,
                "precision": 84.65,
                "recall": 89.2,
                "main_score": 86.13333333333333
            },
            {
                "hf_subset": "lvs-eng",
                "languages": [
                    "lvs-Latn",
                    "eng-Latn"
                ],
                "accuracy": 13.600000000000001,
                "f1": 10.721816580317723,
                "precision": 9.97922024538847,
                "recall": 13.600000000000001,
                "main_score": 10.721816580317723
            },
            {
                "hf_subset": "glg-eng",
                "languages": [
                    "glg-Latn",
                    "eng-Latn"
                ],
                "accuracy": 79.0,
                "f1": 74.2652380952381,
                "precision": 72.18690476190476,
                "recall": 79.0,
                "main_score": 74.2652380952381
            },
            {
                "hf_subset": "ceb-eng",
                "languages": [
                    "ceb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 12.833333333333332,
                "f1": 10.45993265993266,
                "precision": 9.849548907882243,
                "recall": 12.833333333333332,
                "main_score": 10.45993265993266
            },
            {
                "hf_subset": "bre-eng",
                "languages": [
                    "bre-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.3,
                "f1": 5.457311371692176,
                "precision": 4.8466941508148595,
                "recall": 8.3,
                "main_score": 5.457311371692176
            },
            {
                "hf_subset": "ben-eng",
                "languages": [
                    "ben-Beng",
                    "eng-Latn"
                ],
                "accuracy": 26.3,
                "f1": 20.851341154819416,
                "precision": 19.1173617945522,
                "recall": 26.3,
                "main_score": 20.851341154819416
            },
            {
                "hf_subset": "swg-eng",
                "languages": [
                    "swg-Latn",
                    "eng-Latn"
                ],
                "accuracy": 41.964285714285715,
                "f1": 36.38605442176871,
                "precision": 34.523809523809526,
                "recall": 41.964285714285715,
                "main_score": 36.38605442176871
            },
            {
                "hf_subset": "arq-eng",
                "languages": [
                    "arq-Arab",
                    "eng-Latn"
                ],
                "accuracy": 26.454445664105382,
                "f1": 20.67692765826684,
                "precision": 18.684070229075715,
                "recall": 26.454445664105382,
                "main_score": 20.67692765826684
            },
            {
                "hf_subset": "kab-eng",
                "languages": [
                    "kab-Latn",
                    "eng-Latn"
                ],
                "accuracy": 2.8000000000000003,
                "f1": 1.9487240537240536,
                "precision": 1.7766582325720255,
                "recall": 2.8000000000000003,
                "main_score": 1.9487240537240536
            },
            {
                "hf_subset": "fra-eng",
                "languages": [
                    "fra-Latn",
                    "eng-Latn"
                ],
                "accuracy": 91.5,
                "f1": 89.39,
                "precision": 88.425,
                "recall": 91.5,
                "main_score": 89.39
            },
            {
                "hf_subset": "por-eng",
                "languages": [
                    "por-Latn",
                    "eng-Latn"
                ],
                "accuracy": 91.5,
                "f1": 89.38333333333333,
                "precision": 88.36666666666667,
                "recall": 91.5,
                "main_score": 89.38333333333333
            },
            {
                "hf_subset": "tat-eng",
                "languages": [
                    "tat-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 9.2,
                "f1": 6.672282438325198,
                "precision": 6.046073589145276,
                "recall": 9.2,
                "main_score": 6.672282438325198
            },
            {
                "hf_subset": "oci-eng",
                "languages": [
                    "oci-Latn",
                    "eng-Latn"
                ],
                "accuracy": 45.2,
                "f1": 39.12095238095238,
                "precision": 36.820952380952384,
                "recall": 45.2,
                "main_score": 39.12095238095238
            },
            {
                "hf_subset": "pol-eng",
                "languages": [
                    "pol-Latn",
                    "eng-Latn"
                ],
                "accuracy": 86.8,
                "f1": 83.35000000000001,
                "precision": 81.825,
                "recall": 86.8,
                "main_score": 83.35000000000001
            },
            {
                "hf_subset": "war-eng",
                "languages": [
                    "war-Latn",
                    "eng-Latn"
                ],
                "accuracy": 13.5,
                "f1": 10.66862856136998,
                "precision": 9.845928551928552,
                "recall": 13.5,
                "main_score": 10.66862856136998
            },
            {
                "hf_subset": "aze-eng",
                "languages": [
                    "aze-Latn",
                    "eng-Latn"
                ],
                "accuracy": 33.4,
                "f1": 27.78153389993659,
                "precision": 25.778055555555557,
                "recall": 33.4,
                "main_score": 27.78153389993659
            },
            {
                "hf_subset": "vie-eng",
                "languages": [
                    "vie-Latn",
                    "eng-Latn"
                ],
                "accuracy": 57.699999999999996,
                "f1": 50.440714285714286,
                "precision": 47.64396825396825,
                "recall": 57.699999999999996,
                "main_score": 50.440714285714286
            },
            {
                "hf_subset": "nno-eng",
                "languages": [
                    "nno-Latn",
                    "eng-Latn"
                ],
                "accuracy": 62.2,
                "f1": 56.0098625351257,
                "precision": 53.691914098972916,
                "recall": 62.2,
                "main_score": 56.0098625351257
            },
            {
                "hf_subset": "cha-eng",
                "languages": [
                    "cha-Latn",
                    "eng-Latn"
                ],
                "accuracy": 27.00729927007299,
                "f1": 22.798053527980535,
                "precision": 21.107055961070557,
                "recall": 27.00729927007299,
                "main_score": 22.798053527980535
            },
            {
                "hf_subset": "mhr-eng",
                "languages": [
                    "mhr-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 6.2,
                "f1": 4.295544090473964,
                "precision": 3.913153952193392,
                "recall": 6.2,
                "main_score": 4.295544090473964
            },
            {
                "hf_subset": "dan-eng",
                "languages": [
                    "dan-Latn",
                    "eng-Latn"
                ],
                "accuracy": 77.10000000000001,
                "f1": 72.49333333333334,
                "precision": 70.53368637110017,
                "recall": 77.10000000000001,
                "main_score": 72.49333333333334
            },
            {
                "hf_subset": "ell-eng",
                "languages": [
                    "ell-Grek",
                    "eng-Latn"
                ],
                "accuracy": 15.2,
                "f1": 10.429591693330824,
                "precision": 9.145801926831338,
                "recall": 15.2,
                "main_score": 10.429591693330824
            },
            {
                "hf_subset": "amh-eng",
                "languages": [
                    "amh-Ethi",
                    "eng-Latn"
                ],
                "accuracy": 1.7857142857142856,
                "f1": 0.3635204081632653,
                "precision": 0.205026455026455,
                "recall": 1.7857142857142856,
                "main_score": 0.3635204081632653
            },
            {
                "hf_subset": "pam-eng",
                "languages": [
                    "pam-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.4,
                "f1": 4.8412763053939525,
                "precision": 4.444087810337809,
                "recall": 6.4,
                "main_score": 4.8412763053939525
            },
            {
                "hf_subset": "hsb-eng",
                "languages": [
                    "hsb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 43.47826086956522,
                "f1": 37.13266949291794,
                "precision": 34.655332590115194,
                "recall": 43.47826086956522,
                "main_score": 37.13266949291794
            },
            {
                "hf_subset": "srp-eng",
                "languages": [
                    "srp-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 42.0,
                "f1": 35.412229437229435,
                "precision": 32.907539682539685,
                "recall": 42.0,
                "main_score": 35.412229437229435
            },
            {
                "hf_subset": "epo-eng",
                "languages": [
                    "epo-Latn",
                    "eng-Latn"
                ],
                "accuracy": 36.0,
                "f1": 30.53874458874459,
                "precision": 28.711192408382807,
                "recall": 36.0,
                "main_score": 30.53874458874459
            },
            {
                "hf_subset": "kzj-eng",
                "languages": [
                    "kzj-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.9,
                "f1": 5.80190114561213,
                "precision": 5.298527531836355,
                "recall": 7.9,
                "main_score": 5.80190114561213
            },
            {
                "hf_subset": "awa-eng",
                "languages": [
                    "awa-Deva",
                    "eng-Latn"
                ],
                "accuracy": 49.35064935064935,
                "f1": 41.57805638325119,
                "precision": 38.87445887445887,
                "recall": 49.35064935064935,
                "main_score": 41.57805638325119
            },
            {
                "hf_subset": "fao-eng",
                "languages": [
                    "fao-Latn",
                    "eng-Latn"
                ],
                "accuracy": 25.572519083969464,
                "f1": 21.338006776938073,
                "precision": 20.194474736459465,
                "recall": 25.572519083969464,
                "main_score": 21.338006776938073
            },
            {
                "hf_subset": "mal-eng",
                "languages": [
                    "mal-Mlym",
                    "eng-Latn"
                ],
                "accuracy": 79.62154294032024,
                "f1": 74.47355652595827,
                "precision": 72.2076661814653,
                "recall": 79.62154294032024,
                "main_score": 74.47355652595827
            },
            {
                "hf_subset": "ile-eng",
                "languages": [
                    "ile-Latn",
                    "eng-Latn"
                ],
                "accuracy": 68.0,
                "f1": 61.80859649122807,
                "precision": 59.30381381381381,
                "recall": 68.0,
                "main_score": 61.80859649122807
            },
            {
                "hf_subset": "bos-eng",
                "languages": [
                    "bos-Latn",
                    "eng-Latn"
                ],
                "accuracy": 42.93785310734463,
                "f1": 36.72617201306135,
                "precision": 34.72641059505466,
                "recall": 42.93785310734463,
                "main_score": 36.72617201306135
            },
            {
                "hf_subset": "cor-eng",
                "languages": [
                    "cor-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.5,
                "f1": 3.8651658986175113,
                "precision": 3.4432814407814405,
                "recall": 5.5,
                "main_score": 3.8651658986175113
            },
            {
                "hf_subset": "cat-eng",
                "languages": [
                    "cat-Latn",
                    "eng-Latn"
                ],
                "accuracy": 69.19999999999999,
                "f1": 63.41880952380953,
                "precision": 61.07913419913419,
                "recall": 69.19999999999999,
                "main_score": 63.41880952380953
            },
            {
                "hf_subset": "eus-eng",
                "languages": [
                    "eus-Latn",
                    "eng-Latn"
                ],
                "accuracy": 15.4,
                "f1": 11.672122577122575,
                "precision": 10.59919974661354,
                "recall": 15.4,
                "main_score": 11.672122577122575
            },
            {
                "hf_subset": "yue-eng",
                "languages": [
                    "yue-Hant",
                    "eng-Latn"
                ],
                "accuracy": 58.5,
                "f1": 51.31880452880453,
                "precision": 48.60550125313283,
                "recall": 58.5,
                "main_score": 51.31880452880453
            },
            {
                "hf_subset": "swe-eng",
                "languages": [
                    "swe-Latn",
                    "eng-Latn"
                ],
                "accuracy": 89.3,
                "f1": 86.32666666666667,
                "precision": 84.98333333333333,
                "recall": 89.3,
                "main_score": 86.32666666666667
            },
            {
                "hf_subset": "dtp-eng",
                "languages": [
                    "dtp-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.7,
                "f1": 3.8739805216757546,
                "precision": 3.4734608954367014,
                "recall": 5.7,
                "main_score": 3.8739805216757546
            },
            {
                "hf_subset": "kat-eng",
                "languages": [
                    "kat-Geor",
                    "eng-Latn"
                ],
                "accuracy": 0.8042895442359249,
                "f1": 0.7596067917783735,
                "precision": 0.7372654155495978,
                "recall": 0.8042895442359249,
                "main_score": 0.7596067917783735
            },
            {
                "hf_subset": "jpn-eng",
                "languages": [
                    "jpn-Jpan",
                    "eng-Latn"
                ],
                "accuracy": 89.7,
                "f1": 86.92333333333333,
                "precision": 85.64166666666667,
                "recall": 89.7,
                "main_score": 86.92333333333333
            },
            {
                "hf_subset": "csb-eng",
                "languages": [
                    "csb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 26.08695652173913,
                "f1": 20.517863778733343,
                "precision": 18.901098901098898,
                "recall": 26.08695652173913,
                "main_score": 20.517863778733343
            },
            {
                "hf_subset": "xho-eng",
                "languages": [
                    "xho-Latn",
                    "eng-Latn"
                ],
                "accuracy": 12.676056338028168,
                "f1": 9.526324614352783,
                "precision": 9.006292657908235,
                "recall": 12.676056338028168,
                "main_score": 9.526324614352783
            },
            {
                "hf_subset": "orv-eng",
                "languages": [
                    "orv-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 24.910179640718564,
                "f1": 19.645099411566473,
                "precision": 17.676076418591386,
                "recall": 24.910179640718564,
                "main_score": 19.645099411566473
            },
            {
                "hf_subset": "ind-eng",
                "languages": [
                    "ind-Latn",
                    "eng-Latn"
                ],
                "accuracy": 61.4,
                "f1": 54.64269841269841,
                "precision": 51.981071428571425,
                "recall": 61.4,
                "main_score": 54.64269841269841
            },
            {
                "hf_subset": "tuk-eng",
                "languages": [
                    "tuk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 11.330049261083744,
                "f1": 9.610016420361248,
                "precision": 9.123781574258464,
                "recall": 11.330049261083744,
                "main_score": 9.610016420361248
            },
            {
                "hf_subset": "max-eng",
                "languages": [
                    "max-Deva",
                    "eng-Latn"
                ],
                "accuracy": 27.816901408450708,
                "f1": 22.51925345174495,
                "precision": 21.10468365750056,
                "recall": 27.816901408450708,
                "main_score": 22.51925345174495
            },
            {
                "hf_subset": "swh-eng",
                "languages": [
                    "swh-Latn",
                    "eng-Latn"
                ],
                "accuracy": 11.282051282051283,
                "f1": 7.777167097237831,
                "precision": 7.050109879436802,
                "recall": 11.282051282051283,
                "main_score": 7.777167097237831
            },
            {
                "hf_subset": "hin-eng",
                "languages": [
                    "hin-Deva",
                    "eng-Latn"
                ],
                "accuracy": 86.0,
                "f1": 82.05857142857143,
                "precision": 80.25,
                "recall": 86.0,
                "main_score": 82.05857142857143
            },
            {
                "hf_subset": "dsb-eng",
                "languages": [
                    "dsb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 34.44676409185804,
                "f1": 28.296517215097587,
                "precision": 26.16624956236465,
                "recall": 34.44676409185804,
                "main_score": 28.296517215097587
            },
            {
                "hf_subset": "ber-eng",
                "languages": [
                    "ber-Tfng",
                    "eng-Latn"
                ],
                "accuracy": 7.199999999999999,
                "f1": 5.500051631938041,
                "precision": 5.164411510424442,
                "recall": 7.199999999999999,
                "main_score": 5.500051631938041
            },
            {
                "hf_subset": "tam-eng",
                "languages": [
                    "tam-Taml",
                    "eng-Latn"
                ],
                "accuracy": 71.9869706840391,
                "f1": 65.79339227547696,
                "precision": 63.16503800217155,
                "recall": 71.9869706840391,
                "main_score": 65.79339227547696
            },
            {
                "hf_subset": "slk-eng",
                "languages": [
                    "slk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 70.89999999999999,
                "f1": 65.4152380952381,
                "precision": 63.106666666666655,
                "recall": 70.89999999999999,
                "main_score": 65.4152380952381
            },
            {
                "hf_subset": "tgl-eng",
                "languages": [
                    "tgl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 21.0,
                "f1": 17.86438197644649,
                "precision": 16.84469948469949,
                "recall": 21.0,
                "main_score": 17.86438197644649
            },
            {
                "hf_subset": "ast-eng",
                "languages": [
                    "ast-Latn",
                    "eng-Latn"
                ],
                "accuracy": 62.20472440944882,
                "f1": 55.81364829396325,
                "precision": 53.262092238470196,
                "recall": 62.20472440944882,
                "main_score": 55.81364829396325
            },
            {
                "hf_subset": "mkd-eng",
                "languages": [
                    "mkd-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 41.8,
                "f1": 34.724603174603175,
                "precision": 32.040277777777774,
                "recall": 41.8,
                "main_score": 34.724603174603175
            },
            {
                "hf_subset": "khm-eng",
                "languages": [
                    "khm-Khmr",
                    "eng-Latn"
                ],
                "accuracy": 0.41551246537396125,
                "f1": 0.3462603878116343,
                "precision": 0.32317636195752536,
                "recall": 0.41551246537396125,
                "main_score": 0.3462603878116343
            },
            {
                "hf_subset": "ces-eng",
                "languages": [
                    "ces-Latn",
                    "eng-Latn"
                ],
                "accuracy": 85.6,
                "f1": 81.81333333333333,
                "precision": 80.08333333333334,
                "recall": 85.6,
                "main_score": 81.81333333333333
            },
            {
                "hf_subset": "tzl-eng",
                "languages": [
                    "tzl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 31.73076923076923,
                "f1": 26.097374847374844,
                "precision": 24.31891025641026,
                "recall": 31.73076923076923,
                "main_score": 26.097374847374844
            },
            {
                "hf_subset": "urd-eng",
                "languages": [
                    "urd-Arab",
                    "eng-Latn"
                ],
                "accuracy": 9.6,
                "f1": 6.598392371412457,
                "precision": 5.855494356434758,
                "recall": 9.6,
                "main_score": 6.598392371412457
            },
            {
                "hf_subset": "ara-eng",
                "languages": [
                    "ara-Arab",
                    "eng-Latn"
                ],
                "accuracy": 83.5,
                "f1": 79.65190476190476,
                "precision": 77.875,
                "recall": 83.5,
                "main_score": 79.65190476190476
            },
            {
                "hf_subset": "kor-eng",
                "languages": [
                    "kor-Hang",
                    "eng-Latn"
                ],
                "accuracy": 80.5,
                "f1": 75.75999999999999,
                "precision": 73.60333333333332,
                "recall": 80.5,
                "main_score": 75.75999999999999
            },
            {
                "hf_subset": "yid-eng",
                "languages": [
                    "yid-Hebr",
                    "eng-Latn"
                ],
                "accuracy": 2.1226415094339623,
                "f1": 1.4622641509433962,
                "precision": 1.2637578616352203,
                "recall": 2.1226415094339623,
                "main_score": 1.4622641509433962
            },
            {
                "hf_subset": "fin-eng",
                "languages": [
                    "fin-Latn",
                    "eng-Latn"
                ],
                "accuracy": 23.0,
                "f1": 18.111780719280716,
                "precision": 16.497738095238095,
                "recall": 23.0,
                "main_score": 18.111780719280716
            },
            {
                "hf_subset": "tha-eng",
                "languages": [
                    "tha-Thai",
                    "eng-Latn"
                ],
                "accuracy": 4.562043795620438,
                "f1": 3.1632119907667358,
                "precision": 2.8806772100567724,
                "recall": 4.562043795620438,
                "main_score": 3.1632119907667358
            },
            {
                "hf_subset": "wuu-eng",
                "languages": [
                    "wuu-Hans",
                    "eng-Latn"
                ],
                "accuracy": 75.9,
                "f1": 70.57690476190476,
                "precision": 68.19761904761904,
                "recall": 75.9,
                "main_score": 70.57690476190476
            }
        ]
    }
}