{
    "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
    "task_name": "MTOPIntentClassification",
    "evaluation_time": null,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 66.0031919744642,
                "f1": 48.13490278120492,
                "main_score": 66.0031919744642
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 63.260073260073256,
                "f1": 42.627167415555505,
                "main_score": 63.260073260073256
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 65.06004002668445,
                "f1": 44.90527231209402,
                "main_score": 65.06004002668445
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 59.42687128092702,
                "f1": 41.79584710899656,
                "main_score": 59.42687128092702
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 59.078522768017216,
                "f1": 40.398016878580734,
                "main_score": 59.078522768017216
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 43.750452079565996,
                "f1": 28.985320742729865,
                "main_score": 43.750452079565996
            }
        ]
    }
}