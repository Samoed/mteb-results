{
    "dataset_revision": "ed9e4a974f867fd9736efcf222fc3a26487387a5",
    "task_name": "Tatoeba",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "sqi-eng",
                "languages": [
                    "sqi-Latn",
                    "eng-Latn"
                ],
                "accuracy": 12.7,
                "f1": 10.384182044950325,
                "precision": 9.805277385275312,
                "recall": 12.7,
                "main_score": 10.384182044950325
            },
            {
                "hf_subset": "fry-eng",
                "languages": [
                    "fry-Latn",
                    "eng-Latn"
                ],
                "accuracy": 30.63583815028902,
                "f1": 24.623726947426373,
                "precision": 22.987809919828013,
                "recall": 30.63583815028902,
                "main_score": 24.623726947426373
            },
            {
                "hf_subset": "kur-eng",
                "languages": [
                    "kur-Latn",
                    "eng-Latn"
                ],
                "accuracy": 10.487804878048781,
                "f1": 8.255945048627975,
                "precision": 7.649047253615001,
                "recall": 10.487804878048781,
                "main_score": 8.255945048627975
            },
            {
                "hf_subset": "tur-eng",
                "languages": [
                    "tur-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.5,
                "f1": 6.154428783776609,
                "precision": 5.680727638128585,
                "recall": 8.5,
                "main_score": 6.154428783776609
            },
            {
                "hf_subset": "deu-eng",
                "languages": [
                    "deu-Latn",
                    "eng-Latn"
                ],
                "accuracy": 73.0,
                "f1": 70.10046605876393,
                "precision": 69.0018253968254,
                "recall": 73.0,
                "main_score": 70.10046605876393
            },
            {
                "hf_subset": "nld-eng",
                "languages": [
                    "nld-Latn",
                    "eng-Latn"
                ],
                "accuracy": 32.7,
                "f1": 29.7428583868239,
                "precision": 28.81671359506905,
                "recall": 32.7,
                "main_score": 29.7428583868239
            },
            {
                "hf_subset": "ron-eng",
                "languages": [
                    "ron-Latn",
                    "eng-Latn"
                ],
                "accuracy": 31.5,
                "f1": 27.228675552174003,
                "precision": 25.950062299847747,
                "recall": 31.5,
                "main_score": 27.228675552174003
            },
            {
                "hf_subset": "ang-eng",
                "languages": [
                    "ang-Latn",
                    "eng-Latn"
                ],
                "accuracy": 35.82089552238806,
                "f1": 28.75836980510979,
                "precision": 26.971643613434658,
                "recall": 35.82089552238806,
                "main_score": 28.75836980510979
            },
            {
                "hf_subset": "ido-eng",
                "languages": [
                    "ido-Latn",
                    "eng-Latn"
                ],
                "accuracy": 49.8,
                "f1": 43.909237401451776,
                "precision": 41.944763440988936,
                "recall": 49.8,
                "main_score": 43.909237401451776
            },
            {
                "hf_subset": "jav-eng",
                "languages": [
                    "jav-Latn",
                    "eng-Latn"
                ],
                "accuracy": 18.536585365853657,
                "f1": 15.020182570246751,
                "precision": 14.231108073213337,
                "recall": 18.536585365853657,
                "main_score": 15.020182570246751
            },
            {
                "hf_subset": "isl-eng",
                "languages": [
                    "isl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.7,
                "f1": 6.2934784902885355,
                "precision": 5.685926293425392,
                "recall": 8.7,
                "main_score": 6.2934784902885355
            },
            {
                "hf_subset": "slv-eng",
                "languages": [
                    "slv-Latn",
                    "eng-Latn"
                ],
                "accuracy": 12.879708383961116,
                "f1": 10.136118341751114,
                "precision": 9.571444036679436,
                "recall": 12.879708383961116,
                "main_score": 10.136118341751114
            },
            {
                "hf_subset": "cym-eng",
                "languages": [
                    "cym-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.217391304347826,
                "f1": 6.965003297761793,
                "precision": 6.476093529199119,
                "recall": 9.217391304347826,
                "main_score": 6.965003297761793
            },
            {
                "hf_subset": "kaz-eng",
                "languages": [
                    "kaz-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 4.3478260869565215,
                "f1": 3.3186971707677397,
                "precision": 3.198658632552104,
                "recall": 4.3478260869565215,
                "main_score": 3.3186971707677397
            },
            {
                "hf_subset": "est-eng",
                "languages": [
                    "est-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.9,
                "f1": 4.760708297894056,
                "precision": 4.28409511756074,
                "recall": 6.9,
                "main_score": 4.760708297894056
            },
            {
                "hf_subset": "heb-eng",
                "languages": [
                    "heb-Hebr",
                    "eng-Latn"
                ],
                "accuracy": 2.1999999999999997,
                "f1": 1.6862703878117107,
                "precision": 1.6048118233915603,
                "recall": 2.1999999999999997,
                "main_score": 1.6862703878117107
            },
            {
                "hf_subset": "gla-eng",
                "languages": [
                    "gla-Latn",
                    "eng-Latn"
                ],
                "accuracy": 3.0156815440289506,
                "f1": 2.0913257250659134,
                "precision": 1.9072775486461648,
                "recall": 3.0156815440289506,
                "main_score": 2.0913257250659134
            },
            {
                "hf_subset": "mar-eng",
                "languages": [
                    "mar-Deva",
                    "eng-Latn"
                ],
                "accuracy": 49.0,
                "f1": 45.5254456536713,
                "precision": 44.134609250398725,
                "recall": 49.0,
                "main_score": 45.5254456536713
            },
            {
                "hf_subset": "lat-eng",
                "languages": [
                    "lat-Latn",
                    "eng-Latn"
                ],
                "accuracy": 33.5,
                "f1": 28.759893973182564,
                "precision": 27.401259116024836,
                "recall": 33.5,
                "main_score": 28.759893973182564
            },
            {
                "hf_subset": "bel-eng",
                "languages": [
                    "bel-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 10.2,
                "f1": 8.030039981676275,
                "precision": 7.548748077210127,
                "recall": 10.2,
                "main_score": 8.030039981676275
            },
            {
                "hf_subset": "pms-eng",
                "languages": [
                    "pms-Latn",
                    "eng-Latn"
                ],
                "accuracy": 38.095238095238095,
                "f1": 31.944999250262406,
                "precision": 30.04452690166976,
                "recall": 38.095238095238095,
                "main_score": 31.944999250262406
            },
            {
                "hf_subset": "gle-eng",
                "languages": [
                    "gle-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.8,
                "f1": 3.2638960786708067,
                "precision": 3.0495382950729644,
                "recall": 4.8,
                "main_score": 3.2638960786708067
            },
            {
                "hf_subset": "pes-eng",
                "languages": [
                    "pes-Arab",
                    "eng-Latn"
                ],
                "accuracy": 15.8,
                "f1": 12.131087470371275,
                "precision": 11.141304011547815,
                "recall": 15.8,
                "main_score": 12.131087470371275
            },
            {
                "hf_subset": "nob-eng",
                "languages": [
                    "nob-Latn",
                    "eng-Latn"
                ],
                "accuracy": 23.3,
                "f1": 21.073044636921384,
                "precision": 20.374220568287285,
                "recall": 23.3,
                "main_score": 21.073044636921384
            },
            {
                "hf_subset": "bul-eng",
                "languages": [
                    "bul-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 24.9,
                "f1": 20.091060685364987,
                "precision": 18.899700591081224,
                "recall": 24.9,
                "main_score": 20.091060685364987
            },
            {
                "hf_subset": "cbk-eng",
                "languages": [
                    "cbk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 70.1,
                "f1": 64.62940836940835,
                "precision": 62.46559523809524,
                "recall": 70.1,
                "main_score": 64.62940836940835
            },
            {
                "hf_subset": "hun-eng",
                "languages": [
                    "hun-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.199999999999999,
                "f1": 5.06613460576115,
                "precision": 4.625224463391809,
                "recall": 7.199999999999999,
                "main_score": 5.06613460576115
            },
            {
                "hf_subset": "uig-eng",
                "languages": [
                    "uig-Arab",
                    "eng-Latn"
                ],
                "accuracy": 1.7999999999999998,
                "f1": 1.2716249514772895,
                "precision": 1.2107445914723798,
                "recall": 1.7999999999999998,
                "main_score": 1.2716249514772895
            },
            {
                "hf_subset": "rus-eng",
                "languages": [
                    "rus-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 65.5,
                "f1": 59.84399711399712,
                "precision": 57.86349567099567,
                "recall": 65.5,
                "main_score": 59.84399711399712
            },
            {
                "hf_subset": "spa-eng",
                "languages": [
                    "spa-Latn",
                    "eng-Latn"
                ],
                "accuracy": 95.7,
                "f1": 94.48333333333333,
                "precision": 93.89999999999999,
                "recall": 95.7,
                "main_score": 94.48333333333333
            },
            {
                "hf_subset": "hye-eng",
                "languages": [
                    "hye-Armn",
                    "eng-Latn"
                ],
                "accuracy": 0.8086253369272237,
                "f1": 0.4962046191492002,
                "precision": 0.47272438578554393,
                "recall": 0.8086253369272237,
                "main_score": 0.4962046191492002
            },
            {
                "hf_subset": "tel-eng",
                "languages": [
                    "tel-Telu",
                    "eng-Latn"
                ],
                "accuracy": 69.23076923076923,
                "f1": 64.6227941099736,
                "precision": 63.03795877325289,
                "recall": 69.23076923076923,
                "main_score": 64.6227941099736
            },
            {
                "hf_subset": "afr-eng",
                "languages": [
                    "afr-Latn",
                    "eng-Latn"
                ],
                "accuracy": 20.599999999999998,
                "f1": 16.62410040660465,
                "precision": 15.598352437967069,
                "recall": 20.599999999999998,
                "main_score": 16.62410040660465
            },
            {
                "hf_subset": "mon-eng",
                "languages": [
                    "mon-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 4.318181818181818,
                "f1": 2.846721192535661,
                "precision": 2.6787861417537147,
                "recall": 4.318181818181818,
                "main_score": 2.846721192535661
            },
            {
                "hf_subset": "arz-eng",
                "languages": [
                    "arz-Arab",
                    "eng-Latn"
                ],
                "accuracy": 74.84276729559748,
                "f1": 70.6638714185884,
                "precision": 68.86792452830188,
                "recall": 74.84276729559748,
                "main_score": 70.6638714185884
            },
            {
                "hf_subset": "hrv-eng",
                "languages": [
                    "hrv-Latn",
                    "eng-Latn"
                ],
                "accuracy": 15.9,
                "f1": 12.793698974586706,
                "precision": 12.088118017657736,
                "recall": 15.9,
                "main_score": 12.793698974586706
            },
            {
                "hf_subset": "nov-eng",
                "languages": [
                    "nov-Latn",
                    "eng-Latn"
                ],
                "accuracy": 59.92217898832685,
                "f1": 52.23086900129701,
                "precision": 49.25853869433636,
                "recall": 59.92217898832685,
                "main_score": 52.23086900129701
            },
            {
                "hf_subset": "gsw-eng",
                "languages": [
                    "gsw-Latn",
                    "eng-Latn"
                ],
                "accuracy": 27.350427350427353,
                "f1": 21.033781033781032,
                "precision": 19.337955491801644,
                "recall": 27.350427350427353,
                "main_score": 21.033781033781032
            },
            {
                "hf_subset": "nds-eng",
                "languages": [
                    "nds-Latn",
                    "eng-Latn"
                ],
                "accuracy": 29.299999999999997,
                "f1": 23.91597452425777,
                "precision": 22.36696598364942,
                "recall": 29.299999999999997,
                "main_score": 23.91597452425777
            },
            {
                "hf_subset": "ukr-eng",
                "languages": [
                    "ukr-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 27.3,
                "f1": 22.059393517688886,
                "precision": 20.503235534170887,
                "recall": 27.3,
                "main_score": 22.059393517688886
            },
            {
                "hf_subset": "uzb-eng",
                "languages": [
                    "uzb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.177570093457943,
                "f1": 4.714367017906037,
                "precision": 4.163882933965758,
                "recall": 8.177570093457943,
                "main_score": 4.714367017906037
            },
            {
                "hf_subset": "lit-eng",
                "languages": [
                    "lit-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.800000000000001,
                "f1": 4.4859357432293825,
                "precision": 4.247814465614043,
                "recall": 5.800000000000001,
                "main_score": 4.4859357432293825
            },
            {
                "hf_subset": "ina-eng",
                "languages": [
                    "ina-Latn",
                    "eng-Latn"
                ],
                "accuracy": 78.4,
                "f1": 73.67166666666667,
                "precision": 71.83285714285714,
                "recall": 78.4,
                "main_score": 73.67166666666667
            },
            {
                "hf_subset": "lfn-eng",
                "languages": [
                    "lfn-Latn",
                    "eng-Latn"
                ],
                "accuracy": 50.3,
                "f1": 44.85221545883311,
                "precision": 43.04913026243909,
                "recall": 50.3,
                "main_score": 44.85221545883311
            },
            {
                "hf_subset": "zsm-eng",
                "languages": [
                    "zsm-Latn",
                    "eng-Latn"
                ],
                "accuracy": 83.5,
                "f1": 79.95151515151515,
                "precision": 78.53611111111111,
                "recall": 83.5,
                "main_score": 79.95151515151515
            },
            {
                "hf_subset": "ita-eng",
                "languages": [
                    "ita-Latn",
                    "eng-Latn"
                ],
                "accuracy": 69.89999999999999,
                "f1": 65.03756269256269,
                "precision": 63.233519536019536,
                "recall": 69.89999999999999,
                "main_score": 65.03756269256269
            },
            {
                "hf_subset": "cmn-eng",
                "languages": [
                    "cmn-Hans",
                    "eng-Latn"
                ],
                "accuracy": 93.2,
                "f1": 91.44666666666666,
                "precision": 90.63333333333333,
                "recall": 93.2,
                "main_score": 91.44666666666666
            },
            {
                "hf_subset": "lvs-eng",
                "languages": [
                    "lvs-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.3,
                "f1": 6.553388144729963,
                "precision": 6.313497782829976,
                "recall": 8.3,
                "main_score": 6.553388144729963
            },
            {
                "hf_subset": "glg-eng",
                "languages": [
                    "glg-Latn",
                    "eng-Latn"
                ],
                "accuracy": 83.6,
                "f1": 79.86243107769424,
                "precision": 78.32555555555555,
                "recall": 83.6,
                "main_score": 79.86243107769424
            },
            {
                "hf_subset": "ceb-eng",
                "languages": [
                    "ceb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.166666666666666,
                "f1": 6.637753604420271,
                "precision": 6.10568253585495,
                "recall": 9.166666666666666,
                "main_score": 6.637753604420271
            },
            {
                "hf_subset": "bre-eng",
                "languages": [
                    "bre-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.3999999999999995,
                "f1": 4.6729483612322165,
                "precision": 4.103844520292658,
                "recall": 7.3999999999999995,
                "main_score": 4.6729483612322165
            },
            {
                "hf_subset": "ben-eng",
                "languages": [
                    "ben-Beng",
                    "eng-Latn"
                ],
                "accuracy": 80.30000000000001,
                "f1": 75.97666666666667,
                "precision": 74.16,
                "recall": 80.30000000000001,
                "main_score": 75.97666666666667
            },
            {
                "hf_subset": "swg-eng",
                "languages": [
                    "swg-Latn",
                    "eng-Latn"
                ],
                "accuracy": 23.214285714285715,
                "f1": 16.88988095238095,
                "precision": 15.364937641723353,
                "recall": 23.214285714285715,
                "main_score": 16.88988095238095
            },
            {
                "hf_subset": "arq-eng",
                "languages": [
                    "arq-Arab",
                    "eng-Latn"
                ],
                "accuracy": 33.15038419319429,
                "f1": 27.747873024072415,
                "precision": 25.99320572578704,
                "recall": 33.15038419319429,
                "main_score": 27.747873024072415
            },
            {
                "hf_subset": "kab-eng",
                "languages": [
                    "kab-Latn",
                    "eng-Latn"
                ],
                "accuracy": 2.6,
                "f1": 1.687059048752127,
                "precision": 1.5384884521299,
                "recall": 2.6,
                "main_score": 1.687059048752127
            },
            {
                "hf_subset": "fra-eng",
                "languages": [
                    "fra-Latn",
                    "eng-Latn"
                ],
                "accuracy": 93.30000000000001,
                "f1": 91.44000000000001,
                "precision": 90.59166666666667,
                "recall": 93.30000000000001,
                "main_score": 91.44000000000001
            },
            {
                "hf_subset": "por-eng",
                "languages": [
                    "por-Latn",
                    "eng-Latn"
                ],
                "accuracy": 94.1,
                "f1": 92.61666666666667,
                "precision": 91.88333333333333,
                "recall": 94.1,
                "main_score": 92.61666666666667
            },
            {
                "hf_subset": "tat-eng",
                "languages": [
                    "tat-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 5.0,
                "f1": 3.589591971281927,
                "precision": 3.3046491614532854,
                "recall": 5.0,
                "main_score": 3.589591971281927
            },
            {
                "hf_subset": "oci-eng",
                "languages": [
                    "oci-Latn",
                    "eng-Latn"
                ],
                "accuracy": 45.9,
                "f1": 40.171969141969136,
                "precision": 38.30764368870302,
                "recall": 45.9,
                "main_score": 40.171969141969136
            },
            {
                "hf_subset": "pol-eng",
                "languages": [
                    "pol-Latn",
                    "eng-Latn"
                ],
                "accuracy": 16.900000000000002,
                "f1": 14.094365204207351,
                "precision": 13.276519841269844,
                "recall": 16.900000000000002,
                "main_score": 14.094365204207351
            },
            {
                "hf_subset": "war-eng",
                "languages": [
                    "war-Latn",
                    "eng-Latn"
                ],
                "accuracy": 12.8,
                "f1": 10.376574912567156,
                "precision": 9.758423963284509,
                "recall": 12.8,
                "main_score": 10.376574912567156
            },
            {
                "hf_subset": "aze-eng",
                "languages": [
                    "aze-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.1,
                "f1": 6.319455355175778,
                "precision": 5.849948830628881,
                "recall": 8.1,
                "main_score": 6.319455355175778
            },
            {
                "hf_subset": "vie-eng",
                "languages": [
                    "vie-Latn",
                    "eng-Latn"
                ],
                "accuracy": 95.5,
                "f1": 94.19666666666667,
                "precision": 93.60000000000001,
                "recall": 95.5,
                "main_score": 94.19666666666667
            },
            {
                "hf_subset": "nno-eng",
                "languages": [
                    "nno-Latn",
                    "eng-Latn"
                ],
                "accuracy": 19.1,
                "f1": 16.280080686081906,
                "precision": 15.451573089395668,
                "recall": 19.1,
                "main_score": 16.280080686081906
            },
            {
                "hf_subset": "cha-eng",
                "languages": [
                    "cha-Latn",
                    "eng-Latn"
                ],
                "accuracy": 30.656934306569344,
                "f1": 23.2568647897115,
                "precision": 21.260309034031664,
                "recall": 30.656934306569344,
                "main_score": 23.2568647897115
            },
            {
                "hf_subset": "mhr-eng",
                "languages": [
                    "mhr-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 2.1999999999999997,
                "f1": 1.556861047295521,
                "precision": 1.4555993437238521,
                "recall": 2.1999999999999997,
                "main_score": 1.556861047295521
            },
            {
                "hf_subset": "dan-eng",
                "languages": [
                    "dan-Latn",
                    "eng-Latn"
                ],
                "accuracy": 27.500000000000004,
                "f1": 23.521682636223492,
                "precision": 22.345341306967683,
                "recall": 27.500000000000004,
                "main_score": 23.521682636223492
            },
            {
                "hf_subset": "ell-eng",
                "languages": [
                    "ell-Grek",
                    "eng-Latn"
                ],
                "accuracy": 7.3999999999999995,
                "f1": 5.344253880846173,
                "precision": 4.999794279068863,
                "recall": 7.3999999999999995,
                "main_score": 5.344253880846173
            },
            {
                "hf_subset": "amh-eng",
                "languages": [
                    "amh-Ethi",
                    "eng-Latn"
                ],
                "accuracy": 0.5952380952380952,
                "f1": 0.026455026455026457,
                "precision": 0.013528138528138528,
                "recall": 0.5952380952380952,
                "main_score": 0.026455026455026457
            },
            {
                "hf_subset": "pam-eng",
                "languages": [
                    "pam-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.3,
                "f1": 5.853140211779251,
                "precision": 5.505563080945322,
                "recall": 7.3,
                "main_score": 5.853140211779251
            },
            {
                "hf_subset": "hsb-eng",
                "languages": [
                    "hsb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 13.250517598343686,
                "f1": 9.676349506190704,
                "precision": 8.930392053553216,
                "recall": 13.250517598343686,
                "main_score": 9.676349506190704
            },
            {
                "hf_subset": "srp-eng",
                "languages": [
                    "srp-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 14.499999999999998,
                "f1": 11.68912588067557,
                "precision": 11.024716513105519,
                "recall": 14.499999999999998,
                "main_score": 11.68912588067557
            },
            {
                "hf_subset": "epo-eng",
                "languages": [
                    "epo-Latn",
                    "eng-Latn"
                ],
                "accuracy": 30.099999999999998,
                "f1": 26.196880936315146,
                "precision": 25.271714086169478,
                "recall": 30.099999999999998,
                "main_score": 26.196880936315146
            },
            {
                "hf_subset": "kzj-eng",
                "languages": [
                    "kzj-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.4,
                "f1": 5.1749445942023335,
                "precision": 4.975338142029625,
                "recall": 6.4,
                "main_score": 5.1749445942023335
            },
            {
                "hf_subset": "awa-eng",
                "languages": [
                    "awa-Deva",
                    "eng-Latn"
                ],
                "accuracy": 39.39393939393939,
                "f1": 35.005707393767096,
                "precision": 33.64342032053631,
                "recall": 39.39393939393939,
                "main_score": 35.005707393767096
            },
            {
                "hf_subset": "fao-eng",
                "languages": [
                    "fao-Latn",
                    "eng-Latn"
                ],
                "accuracy": 18.3206106870229,
                "f1": 12.610893447220345,
                "precision": 11.079228765297467,
                "recall": 18.3206106870229,
                "main_score": 12.610893447220345
            },
            {
                "hf_subset": "mal-eng",
                "languages": [
                    "mal-Mlym",
                    "eng-Latn"
                ],
                "accuracy": 85.58951965065502,
                "f1": 83.30363944928548,
                "precision": 82.40026591554977,
                "recall": 85.58951965065502,
                "main_score": 83.30363944928548
            },
            {
                "hf_subset": "ile-eng",
                "languages": [
                    "ile-Latn",
                    "eng-Latn"
                ],
                "accuracy": 65.7,
                "f1": 59.589642857142856,
                "precision": 57.392826797385624,
                "recall": 65.7,
                "main_score": 59.589642857142856
            },
            {
                "hf_subset": "bos-eng",
                "languages": [
                    "bos-Latn",
                    "eng-Latn"
                ],
                "accuracy": 18.07909604519774,
                "f1": 13.65194306689995,
                "precision": 12.567953943826327,
                "recall": 18.07909604519774,
                "main_score": 13.65194306689995
            },
            {
                "hf_subset": "cor-eng",
                "languages": [
                    "cor-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.6,
                "f1": 2.8335386392505013,
                "precision": 2.558444143575722,
                "recall": 4.6,
                "main_score": 2.8335386392505013
            },
            {
                "hf_subset": "cat-eng",
                "languages": [
                    "cat-Latn",
                    "eng-Latn"
                ],
                "accuracy": 90.7,
                "f1": 88.30666666666666,
                "precision": 87.195,
                "recall": 90.7,
                "main_score": 88.30666666666666
            },
            {
                "hf_subset": "eus-eng",
                "languages": [
                    "eus-Latn",
                    "eng-Latn"
                ],
                "accuracy": 57.699999999999996,
                "f1": 53.38433067253876,
                "precision": 51.815451335350346,
                "recall": 57.699999999999996,
                "main_score": 53.38433067253876
            },
            {
                "hf_subset": "yue-eng",
                "languages": [
                    "yue-Hant",
                    "eng-Latn"
                ],
                "accuracy": 80.60000000000001,
                "f1": 77.0290354090354,
                "precision": 75.61685897435898,
                "recall": 80.60000000000001,
                "main_score": 77.0290354090354
            },
            {
                "hf_subset": "swe-eng",
                "languages": [
                    "swe-Latn",
                    "eng-Latn"
                ],
                "accuracy": 24.6,
                "f1": 19.52814960069739,
                "precision": 18.169084599880502,
                "recall": 24.6,
                "main_score": 19.52814960069739
            },
            {
                "hf_subset": "dtp-eng",
                "languages": [
                    "dtp-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.0,
                "f1": 3.4078491753102376,
                "precision": 3.1757682319102387,
                "recall": 5.0,
                "main_score": 3.4078491753102376
            },
            {
                "hf_subset": "kat-eng",
                "languages": [
                    "kat-Geor",
                    "eng-Latn"
                ],
                "accuracy": 1.2064343163538873,
                "f1": 0.4224313053283095,
                "precision": 0.3360484946842894,
                "recall": 1.2064343163538873,
                "main_score": 0.4224313053283095
            },
            {
                "hf_subset": "jpn-eng",
                "languages": [
                    "jpn-Jpan",
                    "eng-Latn"
                ],
                "accuracy": 76.1,
                "f1": 71.36246031746032,
                "precision": 69.5086544011544,
                "recall": 76.1,
                "main_score": 71.36246031746032
            },
            {
                "hf_subset": "csb-eng",
                "languages": [
                    "csb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 14.229249011857709,
                "f1": 10.026578603653704,
                "precision": 9.09171178352764,
                "recall": 14.229249011857709,
                "main_score": 10.026578603653704
            },
            {
                "hf_subset": "xho-eng",
                "languages": [
                    "xho-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.450704225352112,
                "f1": 5.51214407186151,
                "precision": 4.928281812084629,
                "recall": 8.450704225352112,
                "main_score": 5.51214407186151
            },
            {
                "hf_subset": "orv-eng",
                "languages": [
                    "orv-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 7.664670658682635,
                "f1": 5.786190079917295,
                "precision": 5.3643643579244,
                "recall": 7.664670658682635,
                "main_score": 5.786190079917295
            },
            {
                "hf_subset": "ind-eng",
                "languages": [
                    "ind-Latn",
                    "eng-Latn"
                ],
                "accuracy": 90.5,
                "f1": 88.03999999999999,
                "precision": 86.94833333333334,
                "recall": 90.5,
                "main_score": 88.03999999999999
            },
            {
                "hf_subset": "tuk-eng",
                "languages": [
                    "tuk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.389162561576355,
                "f1": 5.482366349556517,
                "precision": 5.156814449917898,
                "recall": 7.389162561576355,
                "main_score": 5.482366349556517
            },
            {
                "hf_subset": "max-eng",
                "languages": [
                    "max-Deva",
                    "eng-Latn"
                ],
                "accuracy": 41.54929577464789,
                "f1": 36.13520282534367,
                "precision": 34.818226488560995,
                "recall": 41.54929577464789,
                "main_score": 36.13520282534367
            },
            {
                "hf_subset": "swh-eng",
                "languages": [
                    "swh-Latn",
                    "eng-Latn"
                ],
                "accuracy": 20.76923076923077,
                "f1": 16.742497560177643,
                "precision": 15.965759712090138,
                "recall": 20.76923076923077,
                "main_score": 16.742497560177643
            },
            {
                "hf_subset": "hin-eng",
                "languages": [
                    "hin-Deva",
                    "eng-Latn"
                ],
                "accuracy": 88.1,
                "f1": 85.23176470588236,
                "precision": 84.04458333333334,
                "recall": 88.1,
                "main_score": 85.23176470588236
            },
            {
                "hf_subset": "dsb-eng",
                "languages": [
                    "dsb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 11.899791231732777,
                "f1": 8.776706659565102,
                "precision": 8.167815946521582,
                "recall": 11.899791231732777,
                "main_score": 8.776706659565102
            },
            {
                "hf_subset": "ber-eng",
                "languages": [
                    "ber-Tfng",
                    "eng-Latn"
                ],
                "accuracy": 6.1,
                "f1": 4.916589537178435,
                "precision": 4.72523017415345,
                "recall": 6.1,
                "main_score": 4.916589537178435
            },
            {
                "hf_subset": "tam-eng",
                "languages": [
                    "tam-Taml",
                    "eng-Latn"
                ],
                "accuracy": 76.54723127035831,
                "f1": 72.75787187839306,
                "precision": 71.43338442869005,
                "recall": 76.54723127035831,
                "main_score": 72.75787187839306
            },
            {
                "hf_subset": "slk-eng",
                "languages": [
                    "slk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 11.700000000000001,
                "f1": 9.975679190026007,
                "precision": 9.569927715653522,
                "recall": 11.700000000000001,
                "main_score": 9.975679190026007
            },
            {
                "hf_subset": "tgl-eng",
                "languages": [
                    "tgl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 13.100000000000001,
                "f1": 10.697335850115408,
                "precision": 10.113816082086341,
                "recall": 13.100000000000001,
                "main_score": 10.697335850115408
            },
            {
                "hf_subset": "ast-eng",
                "languages": [
                    "ast-Latn",
                    "eng-Latn"
                ],
                "accuracy": 76.37795275590551,
                "f1": 71.12860892388451,
                "precision": 68.89763779527559,
                "recall": 76.37795275590551,
                "main_score": 71.12860892388451
            },
            {
                "hf_subset": "mkd-eng",
                "languages": [
                    "mkd-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 13.700000000000001,
                "f1": 10.471861684067568,
                "precision": 9.602902567641697,
                "recall": 13.700000000000001,
                "main_score": 10.471861684067568
            },
            {
                "hf_subset": "khm-eng",
                "languages": [
                    "khm-Khmr",
                    "eng-Latn"
                ],
                "accuracy": 0.554016620498615,
                "f1": 0.37034084643642423,
                "precision": 0.34676040281208437,
                "recall": 0.554016620498615,
                "main_score": 0.37034084643642423
            },
            {
                "hf_subset": "ces-eng",
                "languages": [
                    "ces-Latn",
                    "eng-Latn"
                ],
                "accuracy": 12.4,
                "f1": 9.552607451092534,
                "precision": 8.985175505050504,
                "recall": 12.4,
                "main_score": 9.552607451092534
            },
            {
                "hf_subset": "tzl-eng",
                "languages": [
                    "tzl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 33.65384615384615,
                "f1": 27.820512820512818,
                "precision": 26.09432234432234,
                "recall": 33.65384615384615,
                "main_score": 27.820512820512818
            },
            {
                "hf_subset": "urd-eng",
                "languages": [
                    "urd-Arab",
                    "eng-Latn"
                ],
                "accuracy": 74.5,
                "f1": 70.09686507936507,
                "precision": 68.3117857142857,
                "recall": 74.5,
                "main_score": 70.09686507936507
            },
            {
                "hf_subset": "ara-eng",
                "languages": [
                    "ara-Arab",
                    "eng-Latn"
                ],
                "accuracy": 88.3,
                "f1": 85.37333333333333,
                "precision": 84.05833333333334,
                "recall": 88.3,
                "main_score": 85.37333333333333
            },
            {
                "hf_subset": "kor-eng",
                "languages": [
                    "kor-Hang",
                    "eng-Latn"
                ],
                "accuracy": 25.0,
                "f1": 22.393124632031995,
                "precision": 21.58347686592367,
                "recall": 25.0,
                "main_score": 22.393124632031995
            },
            {
                "hf_subset": "yid-eng",
                "languages": [
                    "yid-Hebr",
                    "eng-Latn"
                ],
                "accuracy": 0.589622641509434,
                "f1": 0.15804980033762941,
                "precision": 0.1393275384872965,
                "recall": 0.589622641509434,
                "main_score": 0.15804980033762941
            },
            {
                "hf_subset": "fin-eng",
                "languages": [
                    "fin-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.1000000000000005,
                "f1": 3.4069011332551775,
                "precision": 3.1784507042253516,
                "recall": 4.1000000000000005,
                "main_score": 3.4069011332551775
            },
            {
                "hf_subset": "tha-eng",
                "languages": [
                    "tha-Thai",
                    "eng-Latn"
                ],
                "accuracy": 3.102189781021898,
                "f1": 2.223851811694751,
                "precision": 2.103465682299194,
                "recall": 3.102189781021898,
                "main_score": 2.223851811694751
            },
            {
                "hf_subset": "wuu-eng",
                "languages": [
                    "wuu-Hans",
                    "eng-Latn"
                ],
                "accuracy": 83.1,
                "f1": 79.58255835667599,
                "precision": 78.09708333333333,
                "recall": 83.1,
                "main_score": 79.58255835667599
            }
        ]
    }
}