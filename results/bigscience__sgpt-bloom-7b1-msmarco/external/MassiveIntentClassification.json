{
    "dataset_revision": "072a486a144adf7f4479a4a0dddb2152e161e1ea",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": -1,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 47.85474108944183,
                "f1": 46.50175016795915,
                "main_score": 47.85474108944183
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 33.29858776059179,
                "f1": 31.803027601259082,
                "main_score": 33.29858776059179
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 59.24680564895763,
                "f1": 57.037691806846865,
                "main_score": 59.24680564895763
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 45.23537323470073,
                "f1": 44.81126398428613,
                "main_score": 45.23537323470073
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 61.590450571620714,
                "f1": 59.247442149977104,
                "main_score": 61.590450571620714
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 44.9226630800269,
                "f1": 44.076183379991654,
                "main_score": 44.9226630800269
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 51.23066577000672,
                "f1": 50.20719330417618,
                "main_score": 51.23066577000672
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 56.0995292535306,
                "f1": 53.29421532133969,
                "main_score": 56.0995292535306
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 46.12642905178211,
                "f1": 44.441530267639635,
                "main_score": 46.12642905178211
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 69.67047747141896,
                "f1": 68.38493366054783,
                "main_score": 69.67047747141896
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 66.3483523873571,
                "f1": 65.13046416817832,
                "main_score": 66.3483523873571
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 51.20040349697378,
                "f1": 49.02889836601541,
                "main_score": 51.20040349697378
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 45.33288500336248,
                "f1": 42.91893101970983,
                "main_score": 45.33288500336248
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 66.95359784801613,
                "f1": 64.98788914810562,
                "main_score": 66.95359784801613
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 43.18090114324143,
                "f1": 41.31250407417542,
                "main_score": 43.18090114324143
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 63.54068594485541,
                "f1": 61.94829361488948,
                "main_score": 63.54068594485541
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 44.7343644922663,
                "f1": 43.23001702247849,
                "main_score": 44.7343644922663
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 38.1271015467384,
                "f1": 36.94700198241727,
                "main_score": 38.1271015467384
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 64.05514458641561,
                "f1": 62.35033731674541,
                "main_score": 64.05514458641561
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 44.351042367182245,
                "f1": 43.13370397574502,
                "main_score": 44.351042367182245
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 60.77000672494955,
                "f1": 59.71546868957779,
                "main_score": 60.77000672494955
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 61.22057834566241,
                "f1": 59.447639306287044,
                "main_score": 61.22057834566241
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 50.9448554135844,
                "f1": 48.524338247875214,
                "main_score": 50.9448554135844
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 33.8399462004035,
                "f1": 33.518999997305535,
                "main_score": 33.8399462004035
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 37.34028244788165,
                "f1": 35.6156599064704,
                "main_score": 37.34028244788165
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 53.544048419636844,
                "f1": 51.29299915455352,
                "main_score": 53.544048419636844
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 53.35574983187625,
                "f1": 51.463936565192945,
                "main_score": 53.35574983187625
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 46.503026227303295,
                "f1": 46.049497734375514,
                "main_score": 46.503026227303295
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 58.268325487558826,
                "f1": 56.10849656896158,
                "main_score": 58.268325487558826
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 40.27572293207801,
                "f1": 40.20097238549224,
                "main_score": 40.27572293207801
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 59.64694014794889,
                "f1": 58.39584148789066,
                "main_score": 59.64694014794889
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 37.41761936785474,
                "f1": 35.04551731363685,
                "main_score": 37.41761936785474
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 49.408204438466704,
                "f1": 48.39369057638714,
                "main_score": 49.408204438466704
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 52.09482178883659,
                "f1": 49.91518031712698,
                "main_score": 52.09482178883659
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 50.477471418964356,
                "f1": 48.429495257184705,
                "main_score": 50.477471418964356
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 66.69468728984532,
                "f1": 65.40306868707009,
                "main_score": 66.69468728984532
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 50.52790854068594,
                "f1": 49.780400354514,
                "main_score": 50.52790854068594
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 58.31540013449899,
                "f1": 56.144142926685134,
                "main_score": 58.31540013449899
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 47.74041694687289,
                "f1": 46.16767322761359,
                "main_score": 47.74041694687289
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 48.94418291862811,
                "f1": 48.445352284756325,
                "main_score": 48.94418291862811
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 50.78681909885676,
                "f1": 49.64882295494536,
                "main_score": 50.78681909885676
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 49.811701412239415,
                "f1": 48.213234514449375,
                "main_score": 49.811701412239415
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 56.39542703429725,
                "f1": 54.031981085233795,
                "main_score": 56.39542703429725
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 54.71082716879623,
                "f1": 52.513144113474596,
                "main_score": 54.71082716879623
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 44.425016812373904,
                "f1": 43.96016300057656,
                "main_score": 44.425016812373904
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 50.205110961667785,
                "f1": 48.86669996798709,
                "main_score": 50.205110961667785
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 46.56355077336921,
                "f1": 45.18252022585022,
                "main_score": 46.56355077336921
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 56.748486886348346,
                "f1": 54.29884570375382,
                "main_score": 56.748486886348346
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 64.52589105581708,
                "f1": 62.97947342861603,
                "main_score": 64.52589105581708
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 67.06792199058508,
                "f1": 65.36025601634017,
                "main_score": 67.06792199058508
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 62.89172831203766,
                "f1": 62.69803707054342,
                "main_score": 62.89172831203766
            }
        ]
    }
}