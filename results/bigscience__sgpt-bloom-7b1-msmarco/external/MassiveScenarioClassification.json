{
    "dataset_revision": "7d571f92784cd94a019292a1f45445077d0ef634",
    "task_name": "MassiveScenarioClassification",
    "evaluation_time": NaN,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 51.47276395427035,
                "f1": 49.37463208130799,
                "main_score": 51.47276395427035
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 34.86886348352387,
                "f1": 33.74178074349636,
                "main_score": 34.86886348352387
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 65.20511096166778,
                "f1": 65.85812500602437,
                "main_score": 65.20511096166778
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 45.578345662407536,
                "f1": 44.44514917028003,
                "main_score": 45.578345662407536
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 67.29657027572293,
                "f1": 67.24477523937466,
                "main_score": 67.29657027572293
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 46.29455279085407,
                "f1": 43.8563839951935,
                "main_score": 46.29455279085407
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 53.52387357094821,
                "f1": 51.70977848027552,
                "main_score": 53.52387357094821
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 61.741761936785466,
                "f1": 60.219169644792295,
                "main_score": 61.741761936785466
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 48.957632817753876,
                "f1": 46.878428264460034,
                "main_score": 48.957632817753876
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 75.33624747814393,
                "f1": 75.9143846211171,
                "main_score": 75.33624747814393
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 73.34229993275049,
                "f1": 73.78165397558983,
                "main_score": 73.34229993275049
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 53.174176193678555,
                "f1": 51.709679227778985,
                "main_score": 53.174176193678555
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 44.6906523201076,
                "f1": 41.54881682785664,
                "main_score": 44.6906523201076
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 72.9119031607263,
                "f1": 73.2742013056326,
                "main_score": 72.9119031607263
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 43.10356422326832,
                "f1": 40.8859122581252,
                "main_score": 43.10356422326832
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 69.27370544720914,
                "f1": 69.39544506405082,
                "main_score": 69.27370544720914
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 45.16476126429052,
                "f1": 42.74022531579054,
                "main_score": 45.16476126429052
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 38.73234700739744,
                "f1": 37.40546754951026,
                "main_score": 38.73234700739744
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 70.12777404169468,
                "f1": 70.27219152812738,
                "main_score": 70.12777404169468
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 44.21318090114325,
                "f1": 41.934593213829366,
                "main_score": 44.21318090114325
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 65.57162071284466,
                "f1": 64.83341759045335,
                "main_score": 65.57162071284466
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 65.75991930060525,
                "f1": 65.16549875504951,
                "main_score": 65.75991930060525
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 54.79488903833223,
                "f1": 54.03616401426859,
                "main_score": 54.79488903833223
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 32.992602555480836,
                "f1": 31.820068470018846,
                "main_score": 32.992602555480836
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 39.34431741761937,
                "f1": 36.436221665290105,
                "main_score": 39.34431741761937
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 60.501008742434436,
                "f1": 60.051013712579085,
                "main_score": 60.501008742434436
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 55.689307330195035,
                "f1": 53.94058032286942,
                "main_score": 55.689307330195035
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 44.351042367182245,
                "f1": 42.05421666771541,
                "main_score": 44.351042367182245
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 65.53127101546738,
                "f1": 65.98462024333497,
                "main_score": 65.53127101546738
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 38.71553463349025,
                "f1": 37.44327037149584,
                "main_score": 38.71553463349025
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 64.98991257565567,
                "f1": 63.87720198978004,
                "main_score": 64.98991257565567
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 36.839273705447205,
                "f1": 35.233967279698376,
                "main_score": 36.839273705447205
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 51.79892400806993,
                "f1": 49.66926632125972,
                "main_score": 51.79892400806993
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 56.31809011432415,
                "f1": 53.832185336179826,
                "main_score": 56.31809011432415
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 49.979825151311374,
                "f1": 48.83013175441888,
                "main_score": 49.979825151311374
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 71.45595158036315,
                "f1": 72.08708814699702,
                "main_score": 71.45595158036315
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 53.68527236045729,
                "f1": 52.23278593929981,
                "main_score": 53.68527236045729
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 61.60390047074647,
                "f1": 60.50391482195116,
                "main_score": 61.60390047074647
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 48.036314727639535,
                "f1": 46.43480413383716,
                "main_score": 48.036314727639535
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 50.05716207128445,
                "f1": 48.85821859948888,
                "main_score": 50.05716207128445
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 51.728312037659705,
                "f1": 49.89292996950847,
                "main_score": 51.728312037659705
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 54.21990585070613,
                "f1": 52.8711542984193,
                "main_score": 54.21990585070613
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 62.770679219905844,
                "f1": 63.09441501491594,
                "main_score": 62.770679219905844
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 62.58574310692671,
                "f1": 61.61370697612978,
                "main_score": 62.58574310692671
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 45.17821116341628,
                "f1": 43.85143229183324,
                "main_score": 45.17821116341628
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 52.064559515803644,
                "f1": 50.94356892049626,
                "main_score": 52.064559515803644
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 47.205783456624076,
                "f1": 47.04223644120489,
                "main_score": 47.205783456624076
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 64.25689307330195,
                "f1": 63.89944944984115,
                "main_score": 64.25689307330195
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 70.60524546065905,
                "f1": 71.5634157334358,
                "main_score": 70.60524546065905
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 73.95427034297242,
                "f1": 74.39706882311063,
                "main_score": 73.95427034297242
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 70.29926025554808,
                "f1": 71.32045932560297,
                "main_score": 70.29926025554808
            }
        ]
    }
}