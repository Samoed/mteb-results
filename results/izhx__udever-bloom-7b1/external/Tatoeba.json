{
    "dataset_revision": "9080400076fbadbb4c4dcb136ff4eddc40b42553",
    "task_name": "Tatoeba",
    "evaluation_time": -1,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "sqi-eng",
                "languages": [
                    "sqi-Latn",
                    "eng-Latn"
                ],
                "accuracy": 19.0,
                "f1": 15.331629955575188,
                "precision": 14.38509724403208,
                "recall": 19.0,
                "main_score": 15.331629955575188
            },
            {
                "hf_subset": "fry-eng",
                "languages": [
                    "fry-Latn",
                    "eng-Latn"
                ],
                "accuracy": 39.884393063583815,
                "f1": 32.369942196531795,
                "precision": 30.036929993577395,
                "recall": 39.884393063583815,
                "main_score": 32.369942196531795
            },
            {
                "hf_subset": "kur-eng",
                "languages": [
                    "kur-Latn",
                    "eng-Latn"
                ],
                "accuracy": 15.365853658536585,
                "f1": 12.49755078527547,
                "precision": 11.840415442997939,
                "recall": 15.365853658536585,
                "main_score": 12.49755078527547
            },
            {
                "hf_subset": "tur-eng",
                "languages": [
                    "tur-Latn",
                    "eng-Latn"
                ],
                "accuracy": 11.1,
                "f1": 8.955359175928436,
                "precision": 8.324461412770235,
                "recall": 11.1,
                "main_score": 8.955359175928436
            },
            {
                "hf_subset": "deu-eng",
                "languages": [
                    "deu-Latn",
                    "eng-Latn"
                ],
                "accuracy": 87.7,
                "f1": 85.06214285714286,
                "precision": 83.98761904761905,
                "recall": 87.7,
                "main_score": 85.06214285714286
            },
            {
                "hf_subset": "nld-eng",
                "languages": [
                    "nld-Latn",
                    "eng-Latn"
                ],
                "accuracy": 56.00000000000001,
                "f1": 49.8456850459482,
                "precision": 47.80084415584415,
                "recall": 56.00000000000001,
                "main_score": 49.8456850459482
            },
            {
                "hf_subset": "ron-eng",
                "languages": [
                    "ron-Latn",
                    "eng-Latn"
                ],
                "accuracy": 38.1,
                "f1": 33.85465329991646,
                "precision": 32.37519841269841,
                "recall": 38.1,
                "main_score": 33.85465329991646
            },
            {
                "hf_subset": "ang-eng",
                "languages": [
                    "ang-Latn",
                    "eng-Latn"
                ],
                "accuracy": 42.53731343283582,
                "f1": 34.67903986560703,
                "precision": 32.17128642501776,
                "recall": 42.53731343283582,
                "main_score": 34.67903986560703
            },
            {
                "hf_subset": "ido-eng",
                "languages": [
                    "ido-Latn",
                    "eng-Latn"
                ],
                "accuracy": 53.900000000000006,
                "f1": 47.83909812409812,
                "precision": 45.67887667887668,
                "recall": 53.900000000000006,
                "main_score": 47.83909812409812
            },
            {
                "hf_subset": "jav-eng",
                "languages": [
                    "jav-Latn",
                    "eng-Latn"
                ],
                "accuracy": 26.34146341463415,
                "f1": 22.264125162260022,
                "precision": 21.384015912351636,
                "recall": 26.34146341463415,
                "main_score": 22.264125162260022
            },
            {
                "hf_subset": "isl-eng",
                "languages": [
                    "isl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 10.2,
                "f1": 8.001233870597419,
                "precision": 7.383838204560821,
                "recall": 10.2,
                "main_score": 8.001233870597419
            },
            {
                "hf_subset": "slv-eng",
                "languages": [
                    "slv-Latn",
                    "eng-Latn"
                ],
                "accuracy": 17.253948967193196,
                "f1": 13.055189087650387,
                "precision": 12.105642744272275,
                "recall": 17.253948967193196,
                "main_score": 13.055189087650387
            },
            {
                "hf_subset": "cym-eng",
                "languages": [
                    "cym-Latn",
                    "eng-Latn"
                ],
                "accuracy": 10.26086956521739,
                "f1": 8.31837824011737,
                "precision": 7.879315672736052,
                "recall": 10.26086956521739,
                "main_score": 8.31837824011737
            },
            {
                "hf_subset": "kaz-eng",
                "languages": [
                    "kaz-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 11.826086956521738,
                "f1": 9.663030581871162,
                "precision": 9.152605557273077,
                "recall": 11.826086956521738,
                "main_score": 9.663030581871162
            },
            {
                "hf_subset": "est-eng",
                "languages": [
                    "est-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.800000000000001,
                "f1": 5.608697757594542,
                "precision": 5.333727335466467,
                "recall": 6.800000000000001,
                "main_score": 5.608697757594542
            },
            {
                "hf_subset": "heb-eng",
                "languages": [
                    "heb-Hebr",
                    "eng-Latn"
                ],
                "accuracy": 11.3,
                "f1": 7.4866384899217335,
                "precision": 6.580321536442861,
                "recall": 11.3,
                "main_score": 7.4866384899217335
            },
            {
                "hf_subset": "gla-eng",
                "languages": [
                    "gla-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.101326899879373,
                "f1": 3.0988364784130122,
                "precision": 2.925923150618102,
                "recall": 4.101326899879373,
                "main_score": 3.0988364784130122
            },
            {
                "hf_subset": "mar-eng",
                "languages": [
                    "mar-Deva",
                    "eng-Latn"
                ],
                "accuracy": 76.3,
                "f1": 71.55912698412699,
                "precision": 69.55511904761904,
                "recall": 76.3,
                "main_score": 71.55912698412699
            },
            {
                "hf_subset": "lat-eng",
                "languages": [
                    "lat-Latn",
                    "eng-Latn"
                ],
                "accuracy": 53.6,
                "f1": 46.74811085685228,
                "precision": 44.41049616018656,
                "recall": 53.6,
                "main_score": 46.74811085685228
            },
            {
                "hf_subset": "bel-eng",
                "languages": [
                    "bel-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 23.400000000000002,
                "f1": 18.485309948823105,
                "precision": 17.12104734130107,
                "recall": 23.400000000000002,
                "main_score": 18.485309948823105
            },
            {
                "hf_subset": "pms-eng",
                "languages": [
                    "pms-Latn",
                    "eng-Latn"
                ],
                "accuracy": 41.523809523809526,
                "f1": 36.577269291555005,
                "precision": 35.00219198790627,
                "recall": 41.523809523809526,
                "main_score": 36.577269291555005
            },
            {
                "hf_subset": "gle-eng",
                "languages": [
                    "gle-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.9,
                "f1": 3.909842412258181,
                "precision": 3.7099694121032796,
                "recall": 4.9,
                "main_score": 3.909842412258181
            },
            {
                "hf_subset": "pes-eng",
                "languages": [
                    "pes-Arab",
                    "eng-Latn"
                ],
                "accuracy": 26.900000000000002,
                "f1": 21.587309161426806,
                "precision": 19.877234126984124,
                "recall": 26.900000000000002,
                "main_score": 21.587309161426806
            },
            {
                "hf_subset": "nob-eng",
                "languages": [
                    "nob-Latn",
                    "eng-Latn"
                ],
                "accuracy": 37.3,
                "f1": 31.940531675926408,
                "precision": 30.414405457464277,
                "recall": 37.3,
                "main_score": 31.940531675926408
            },
            {
                "hf_subset": "bul-eng",
                "languages": [
                    "bul-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 34.4,
                "f1": 28.460500740394355,
                "precision": 26.630818170746558,
                "recall": 34.4,
                "main_score": 28.460500740394355
            },
            {
                "hf_subset": "cbk-eng",
                "languages": [
                    "cbk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 67.5,
                "f1": 61.492367158984806,
                "precision": 59.23266755904913,
                "recall": 67.5,
                "main_score": 61.492367158984806
            },
            {
                "hf_subset": "hun-eng",
                "languages": [
                    "hun-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.9,
                "f1": 6.652063929922994,
                "precision": 6.392931096681097,
                "recall": 7.9,
                "main_score": 6.652063929922994
            },
            {
                "hf_subset": "uig-eng",
                "languages": [
                    "uig-Arab",
                    "eng-Latn"
                ],
                "accuracy": 2.6,
                "f1": 2.0216271963330783,
                "precision": 1.9467343791901313,
                "recall": 2.6,
                "main_score": 2.0216271963330783
            },
            {
                "hf_subset": "rus-eng",
                "languages": [
                    "rus-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 76.6,
                "f1": 71.23357142857142,
                "precision": 69.03261904761905,
                "recall": 76.6,
                "main_score": 71.23357142857142
            },
            {
                "hf_subset": "spa-eng",
                "languages": [
                    "spa-Latn",
                    "eng-Latn"
                ],
                "accuracy": 98.6,
                "f1": 98.13333333333333,
                "precision": 97.89999999999999,
                "recall": 98.6,
                "main_score": 98.13333333333333
            },
            {
                "hf_subset": "hye-eng",
                "languages": [
                    "hye-Armn",
                    "eng-Latn"
                ],
                "accuracy": 1.8867924528301887,
                "f1": 0.9184016421339141,
                "precision": 0.8343646123610833,
                "recall": 1.8867924528301887,
                "main_score": 0.9184016421339141
            },
            {
                "hf_subset": "tel-eng",
                "languages": [
                    "tel-Telu",
                    "eng-Latn"
                ],
                "accuracy": 84.1880341880342,
                "f1": 80.56369556369557,
                "precision": 79.02421652421653,
                "recall": 84.1880341880342,
                "main_score": 80.56369556369557
            },
            {
                "hf_subset": "afr-eng",
                "languages": [
                    "afr-Latn",
                    "eng-Latn"
                ],
                "accuracy": 27.200000000000003,
                "f1": 22.55873107448107,
                "precision": 21.13610950874723,
                "recall": 27.200000000000003,
                "main_score": 22.55873107448107
            },
            {
                "hf_subset": "mon-eng",
                "languages": [
                    "mon-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 9.090909090909092,
                "f1": 7.37323521273764,
                "precision": 7.01229523252768,
                "recall": 9.090909090909092,
                "main_score": 7.37323521273764
            },
            {
                "hf_subset": "arz-eng",
                "languages": [
                    "arz-Arab",
                    "eng-Latn"
                ],
                "accuracy": 79.24528301886792,
                "f1": 74.80483178596387,
                "precision": 72.8336827393431,
                "recall": 79.24528301886792,
                "main_score": 74.80483178596387
            },
            {
                "hf_subset": "hrv-eng",
                "languages": [
                    "hrv-Latn",
                    "eng-Latn"
                ],
                "accuracy": 21.3,
                "f1": 17.754399705471684,
                "precision": 16.81516621898026,
                "recall": 21.3,
                "main_score": 17.754399705471684
            },
            {
                "hf_subset": "nov-eng",
                "languages": [
                    "nov-Latn",
                    "eng-Latn"
                ],
                "accuracy": 59.92217898832685,
                "f1": 54.92807451951421,
                "precision": 53.071150639244024,
                "recall": 59.92217898832685,
                "main_score": 54.92807451951421
            },
            {
                "hf_subset": "gsw-eng",
                "languages": [
                    "gsw-Latn",
                    "eng-Latn"
                ],
                "accuracy": 30.76923076923077,
                "f1": 23.70099036765703,
                "precision": 21.666666666666664,
                "recall": 30.76923076923077,
                "main_score": 23.70099036765703
            },
            {
                "hf_subset": "nds-eng",
                "languages": [
                    "nds-Latn",
                    "eng-Latn"
                ],
                "accuracy": 35.6,
                "f1": 29.87713276919159,
                "precision": 28.07062211509473,
                "recall": 35.6,
                "main_score": 29.87713276919159
            },
            {
                "hf_subset": "ukr-eng",
                "languages": [
                    "ukr-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 38.1,
                "f1": 31.123585858585855,
                "precision": 28.995893769823304,
                "recall": 38.1,
                "main_score": 31.123585858585855
            },
            {
                "hf_subset": "uzb-eng",
                "languages": [
                    "uzb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 10.74766355140187,
                "f1": 8.280338473537247,
                "precision": 7.806134675293554,
                "recall": 10.74766355140187,
                "main_score": 8.280338473537247
            },
            {
                "hf_subset": "lit-eng",
                "languages": [
                    "lit-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.6,
                "f1": 5.872095040470223,
                "precision": 5.557777361527362,
                "recall": 7.6,
                "main_score": 5.872095040470223
            },
            {
                "hf_subset": "ina-eng",
                "languages": [
                    "ina-Latn",
                    "eng-Latn"
                ],
                "accuracy": 86.8,
                "f1": 83.72833333333332,
                "precision": 82.4259523809524,
                "recall": 86.8,
                "main_score": 83.72833333333332
            },
            {
                "hf_subset": "lfn-eng",
                "languages": [
                    "lfn-Latn",
                    "eng-Latn"
                ],
                "accuracy": 52.0,
                "f1": 46.48058132211534,
                "precision": 44.52753032676945,
                "recall": 52.0,
                "main_score": 46.48058132211534
            },
            {
                "hf_subset": "zsm-eng",
                "languages": [
                    "zsm-Latn",
                    "eng-Latn"
                ],
                "accuracy": 90.4,
                "f1": 88.10999999999999,
                "precision": 87.10333333333334,
                "recall": 90.4,
                "main_score": 88.10999999999999
            },
            {
                "hf_subset": "ita-eng",
                "languages": [
                    "ita-Latn",
                    "eng-Latn"
                ],
                "accuracy": 79.5,
                "f1": 74.95746031746032,
                "precision": 73.03249999999998,
                "recall": 79.5,
                "main_score": 74.95746031746032
            },
            {
                "hf_subset": "cmn-eng",
                "languages": [
                    "cmn-Hans",
                    "eng-Latn"
                ],
                "accuracy": 96.7,
                "f1": 95.7,
                "precision": 95.21666666666667,
                "recall": 96.7,
                "main_score": 95.7
            },
            {
                "hf_subset": "lvs-eng",
                "languages": [
                    "lvs-Latn",
                    "eng-Latn"
                ],
                "accuracy": 10.7,
                "f1": 8.576412755390276,
                "precision": 8.046714349557488,
                "recall": 10.7,
                "main_score": 8.576412755390276
            },
            {
                "hf_subset": "glg-eng",
                "languages": [
                    "glg-Latn",
                    "eng-Latn"
                ],
                "accuracy": 86.0,
                "f1": 82.54523809523809,
                "precision": 81.06166666666665,
                "recall": 86.0,
                "main_score": 82.54523809523809
            },
            {
                "hf_subset": "ceb-eng",
                "languages": [
                    "ceb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 11.0,
                "f1": 9.080509354193564,
                "precision": 8.57587968815845,
                "recall": 11.0,
                "main_score": 9.080509354193564
            },
            {
                "hf_subset": "bre-eng",
                "languages": [
                    "bre-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.6,
                "f1": 7.409451659451658,
                "precision": 6.8121069441897415,
                "recall": 9.6,
                "main_score": 7.409451659451658
            },
            {
                "hf_subset": "ben-eng",
                "languages": [
                    "ben-Beng",
                    "eng-Latn"
                ],
                "accuracy": 87.1,
                "f1": 83.88999999999999,
                "precision": 82.395,
                "recall": 87.1,
                "main_score": 83.88999999999999
            },
            {
                "hf_subset": "swg-eng",
                "languages": [
                    "swg-Latn",
                    "eng-Latn"
                ],
                "accuracy": 34.82142857142857,
                "f1": 29.175170068027214,
                "precision": 27.40499084249084,
                "recall": 34.82142857142857,
                "main_score": 29.175170068027214
            },
            {
                "hf_subset": "arq-eng",
                "languages": [
                    "arq-Arab",
                    "eng-Latn"
                ],
                "accuracy": 42.9198682766191,
                "f1": 37.21120707205811,
                "precision": 35.23526784229309,
                "recall": 42.9198682766191,
                "main_score": 37.21120707205811
            },
            {
                "hf_subset": "kab-eng",
                "languages": [
                    "kab-Latn",
                    "eng-Latn"
                ],
                "accuracy": 2.3,
                "f1": 1.5401826425879608,
                "precision": 1.424235527544351,
                "recall": 2.3,
                "main_score": 1.5401826425879608
            },
            {
                "hf_subset": "fra-eng",
                "languages": [
                    "fra-Latn",
                    "eng-Latn"
                ],
                "accuracy": 95.6,
                "f1": 94.32333333333334,
                "precision": 93.72500000000001,
                "recall": 95.6,
                "main_score": 94.32333333333334
            },
            {
                "hf_subset": "por-eng",
                "languages": [
                    "por-Latn",
                    "eng-Latn"
                ],
                "accuracy": 95.5,
                "f1": 94.43333333333334,
                "precision": 93.89999999999999,
                "recall": 95.5,
                "main_score": 94.43333333333334
            },
            {
                "hf_subset": "tat-eng",
                "languages": [
                    "tat-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 6.7,
                "f1": 4.9622522983552395,
                "precision": 4.528962761017515,
                "recall": 6.7,
                "main_score": 4.9622522983552395
            },
            {
                "hf_subset": "oci-eng",
                "languages": [
                    "oci-Latn",
                    "eng-Latn"
                ],
                "accuracy": 50.8,
                "f1": 45.736438587556236,
                "precision": 44.010822829131655,
                "recall": 50.8,
                "main_score": 45.736438587556236
            },
            {
                "hf_subset": "pol-eng",
                "languages": [
                    "pol-Latn",
                    "eng-Latn"
                ],
                "accuracy": 23.9,
                "f1": 20.267261904761906,
                "precision": 19.16142408316321,
                "recall": 23.9,
                "main_score": 20.267261904761906
            },
            {
                "hf_subset": "war-eng",
                "languages": [
                    "war-Latn",
                    "eng-Latn"
                ],
                "accuracy": 13.4,
                "f1": 11.232209832252995,
                "precision": 10.714445160103056,
                "recall": 13.4,
                "main_score": 11.232209832252995
            },
            {
                "hf_subset": "aze-eng",
                "languages": [
                    "aze-Latn",
                    "eng-Latn"
                ],
                "accuracy": 10.299999999999999,
                "f1": 8.161916387744503,
                "precision": 7.678631905405786,
                "recall": 10.299999999999999,
                "main_score": 8.161916387744503
            },
            {
                "hf_subset": "vie-eng",
                "languages": [
                    "vie-Latn",
                    "eng-Latn"
                ],
                "accuracy": 96.7,
                "f1": 95.83333333333334,
                "precision": 95.41666666666667,
                "recall": 96.7,
                "main_score": 95.83333333333334
            },
            {
                "hf_subset": "nno-eng",
                "languages": [
                    "nno-Latn",
                    "eng-Latn"
                ],
                "accuracy": 24.9,
                "f1": 20.794749162495066,
                "precision": 19.575997295469914,
                "recall": 24.9,
                "main_score": 20.794749162495066
            },
            {
                "hf_subset": "cha-eng",
                "languages": [
                    "cha-Latn",
                    "eng-Latn"
                ],
                "accuracy": 32.11678832116788,
                "f1": 26.960375391032326,
                "precision": 25.498078211502524,
                "recall": 32.11678832116788,
                "main_score": 26.960375391032326
            },
            {
                "hf_subset": "mhr-eng",
                "languages": [
                    "mhr-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 4.9,
                "f1": 3.251889552842259,
                "precision": 2.9281137342615295,
                "recall": 4.9,
                "main_score": 3.251889552842259
            },
            {
                "hf_subset": "dan-eng",
                "languages": [
                    "dan-Latn",
                    "eng-Latn"
                ],
                "accuracy": 38.9,
                "f1": 33.59595154442981,
                "precision": 31.906759791342587,
                "recall": 38.9,
                "main_score": 33.59595154442981
            },
            {
                "hf_subset": "ell-eng",
                "languages": [
                    "ell-Grek",
                    "eng-Latn"
                ],
                "accuracy": 16.900000000000002,
                "f1": 13.082818919542666,
                "precision": 12.125554724968518,
                "recall": 16.900000000000002,
                "main_score": 13.082818919542666
            },
            {
                "hf_subset": "amh-eng",
                "languages": [
                    "amh-Ethi",
                    "eng-Latn"
                ],
                "accuracy": 0.5952380952380952,
                "f1": 0.09920634920634923,
                "precision": 0.05411255411255411,
                "recall": 0.5952380952380952,
                "main_score": 0.09920634920634923
            },
            {
                "hf_subset": "pam-eng",
                "languages": [
                    "pam-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.1,
                "f1": 7.033911671727207,
                "precision": 6.759952905986985,
                "recall": 8.1,
                "main_score": 7.033911671727207
            },
            {
                "hf_subset": "hsb-eng",
                "languages": [
                    "hsb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 16.149068322981368,
                "f1": 13.314287609382625,
                "precision": 12.588291889534126,
                "recall": 16.149068322981368,
                "main_score": 13.314287609382625
            },
            {
                "hf_subset": "srp-eng",
                "languages": [
                    "srp-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 22.3,
                "f1": 18.754672526177103,
                "precision": 17.77463320976479,
                "recall": 22.3,
                "main_score": 18.754672526177103
            },
            {
                "hf_subset": "epo-eng",
                "languages": [
                    "epo-Latn",
                    "eng-Latn"
                ],
                "accuracy": 39.5,
                "f1": 33.91659439373835,
                "precision": 32.244738455988454,
                "recall": 39.5,
                "main_score": 33.91659439373835
            },
            {
                "hf_subset": "kzj-eng",
                "languages": [
                    "kzj-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.5,
                "f1": 6.300929449087343,
                "precision": 6.05555758176835,
                "recall": 7.5,
                "main_score": 6.300929449087343
            },
            {
                "hf_subset": "awa-eng",
                "languages": [
                    "awa-Deva",
                    "eng-Latn"
                ],
                "accuracy": 57.14285714285714,
                "f1": 53.011353725639445,
                "precision": 51.78829107400536,
                "recall": 57.14285714285714,
                "main_score": 53.011353725639445
            },
            {
                "hf_subset": "fao-eng",
                "languages": [
                    "fao-Latn",
                    "eng-Latn"
                ],
                "accuracy": 16.030534351145036,
                "f1": 14.424487352192786,
                "precision": 13.98739301411057,
                "recall": 16.030534351145036,
                "main_score": 14.424487352192786
            },
            {
                "hf_subset": "mal-eng",
                "languages": [
                    "mal-Mlym",
                    "eng-Latn"
                ],
                "accuracy": 96.21542940320232,
                "f1": 95.0509461426492,
                "precision": 94.46870451237264,
                "recall": 96.21542940320232,
                "main_score": 95.0509461426492
            },
            {
                "hf_subset": "ile-eng",
                "languages": [
                    "ile-Latn",
                    "eng-Latn"
                ],
                "accuracy": 69.1,
                "f1": 63.649573934837086,
                "precision": 61.44357142857143,
                "recall": 69.1,
                "main_score": 63.649573934837086
            },
            {
                "hf_subset": "bos-eng",
                "languages": [
                    "bos-Latn",
                    "eng-Latn"
                ],
                "accuracy": 23.728813559322035,
                "f1": 19.281200536513545,
                "precision": 18.11042731593579,
                "recall": 23.728813559322035,
                "main_score": 19.281200536513545
            },
            {
                "hf_subset": "cor-eng",
                "languages": [
                    "cor-Latn",
                    "eng-Latn"
                ],
                "accuracy": 4.9,
                "f1": 3.8602777777777777,
                "precision": 3.553962393468025,
                "recall": 4.9,
                "main_score": 3.8602777777777777
            },
            {
                "hf_subset": "cat-eng",
                "languages": [
                    "cat-Latn",
                    "eng-Latn"
                ],
                "accuracy": 92.10000000000001,
                "f1": 90.24190476190476,
                "precision": 89.41666666666667,
                "recall": 92.10000000000001,
                "main_score": 90.24190476190476
            },
            {
                "hf_subset": "eus-eng",
                "languages": [
                    "eus-Latn",
                    "eng-Latn"
                ],
                "accuracy": 78.8,
                "f1": 74.53390756302521,
                "precision": 72.79386904761904,
                "recall": 78.8,
                "main_score": 74.53390756302521
            },
            {
                "hf_subset": "yue-eng",
                "languages": [
                    "yue-Hant",
                    "eng-Latn"
                ],
                "accuracy": 91.60000000000001,
                "f1": 89.39,
                "precision": 88.375,
                "recall": 91.60000000000001,
                "main_score": 89.39
            },
            {
                "hf_subset": "swe-eng",
                "languages": [
                    "swe-Latn",
                    "eng-Latn"
                ],
                "accuracy": 32.4,
                "f1": 27.824399979105863,
                "precision": 26.434715247715246,
                "recall": 32.4,
                "main_score": 27.824399979105863
            },
            {
                "hf_subset": "dtp-eng",
                "languages": [
                    "dtp-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.800000000000001,
                "f1": 5.258204523374802,
                "precision": 4.940595825661615,
                "recall": 6.800000000000001,
                "main_score": 5.258204523374802
            },
            {
                "hf_subset": "kat-eng",
                "languages": [
                    "kat-Geor",
                    "eng-Latn"
                ],
                "accuracy": 2.0107238605898123,
                "f1": 1.4770600435024532,
                "precision": 1.4215975441361408,
                "recall": 2.0107238605898123,
                "main_score": 1.4770600435024532
            },
            {
                "hf_subset": "jpn-eng",
                "languages": [
                    "jpn-Jpan",
                    "eng-Latn"
                ],
                "accuracy": 87.2,
                "f1": 83.88333333333333,
                "precision": 82.44166666666668,
                "recall": 87.2,
                "main_score": 83.88333333333333
            },
            {
                "hf_subset": "csb-eng",
                "languages": [
                    "csb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 14.229249011857709,
                "f1": 11.043453048700425,
                "precision": 10.285902503293807,
                "recall": 14.229249011857709,
                "main_score": 11.043453048700425
            },
            {
                "hf_subset": "xho-eng",
                "languages": [
                    "xho-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.859154929577464,
                "f1": 7.960154086914651,
                "precision": 7.679678785726838,
                "recall": 9.859154929577464,
                "main_score": 7.960154086914651
            },
            {
                "hf_subset": "orv-eng",
                "languages": [
                    "orv-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 12.574850299401197,
                "f1": 8.435162337247867,
                "precision": 7.5408084342568324,
                "recall": 12.574850299401197,
                "main_score": 8.435162337247867
            },
            {
                "hf_subset": "ind-eng",
                "languages": [
                    "ind-Latn",
                    "eng-Latn"
                ],
                "accuracy": 93.5,
                "f1": 91.90666666666665,
                "precision": 91.14166666666668,
                "recall": 93.5,
                "main_score": 91.90666666666665
            },
            {
                "hf_subset": "tuk-eng",
                "languages": [
                    "tuk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.866995073891626,
                "f1": 6.8479221927497775,
                "precision": 6.431102386508143,
                "recall": 8.866995073891626,
                "main_score": 6.8479221927497775
            },
            {
                "hf_subset": "max-eng",
                "languages": [
                    "max-Deva",
                    "eng-Latn"
                ],
                "accuracy": 46.12676056338028,
                "f1": 41.447273383893105,
                "precision": 39.80374351371386,
                "recall": 46.12676056338028,
                "main_score": 41.447273383893105
            },
            {
                "hf_subset": "swh-eng",
                "languages": [
                    "swh-Latn",
                    "eng-Latn"
                ],
                "accuracy": 35.38461538461539,
                "f1": 27.80912253371418,
                "precision": 25.588007434161277,
                "recall": 35.38461538461539,
                "main_score": 27.80912253371418
            },
            {
                "hf_subset": "hin-eng",
                "languages": [
                    "hin-Deva",
                    "eng-Latn"
                ],
                "accuracy": 96.1,
                "f1": 94.88333333333333,
                "precision": 94.3,
                "recall": 96.1,
                "main_score": 94.88333333333333
            },
            {
                "hf_subset": "dsb-eng",
                "languages": [
                    "dsb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 18.16283924843424,
                "f1": 15.00273275898725,
                "precision": 14.135773519036146,
                "recall": 18.16283924843424,
                "main_score": 15.00273275898725
            },
            {
                "hf_subset": "ber-eng",
                "languages": [
                    "ber-Tfng",
                    "eng-Latn"
                ],
                "accuracy": 6.4,
                "f1": 5.169780886652615,
                "precision": 4.901094815916798,
                "recall": 6.4,
                "main_score": 5.169780886652615
            },
            {
                "hf_subset": "tam-eng",
                "languages": [
                    "tam-Taml",
                    "eng-Latn"
                ],
                "accuracy": 85.66775244299674,
                "f1": 81.86753528773072,
                "precision": 80.13029315960912,
                "recall": 85.66775244299674,
                "main_score": 81.86753528773072
            },
            {
                "hf_subset": "slk-eng",
                "languages": [
                    "slk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 14.7,
                "f1": 12.296409553542203,
                "precision": 11.643939628482972,
                "recall": 14.7,
                "main_score": 12.296409553542203
            },
            {
                "hf_subset": "tgl-eng",
                "languages": [
                    "tgl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 14.000000000000002,
                "f1": 11.188658083109301,
                "precision": 10.439068547503426,
                "recall": 14.000000000000002,
                "main_score": 11.188658083109301
            },
            {
                "hf_subset": "ast-eng",
                "languages": [
                    "ast-Latn",
                    "eng-Latn"
                ],
                "accuracy": 74.01574803149606,
                "f1": 68.3727034120735,
                "precision": 66.06299212598424,
                "recall": 74.01574803149606,
                "main_score": 68.3727034120735
            },
            {
                "hf_subset": "mkd-eng",
                "languages": [
                    "mkd-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 20.200000000000003,
                "f1": 15.584321026350167,
                "precision": 14.220359087863855,
                "recall": 20.200000000000003,
                "main_score": 15.584321026350167
            },
            {
                "hf_subset": "khm-eng",
                "languages": [
                    "khm-Khmr",
                    "eng-Latn"
                ],
                "accuracy": 1.2465373961218837,
                "f1": 0.7009849184364421,
                "precision": 0.6369121979354991,
                "recall": 1.2465373961218837,
                "main_score": 0.7009849184364421
            },
            {
                "hf_subset": "ces-eng",
                "languages": [
                    "ces-Latn",
                    "eng-Latn"
                ],
                "accuracy": 15.5,
                "f1": 12.992671904350203,
                "precision": 12.323623108157992,
                "recall": 15.5,
                "main_score": 12.992671904350203
            },
            {
                "hf_subset": "tzl-eng",
                "languages": [
                    "tzl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 37.5,
                "f1": 32.70299145299145,
                "precision": 31.066176470588236,
                "recall": 37.5,
                "main_score": 32.70299145299145
            },
            {
                "hf_subset": "urd-eng",
                "languages": [
                    "urd-Arab",
                    "eng-Latn"
                ],
                "accuracy": 86.2,
                "f1": 82.87166666666667,
                "precision": 81.44261904761906,
                "recall": 86.2,
                "main_score": 82.87166666666667
            },
            {
                "hf_subset": "ara-eng",
                "languages": [
                    "ara-Arab",
                    "eng-Latn"
                ],
                "accuracy": 92.5,
                "f1": 90.61666666666667,
                "precision": 89.71666666666668,
                "recall": 92.5,
                "main_score": 90.61666666666667
            },
            {
                "hf_subset": "kor-eng",
                "languages": [
                    "kor-Hang",
                    "eng-Latn"
                ],
                "accuracy": 51.7,
                "f1": 44.78806599832916,
                "precision": 42.26749389499389,
                "recall": 51.7,
                "main_score": 44.78806599832916
            },
            {
                "hf_subset": "yid-eng",
                "languages": [
                    "yid-Hebr",
                    "eng-Latn"
                ],
                "accuracy": 0.9433962264150944,
                "f1": 0.48704516529471925,
                "precision": 0.41179094097726165,
                "recall": 0.9433962264150944,
                "main_score": 0.48704516529471925
            },
            {
                "hf_subset": "fin-eng",
                "languages": [
                    "fin-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.800000000000001,
                "f1": 5.480668860234897,
                "precision": 5.195067371791852,
                "recall": 6.800000000000001,
                "main_score": 5.480668860234897
            },
            {
                "hf_subset": "tha-eng",
                "languages": [
                    "tha-Thai",
                    "eng-Latn"
                ],
                "accuracy": 10.036496350364963,
                "f1": 6.784271238735886,
                "precision": 6.159462364744479,
                "recall": 10.036496350364963,
                "main_score": 6.784271238735886
            },
            {
                "hf_subset": "wuu-eng",
                "languages": [
                    "wuu-Hans",
                    "eng-Latn"
                ],
                "accuracy": 90.3,
                "f1": 87.91499999999999,
                "precision": 86.82595238095237,
                "recall": 90.3,
                "main_score": 87.91499999999999
            }
        ]
    }
}