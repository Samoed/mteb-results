{
    "dataset_revision": "072a486a144adf7f4479a4a0dddb2152e161e1ea",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": NaN,
    "mteb_version": "unknown",
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 40.548083389374575,
                "f1": 39.490307545239716,
                "main_score": 40.548083389374575
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 24.18291862811029,
                "f1": 23.437620034727473,
                "main_score": 24.18291862811029
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 30.134498991257562,
                "f1": 28.787175191531283,
                "main_score": 30.134498991257562
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 35.88433086751849,
                "f1": 36.264500398782126,
                "main_score": 35.88433086751849
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 29.17283120376597,
                "f1": 27.8101616531901,
                "main_score": 29.17283120376597
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 41.788836583725626,
                "f1": 39.71413181054801,
                "main_score": 41.788836583725626
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 44.176193678547406,
                "f1": 42.192499826552286,
                "main_score": 44.176193678547406
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 42.07464694014795,
                "f1": 39.44188259183162,
                "main_score": 42.07464694014795
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 36.254203093476804,
                "f1": 34.46592715936761,
                "main_score": 36.254203093476804
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 61.40887693342301,
                "f1": 59.79854802683996,
                "main_score": 61.40887693342301
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 42.679892400807,
                "f1": 42.04801248338172,
                "main_score": 42.679892400807
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 35.59179556153329,
                "f1": 34.045862930486166,
                "main_score": 35.59179556153329
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 40.036987222595826,
                "f1": 38.117703439362785,
                "main_score": 40.036987222595826
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 43.43981170141224,
                "f1": 42.7084388987865,
                "main_score": 43.43981170141224
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 31.593813046402154,
                "f1": 29.98550522450782,
                "main_score": 31.593813046402154
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 27.044384667114997,
                "f1": 27.313059184832667,
                "main_score": 27.044384667114997
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 38.453261600538,
                "f1": 37.309189326110435,
                "main_score": 38.453261600538
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 27.979152656355076,
                "f1": 27.430939684346445,
                "main_score": 27.979152656355076
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 43.97108271687963,
                "f1": 43.40585705688761,
                "main_score": 43.97108271687963
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 40.302622730329524,
                "f1": 39.108052180520744,
                "main_score": 40.302622730329524
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 45.474108944182916,
                "f1": 45.85950328241134,
                "main_score": 45.474108944182916
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 45.60860793544048,
                "f1": 43.94920708216737,
                "main_score": 45.60860793544048
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 38.668459986550104,
                "f1": 37.6990034018859,
                "main_score": 38.668459986550104
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 25.6523201075992,
                "f1": 25.279084273189582,
                "main_score": 25.6523201075992
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 28.295225285810353,
                "f1": 26.645825638771548,
                "main_score": 28.295225285810353
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 23.480161398789505,
                "f1": 22.275241866506732,
                "main_score": 23.480161398789505
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 36.55682582380632,
                "f1": 36.004753171063605,
                "main_score": 36.55682582380632
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 41.84936112979153,
                "f1": 41.38932672359119,
                "main_score": 41.84936112979153
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 24.90921318090114,
                "f1": 23.968687483768807,
                "main_score": 24.90921318090114
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 29.86213853396099,
                "f1": 29.977152075255407,
                "main_score": 29.86213853396099
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 42.42098184263618,
                "f1": 41.50877432664628,
                "main_score": 42.42098184263618
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 25.131136516476126,
                "f1": 23.938932214086776,
                "main_score": 25.131136516476126
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 39.81506388702084,
                "f1": 38.809586587791664,
                "main_score": 39.81506388702084
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 43.62138533960995,
                "f1": 42.01386842914633,
                "main_score": 43.62138533960995
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 42.19569603227976,
                "f1": 40.00556559825827,
                "main_score": 42.19569603227976
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 45.20847343644923,
                "f1": 44.24115005029051,
                "main_score": 45.20847343644923
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 41.80901143241426,
                "f1": 40.474074848670085,
                "main_score": 41.80901143241426
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 35.96839273705447,
                "f1": 35.095456843621,
                "main_score": 35.96839273705447
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 40.60524546065905,
                "f1": 39.302383051500136,
                "main_score": 40.60524546065905
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 42.75722932078009,
                "f1": 41.53763931497389,
                "main_score": 42.75722932078009
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 42.347007397444514,
                "f1": 41.04366017948627,
                "main_score": 42.347007397444514
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 41.12306657700067,
                "f1": 39.712940473289024,
                "main_score": 41.12306657700067
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 24.603227975790183,
                "f1": 23.969236788828606,
                "main_score": 24.603227975790183
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 25.03698722259583,
                "f1": 24.37196123281459,
                "main_score": 25.03698722259583
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 35.40013449899126,
                "f1": 35.063600413688036,
                "main_score": 35.40013449899126
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 41.19031607262945,
                "f1": 40.240432304273014,
                "main_score": 41.19031607262945
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 36.405514458641555,
                "f1": 36.03844992856558,
                "main_score": 36.405514458641555
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 25.934767989240076,
                "f1": 25.2074457023531,
                "main_score": 25.934767989240076
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 38.79959650302622,
                "f1": 37.160233794673125,
                "main_score": 38.79959650302622
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 46.244115669132476,
                "f1": 44.367480561291906,
                "main_score": 46.244115669132476
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 42.30665770006724,
                "f1": 41.9642223283514,
                "main_score": 42.30665770006724
            }
        ]
    }
}