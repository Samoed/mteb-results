{
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
    "task_name": "TwitterSemEval2015",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "cos_sim_accuracy": 87.12523097097217,
                "cos_sim_ap": 77.59606075943269,
                "cos_sim_f1": 71.11395646606915,
                "cos_sim_precision": 69.07960199004975,
                "cos_sim_recall": 73.27176781002639,
                "dot_accuracy": 84.68736961316088,
                "dot_ap": 68.47167450741459,
                "dot_f1": 64.42152354914874,
                "dot_precision": 60.887949260042284,
                "dot_recall": 68.3905013192612,
                "euclidean_accuracy": 86.88084878106932,
                "euclidean_ap": 77.27351204978599,
                "euclidean_f1": 70.99179716629381,
                "euclidean_precision": 67.10526315789474,
                "euclidean_recall": 75.35620052770449,
                "manhattan_accuracy": 86.83316445133218,
                "manhattan_ap": 77.21835357308716,
                "manhattan_f1": 71.05587004676349,
                "manhattan_precision": 66.58210332103322,
                "manhattan_recall": 76.17414248021109,
                "max_accuracy": 87.12523097097217,
                "max_ap": 77.59606075943269,
                "max_f1": 71.11395646606915,
                "main_score": 77.59606075943269
            }
        ]
    }
}