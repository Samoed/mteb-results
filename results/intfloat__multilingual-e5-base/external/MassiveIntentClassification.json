{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": -1,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 59.97646267652992,
                "f1": 57.26797883561521,
                "main_score": 59.97646267652992
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 53.65501008742435,
                "f1": 50.416258382177034,
                "main_score": 53.65501008742435
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 57.45796906523201,
                "f1": 53.306690547422185,
                "main_score": 57.45796906523201
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 62.59246805648957,
                "f1": 59.818381969051494,
                "main_score": 62.59246805648957
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 61.126429051782104,
                "f1": 58.25993593933026,
                "main_score": 61.126429051782104
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 50.057162071284466,
                "f1": 46.96095728790911,
                "main_score": 50.057162071284466
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 66.64425016812375,
                "f1": 62.858291698755764,
                "main_score": 66.64425016812375
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 66.08944182918628,
                "f1": 62.44639030604241,
                "main_score": 66.08944182918628
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 64.68056489576328,
                "f1": 61.775326758789504,
                "main_score": 64.68056489576328
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 72.11163416274377,
                "f1": 69.70789096927015,
                "main_score": 72.11163416274377
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 68.40282447881641,
                "f1": 66.38492065671895,
                "main_score": 68.40282447881641
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 67.24613315400134,
                "f1": 64.3348019501336,
                "main_score": 67.24613315400134
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 65.78345662407531,
                "f1": 62.21279452354622,
                "main_score": 65.78345662407531
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 67.9455279085407,
                "f1": 65.48193124964094,
                "main_score": 67.9455279085407
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 62.05110961667788,
                "f1": 58.097856564684534,
                "main_score": 62.05110961667788
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 64.95292535305985,
                "f1": 62.09182174767901,
                "main_score": 64.95292535305985
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 64.97310020174848,
                "f1": 61.14252567730396,
                "main_score": 64.97310020174848
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 60.08069939475453,
                "f1": 57.044041742492034,
                "main_score": 60.08069939475453
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 66.63752521856085,
                "f1": 63.889340907205316,
                "main_score": 66.63752521856085
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 56.385339609952936,
                "f1": 53.449033750088304,
                "main_score": 56.385339609952936
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 68.93073301950234,
                "f1": 65.9884357824104,
                "main_score": 68.93073301950234
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 68.94418291862812,
                "f1": 66.48740222583132,
                "main_score": 68.94418291862812
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 54.26025554808339,
                "f1": 50.19562815100793,
                "main_score": 54.26025554808339
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 48.98789509078682,
                "f1": 46.65788438676836,
                "main_score": 48.98789509078682
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 44.68728984532616,
                "f1": 41.642419349541996,
                "main_score": 44.68728984532616
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 59.19300605245461,
                "f1": 55.8626492442437,
                "main_score": 59.19300605245461
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 66.33826496301278,
                "f1": 63.89499791648792,
                "main_score": 66.33826496301278
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 60.33960995292536,
                "f1": 57.15242464180892,
                "main_score": 60.33960995292536
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 63.09347679892402,
                "f1": 59.64733214063841,
                "main_score": 63.09347679892402
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 58.75924680564896,
                "f1": 55.96585692366827,
                "main_score": 58.75924680564896
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 62.48486886348352,
                "f1": 59.45143559032946,
                "main_score": 62.48486886348352
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 58.56422326832549,
                "f1": 54.96368702901926,
                "main_score": 58.56422326832549
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 66.18022864828512,
                "f1": 63.05369805040634,
                "main_score": 66.18022864828512
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 67.30329522528581,
                "f1": 64.06084612020727,
                "main_score": 67.30329522528581
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 68.36919973100201,
                "f1": 65.12154124788887,
                "main_score": 68.36919973100201
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 68.98117014122394,
                "f1": 66.41847559806962,
                "main_score": 68.98117014122394
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 65.53799596503026,
                "f1": 62.17067330740817,
                "main_score": 65.53799596503026
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 69.01815736381977,
                "f1": 66.24988369607843,
                "main_score": 69.01815736381977
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 62.34700739744452,
                "f1": 59.957933424941636,
                "main_score": 62.34700739744452
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 61.23402824478815,
                "f1": 57.98836976018471,
                "main_score": 61.23402824478815
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 68.54068594485541,
                "f1": 65.43849680666855,
                "main_score": 68.54068594485541
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 55.998655010087425,
                "f1": 52.83737515406804,
                "main_score": 55.998655010087425
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 58.71217215870882,
                "f1": 55.051794977833026,
                "main_score": 58.71217215870882
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 59.724277067921996,
                "f1": 56.33485571838306,
                "main_score": 59.724277067921996
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 65.59515803631473,
                "f1": 64.96772366193588,
                "main_score": 65.59515803631473
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 60.860793544048406,
                "f1": 58.148845819115394,
                "main_score": 60.860793544048406
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 67.40753194351043,
                "f1": 63.18903778054698,
                "main_score": 67.40753194351043
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 61.52320107599194,
                "f1": 58.356144563398516,
                "main_score": 61.52320107599194
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 66.17014122394083,
                "f1": 63.919964062638925,
                "main_score": 66.17014122394083
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 69.15601882985878,
                "f1": 67.01451905761371,
                "main_score": 69.15601882985878
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 64.65030262273034,
                "f1": 64.14420425129063,
                "main_score": 64.65030262273034
            }
        ]
    }
}