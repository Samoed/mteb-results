{
    "dataset_revision": "None",
    "task_name": "QuoraRetrieval",
    "evaluation_time": NaN,
    "mteb_version": "unknown",
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "map_at_1": 70.38799999999999,
                "map_at_10": 84.315,
                "map_at_100": 84.955,
                "map_at_1000": 84.971,
                "map_at_3": 81.33399999999999,
                "map_at_5": 83.21300000000001,
                "mrr_at_1": 81.03,
                "mrr_at_10": 87.395,
                "mrr_at_100": 87.488,
                "mrr_at_1000": 87.48899999999999,
                "mrr_at_3": 86.41499999999999,
                "mrr_at_5": 87.074,
                "ndcg_at_1": 81.04,
                "ndcg_at_10": 88.151,
                "ndcg_at_100": 89.38199999999999,
                "ndcg_at_1000": 89.479,
                "ndcg_at_3": 85.24000000000001,
                "ndcg_at_5": 86.856,
                "precision_at_1": 81.04,
                "precision_at_10": 13.372,
                "precision_at_100": 1.526,
                "precision_at_1000": 0.157,
                "precision_at_3": 37.217,
                "precision_at_5": 24.502,
                "recall_at_1": 70.38799999999999,
                "recall_at_10": 95.452,
                "recall_at_100": 99.59700000000001,
                "recall_at_1000": 99.988,
                "recall_at_3": 87.11,
                "recall_at_5": 91.662,
                "main_score": 88.151
            }
        ]
    }
}