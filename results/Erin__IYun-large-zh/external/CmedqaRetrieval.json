{
    "dataset_revision": "None",
    "task_name": "CmedqaRetrieval",
    "evaluation_time": null,
    "mteb_version": "0.0.0",
    "scores": {
        "dev": [
            {
                "hf_subset": "default",
                "languages": [
                    "cmn-Hans"
                ],
                "map_at_1": 26.950000000000003,
                "map_at_10": 39.982,
                "map_at_100": 41.844,
                "map_at_1000": 41.948,
                "map_at_3": 35.664,
                "map_at_5": 38.061,
                "mrr_at_1": 41.11,
                "mrr_at_10": 49.183,
                "mrr_at_100": 50.166999999999994,
                "mrr_at_1000": 50.205999999999996,
                "mrr_at_3": 46.778,
                "mrr_at_5": 48.120000000000005,
                "ndcg_at_1": 41.11,
                "ndcg_at_10": 46.678,
                "ndcg_at_100": 53.876000000000005,
                "ndcg_at_1000": 55.627,
                "ndcg_at_3": 41.429,
                "ndcg_at_5": 43.551,
                "precision_at_1": 41.11,
                "precision_at_10": 10.325,
                "precision_at_100": 1.6119999999999999,
                "precision_at_1000": 0.184,
                "precision_at_3": 23.498,
                "precision_at_5": 16.894000000000002,
                "recall_at_1": 26.950000000000003,
                "recall_at_10": 57.239,
                "recall_at_100": 86.9,
                "recall_at_1000": 98.581,
                "recall_at_3": 41.221000000000004,
                "recall_at_5": 47.976,
                "main_score": 46.678
            }
        ]
    }
}