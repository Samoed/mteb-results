{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 45.42030934767989,
                "f1": 44.12201543566376,
                "main_score": 45.42030934767989
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 37.67652992602556,
                "f1": 35.422091900843164,
                "main_score": 37.67652992602556
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 45.02353732347007,
                "f1": 41.852484084738194,
                "main_score": 45.02353732347007
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 48.70880968392737,
                "f1": 46.904360615435046,
                "main_score": 48.70880968392737
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 43.78950907868191,
                "f1": 41.58872353920405,
                "main_score": 43.78950907868191
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 28.759246805648957,
                "f1": 27.41182001374226,
                "main_score": 28.759246805648957
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 56.74176193678547,
                "f1": 53.82727354182497,
                "main_score": 56.74176193678547
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 51.55682582380632,
                "f1": 49.41963627941866,
                "main_score": 51.55682582380632
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 56.46940147948891,
                "f1": 55.28178711367465,
                "main_score": 56.46940147948891
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 63.83322125084063,
                "f1": 61.836172900845554,
                "main_score": 63.83322125084063
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 58.27505043712172,
                "f1": 57.642436374361154,
                "main_score": 58.27505043712172
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 59.05178211163417,
                "f1": 56.858998820504056,
                "main_score": 59.05178211163417
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 57.357094821788834,
                "f1": 54.79711189260453,
                "main_score": 57.357094821788834
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 58.79959650302623,
                "f1": 57.59158671719513,
                "main_score": 58.79959650302623
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 51.1768661735037,
                "f1": 48.886397276270515,
                "main_score": 51.1768661735037
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 57.06455951580362,
                "f1": 55.01530952684585,
                "main_score": 57.06455951580362
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 58.3591123066577,
                "f1": 55.9277783370191,
                "main_score": 58.3591123066577
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 52.108271687962336,
                "f1": 51.195023400664596,
                "main_score": 52.108271687962336
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 58.26832548755883,
                "f1": 56.60774065423401,
                "main_score": 58.26832548755883
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 35.806993947545394,
                "f1": 34.290418953173294,
                "main_score": 35.806993947545394
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 58.27841291190315,
                "f1": 56.9438998642419,
                "main_score": 58.27841291190315
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 60.78009414929389,
                "f1": 59.15780842483667,
                "main_score": 60.78009414929389
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 31.153328850033624,
                "f1": 30.11004596099605,
                "main_score": 31.153328850033624
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 44.50235373234701,
                "f1": 44.040585262624745,
                "main_score": 44.50235373234701
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 40.99193006052455,
                "f1": 39.505480119272484,
                "main_score": 40.99193006052455
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 46.95696032279758,
                "f1": 43.093638940785326,
                "main_score": 46.95696032279758
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 54.73100201748486,
                "f1": 52.79750744404114,
                "main_score": 54.73100201748486
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 54.865501008742434,
                "f1": 53.64798408964839,
                "main_score": 54.865501008742434
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 47.891728312037664,
                "f1": 45.261229414636055,
                "main_score": 47.891728312037664
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 52.2259583053127,
                "f1": 50.5903419246987,
                "main_score": 52.2259583053127
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 54.277067921990586,
                "f1": 52.472042479965886,
                "main_score": 54.277067921990586
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 51.95696032279757,
                "f1": 49.79330411854258,
                "main_score": 51.95696032279757
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 54.63685272360457,
                "f1": 52.81267480650003,
                "main_score": 54.63685272360457
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 59.451916610625425,
                "f1": 57.34790386645091,
                "main_score": 59.451916610625425
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 58.91055817081372,
                "f1": 56.39195048528157,
                "main_score": 58.91055817081372
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 59.84196368527236,
                "f1": 58.72244763127063,
                "main_score": 59.84196368527236
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 57.04102219233354,
                "f1": 55.67040186148946,
                "main_score": 57.04102219233354
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 58.01613987895091,
                "f1": 57.203949825484855,
                "main_score": 58.01613987895091
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 56.35843981170141,
                "f1": 54.18656338999773,
                "main_score": 56.35843981170141
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 56.47948890383322,
                "f1": 54.772224557130954,
                "main_score": 56.47948890383322
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 58.43981170141224,
                "f1": 56.09260971364242,
                "main_score": 58.43981170141224
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 33.9609952925353,
                "f1": 33.18853392353405,
                "main_score": 33.9609952925353
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 44.29388029589778,
                "f1": 41.51986533284474,
                "main_score": 44.29388029589778
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 47.13517148621385,
                "f1": 43.94784138379624,
                "main_score": 47.13517148621385
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 56.856086079354405,
                "f1": 56.618177384748456,
                "main_score": 56.856086079354405
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 35.35978480161398,
                "f1": 34.060680080365046,
                "main_score": 35.35978480161398
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 59.630127774041696,
                "f1": 57.46288652988266,
                "main_score": 59.630127774041696
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 52.7908540685945,
                "f1": 51.46934239116157,
                "main_score": 52.7908540685945
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 54.6469401479489,
                "f1": 53.9903066185816,
                "main_score": 54.6469401479489
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 60.85743106926698,
                "f1": 59.31579548450755,
                "main_score": 60.85743106926698
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 57.46805648957633,
                "f1": 57.48469733657326,
                "main_score": 57.46805648957633
            }
        ]
    }
}