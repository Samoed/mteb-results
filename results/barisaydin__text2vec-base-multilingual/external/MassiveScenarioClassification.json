{
    "dataset_revision": "7d571f92784cd94a019292a1f45445077d0ef634",
    "task_name": "MassiveScenarioClassification",
    "evaluation_time": -1,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 50.86415601882985,
                "f1": 49.41696672602645,
                "main_score": 50.86415601882985
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 41.183591123066584,
                "f1": 40.04563865770774,
                "main_score": 41.183591123066584
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 50.08069939475455,
                "f1": 50.724800165846126,
                "main_score": 50.08069939475455
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 51.287827841291204,
                "f1": 50.72873776739851,
                "main_score": 51.287827841291204
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 46.53328850033624,
                "f1": 45.93317866639667,
                "main_score": 46.53328850033624
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 34.347679892400805,
                "f1": 31.941581141280828,
                "main_score": 34.347679892400805
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 63.073301950235376,
                "f1": 62.228728940111054,
                "main_score": 63.073301950235376
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 56.398789509078675,
                "f1": 54.80778341609032,
                "main_score": 56.398789509078675
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 61.79892400806993,
                "f1": 60.69430756982446,
                "main_score": 61.79892400806993
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 66.96368527236046,
                "f1": 66.5893927997656,
                "main_score": 66.96368527236046
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 62.21250840618695,
                "f1": 62.347177794128925,
                "main_score": 62.21250840618695
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 62.43779421654339,
                "f1": 61.307701312085605,
                "main_score": 62.43779421654339
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 61.09952925353059,
                "f1": 60.313907927386914,
                "main_score": 61.09952925353059
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 63.38601210490922,
                "f1": 63.05968938353488,
                "main_score": 63.38601210490922
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 56.2878278412912,
                "f1": 55.92927644838597,
                "main_score": 56.2878278412912
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 60.62878278412912,
                "f1": 60.25299253652635,
                "main_score": 60.62878278412912
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 63.28850033624748,
                "f1": 62.77053246337031,
                "main_score": 63.28850033624748
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 54.875588433086754,
                "f1": 54.30717357279134,
                "main_score": 54.875588433086754
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 61.99394754539341,
                "f1": 61.73085530883037,
                "main_score": 61.99394754539341
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 38.581035642232685,
                "f1": 36.96287269695893,
                "main_score": 38.581035642232685
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 62.350369872225976,
                "f1": 61.807327324823966,
                "main_score": 62.350369872225976
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 65.17148621385338,
                "f1": 65.29620144656751,
                "main_score": 65.17148621385338
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 36.12642905178212,
                "f1": 35.334393048479484,
                "main_score": 36.12642905178212
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 50.26899798251513,
                "f1": 49.041065960139434,
                "main_score": 50.26899798251513
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 44.24344317417619,
                "f1": 42.42177854872125,
                "main_score": 44.24344317417619
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 47.370544720914594,
                "f1": 46.589722581465324,
                "main_score": 47.370544720914594
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 58.89038332212508,
                "f1": 57.753607921990394,
                "main_score": 58.89038332212508
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 56.506388702084756,
                "f1": 56.0485860423295,
                "main_score": 56.506388702084756
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 50.06388702084734,
                "f1": 50.109364641824584,
                "main_score": 50.06388702084734
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 55.053799596503026,
                "f1": 54.490665705666686,
                "main_score": 55.053799596503026
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 59.77135171486213,
                "f1": 58.2808650158803,
                "main_score": 59.77135171486213
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 55.71620712844654,
                "f1": 53.863034882475304,
                "main_score": 55.71620712844654
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 60.26227303295225,
                "f1": 59.86604657147016,
                "main_score": 60.26227303295225
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 63.3759246805649,
                "f1": 62.45257339288533,
                "main_score": 63.3759246805649
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 62.552118359112306,
                "f1": 61.354449605776765,
                "main_score": 62.552118359112306
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 62.40753194351043,
                "f1": 61.98779889528889,
                "main_score": 62.40753194351043
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 60.68258238063214,
                "f1": 60.59973978976571,
                "main_score": 60.68258238063214
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 62.31002017484868,
                "f1": 62.412312268503655,
                "main_score": 62.31002017484868
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 61.429051782111635,
                "f1": 61.60095590401424,
                "main_score": 61.429051782111635
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 62.229320780094156,
                "f1": 61.02251426747547,
                "main_score": 62.229320780094156
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 64.42501681237391,
                "f1": 63.461494430605235,
                "main_score": 64.42501681237391
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 38.51714862138534,
                "f1": 37.12466722986362,
                "main_score": 38.51714862138534
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 46.99731002017485,
                "f1": 45.859147049984834,
                "main_score": 46.99731002017485
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 51.01882985877605,
                "f1": 49.01040173136056,
                "main_score": 51.01882985877605
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 63.234700739744454,
                "f1": 62.732294595214746,
                "main_score": 63.234700739744454
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 38.72225958305312,
                "f1": 36.603231928120906,
                "main_score": 38.72225958305312
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 64.48554135843982,
                "f1": 63.97380562022752,
                "main_score": 64.48554135843982
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 56.7955615332885,
                "f1": 55.95308241204802,
                "main_score": 56.7955615332885
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 57.06455951580362,
                "f1": 56.95570494066693,
                "main_score": 57.06455951580362
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 65.8338937457969,
                "f1": 65.6778746906008,
                "main_score": 65.8338937457969
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 63.369199731002034,
                "f1": 63.527650116059945,
                "main_score": 63.369199731002034
            }
        ]
    }
}