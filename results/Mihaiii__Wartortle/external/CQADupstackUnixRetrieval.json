{
    "dataset_revision": "6c6430d3a6d36f8d2a829195bc5dc94d7e063e53",
    "task_name": "CQADupstackUnixRetrieval",
    "evaluation_time": NaN,
    "mteb_version": "unknown",
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "map_at_1": 13.764999999999999,
                "map_at_10": 17.766000000000002,
                "map_at_100": 18.637999999999998,
                "map_at_1000": 18.755,
                "map_at_20": 18.242,
                "map_at_3": 16.502,
                "map_at_5": 17.155,
                "mrr_at_1": 16.604,
                "mrr_at_10": 21.071,
                "mrr_at_100": 21.906,
                "mrr_at_1000": 22.0,
                "mrr_at_20": 21.545,
                "mrr_at_3": 19.667,
                "mrr_at_5": 20.395,
                "ndcg_at_1": 16.604,
                "ndcg_at_10": 20.742,
                "ndcg_at_100": 25.363999999999997,
                "ndcg_at_1000": 28.607,
                "ndcg_at_20": 22.469,
                "ndcg_at_3": 18.276999999999997,
                "ndcg_at_5": 19.277,
                "precision_at_1": 16.604,
                "precision_at_10": 3.47,
                "precision_at_100": 0.651,
                "precision_at_1000": 0.104,
                "precision_at_20": 2.169,
                "precision_at_3": 8.209,
                "precision_at_5": 5.7090000000000005,
                "recall_at_1": 13.764999999999999,
                "recall_at_10": 26.752,
                "recall_at_100": 47.988,
                "recall_at_1000": 71.859,
                "recall_at_20": 33.25,
                "recall_at_3": 19.777,
                "recall_at_5": 22.39,
                "main_score": 20.742
            }
        ]
    }
}