{
    "dataset_revision": "ed9a4403ed4adbfaf4aab56d5b2709e9f6c3ba33",
    "task_name": "NTREXBitextMining",
    "evaluation_time": NaN,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "arb_Arab-hun_Latn",
                "languages": [
                    "arb-Arab",
                    "hun-Latn"
                ],
                "accuracy": 86.07911867801702,
                "f1": 82.34184610248707,
                "main_score": 82.34184610248707,
                "precision": 80.65598397596395,
                "recall": 86.07911867801702
            },
            {
                "hf_subset": "ben_Beng-hun_Latn",
                "languages": [
                    "ben-Beng",
                    "hun-Latn"
                ],
                "accuracy": 40.91136705057586,
                "f1": 36.01175728956383,
                "main_score": 36.01175728956383,
                "precision": 34.36916434339978,
                "recall": 40.91136705057586
            },
            {
                "hf_subset": "deu_Latn-hun_Latn",
                "languages": [
                    "deu-Latn",
                    "hun-Latn"
                ],
                "accuracy": 93.54031046569855,
                "f1": 91.73760640961443,
                "main_score": 91.73760640961443,
                "precision": 90.87130696044066,
                "recall": 93.54031046569855
            },
            {
                "hf_subset": "ell_Grek-hun_Latn",
                "languages": [
                    "ell-Grek",
                    "hun-Latn"
                ],
                "accuracy": 91.3870806209314,
                "f1": 88.87998664663662,
                "main_score": 88.87998664663662,
                "precision": 87.69821398764815,
                "recall": 91.3870806209314
            },
            {
                "hf_subset": "eng_Latn-hun_Latn",
                "languages": [
                    "eng-Latn",
                    "hun-Latn"
                ],
                "accuracy": 94.69203805708563,
                "f1": 93.04790519112001,
                "main_score": 93.04790519112001,
                "precision": 92.24670338841595,
                "recall": 94.69203805708563
            },
            {
                "hf_subset": "fas_Arab-hun_Latn",
                "languages": [
                    "fas-Arab",
                    "hun-Latn"
                ],
                "accuracy": 89.43415122684027,
                "f1": 86.48138874979135,
                "main_score": 86.48138874979135,
                "precision": 85.1235186112502,
                "recall": 89.43415122684027
            },
            {
                "hf_subset": "fin_Latn-hun_Latn",
                "languages": [
                    "fin-Latn",
                    "hun-Latn"
                ],
                "accuracy": 90.73610415623435,
                "f1": 88.10716074111167,
                "main_score": 88.10716074111167,
                "precision": 86.84860624269739,
                "recall": 90.73610415623435
            },
            {
                "hf_subset": "fra_Latn-hun_Latn",
                "languages": [
                    "fra-Latn",
                    "hun-Latn"
                ],
                "accuracy": 93.03955933900852,
                "f1": 90.97312635620098,
                "main_score": 90.97312635620098,
                "precision": 89.97245868803205,
                "recall": 93.03955933900852
            },
            {
                "hf_subset": "heb_Hebr-hun_Latn",
                "languages": [
                    "heb-Hebr",
                    "hun-Latn"
                ],
                "accuracy": 88.03204807210815,
                "f1": 84.71540644299783,
                "main_score": 84.71540644299783,
                "precision": 83.14972458688032,
                "recall": 88.03204807210815
            },
            {
                "hf_subset": "hin_Deva-hun_Latn",
                "languages": [
                    "hin-Deva",
                    "hun-Latn"
                ],
                "accuracy": 86.9804707060591,
                "f1": 83.51527290936404,
                "main_score": 83.51527290936404,
                "precision": 81.92038057085628,
                "recall": 86.9804707060591
            },
            {
                "hf_subset": "hun_Latn-arb_Arab",
                "languages": [
                    "hun-Latn",
                    "arb-Arab"
                ],
                "accuracy": 86.47971957936905,
                "f1": 82.83592054748789,
                "main_score": 82.83592054748789,
                "precision": 81.18260724419963,
                "recall": 86.47971957936905
            },
            {
                "hf_subset": "hun_Latn-ben_Beng",
                "languages": [
                    "hun-Latn",
                    "ben-Beng"
                ],
                "accuracy": 41.86279419128693,
                "f1": 33.232896964494365,
                "main_score": 33.232896964494365,
                "precision": 30.249043850094402,
                "recall": 41.86279419128693
            },
            {
                "hf_subset": "hun_Latn-deu_Latn",
                "languages": [
                    "hun-Latn",
                    "deu-Latn"
                ],
                "accuracy": 93.94091136705057,
                "f1": 92.14989150392255,
                "main_score": 92.14989150392255,
                "precision": 91.28275746953764,
                "recall": 93.94091136705057
            },
            {
                "hf_subset": "hun_Latn-ell_Grek",
                "languages": [
                    "hun-Latn",
                    "ell-Grek"
                ],
                "accuracy": 92.8392588883325,
                "f1": 90.86296110832916,
                "main_score": 90.86296110832916,
                "precision": 89.93072942747456,
                "recall": 92.8392588883325
            },
            {
                "hf_subset": "hun_Latn-eng_Latn",
                "languages": [
                    "hun-Latn",
                    "eng-Latn"
                ],
                "accuracy": 95.54331497245869,
                "f1": 94.2330161909531,
                "main_score": 94.2330161909531,
                "precision": 93.59873143047905,
                "recall": 95.54331497245869
            },
            {
                "hf_subset": "hun_Latn-fas_Arab",
                "languages": [
                    "hun-Latn",
                    "fas-Arab"
                ],
                "accuracy": 89.43415122684027,
                "f1": 86.54481722583876,
                "main_score": 86.54481722583876,
                "precision": 85.20447337673176,
                "recall": 89.43415122684027
            },
            {
                "hf_subset": "hun_Latn-fin_Latn",
                "languages": [
                    "hun-Latn",
                    "fin-Latn"
                ],
                "accuracy": 89.58437656484726,
                "f1": 86.70839592722417,
                "main_score": 86.70839592722417,
                "precision": 85.37389417459522,
                "recall": 89.58437656484726
            },
            {
                "hf_subset": "hun_Latn-fra_Latn",
                "languages": [
                    "hun-Latn",
                    "fra-Latn"
                ],
                "accuracy": 92.13820731096645,
                "f1": 89.883158070439,
                "main_score": 89.883158070439,
                "precision": 88.81822734101151,
                "recall": 92.13820731096645
            },
            {
                "hf_subset": "hun_Latn-heb_Hebr",
                "languages": [
                    "hun-Latn",
                    "heb-Hebr"
                ],
                "accuracy": 86.93039559339009,
                "f1": 83.32336166587544,
                "main_score": 83.32336166587544,
                "precision": 81.67334334835587,
                "recall": 86.93039559339009
            },
            {
                "hf_subset": "hun_Latn-hin_Deva",
                "languages": [
                    "hun-Latn",
                    "hin-Deva"
                ],
                "accuracy": 85.97896845267901,
                "f1": 82.34685361375396,
                "main_score": 82.34685361375396,
                "precision": 80.72859288933401,
                "recall": 85.97896845267901
            },
            {
                "hf_subset": "hun_Latn-ind_Latn",
                "languages": [
                    "hun-Latn",
                    "ind-Latn"
                ],
                "accuracy": 92.33850776164246,
                "f1": 90.06843598731432,
                "main_score": 90.06843598731432,
                "precision": 88.97512936070773,
                "recall": 92.33850776164246
            },
            {
                "hf_subset": "hun_Latn-jpn_Jpan",
                "languages": [
                    "hun-Latn",
                    "jpn-Jpan"
                ],
                "accuracy": 87.48122183274913,
                "f1": 84.08779836421299,
                "main_score": 84.08779836421299,
                "precision": 82.53380070105159,
                "recall": 87.48122183274913
            },
            {
                "hf_subset": "hun_Latn-kor_Hang",
                "languages": [
                    "hun-Latn",
                    "kor-Hang"
                ],
                "accuracy": 84.82724086129194,
                "f1": 80.77859213062017,
                "main_score": 80.77859213062017,
                "precision": 78.98931730929726,
                "recall": 84.82724086129194
            },
            {
                "hf_subset": "hun_Latn-lav_Latn",
                "languages": [
                    "hun-Latn",
                    "lav-Latn"
                ],
                "accuracy": 89.9849774661993,
                "f1": 87.0422300116842,
                "main_score": 87.0422300116842,
                "precision": 85.65932231680856,
                "recall": 89.9849774661993
            },
            {
                "hf_subset": "hun_Latn-lit_Latn",
                "languages": [
                    "hun-Latn",
                    "lit-Latn"
                ],
                "accuracy": 90.38557836755132,
                "f1": 87.60474044399933,
                "main_score": 87.60474044399933,
                "precision": 86.28776498080455,
                "recall": 90.38557836755132
            },
            {
                "hf_subset": "hun_Latn-nld_Latn",
                "languages": [
                    "hun-Latn",
                    "nld-Latn"
                ],
                "accuracy": 93.64046069103655,
                "f1": 91.81271907861792,
                "main_score": 91.81271907861792,
                "precision": 90.93807377733266,
                "recall": 93.64046069103655
            },
            {
                "hf_subset": "hun_Latn-pol_Latn",
                "languages": [
                    "hun-Latn",
                    "pol-Latn"
                ],
                "accuracy": 91.2368552829244,
                "f1": 88.85924124281661,
                "main_score": 88.85924124281661,
                "precision": 87.7524620263729,
                "recall": 91.2368552829244
            },
            {
                "hf_subset": "hun_Latn-por_Latn",
                "languages": [
                    "hun-Latn",
                    "por-Latn"
                ],
                "accuracy": 93.18978467701552,
                "f1": 91.15172759138709,
                "main_score": 91.15172759138709,
                "precision": 90.19362376898682,
                "recall": 93.18978467701552
            },
            {
                "hf_subset": "hun_Latn-rus_Cyrl",
                "languages": [
                    "hun-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 92.23835753630446,
                "f1": 89.9382406943749,
                "main_score": 89.9382406943749,
                "precision": 88.85411450509096,
                "recall": 92.23835753630446
            },
            {
                "hf_subset": "hun_Latn-spa_Latn",
                "languages": [
                    "hun-Latn",
                    "spa-Latn"
                ],
                "accuracy": 93.34001001502253,
                "f1": 91.47888499415792,
                "main_score": 91.47888499415792,
                "precision": 90.58587881822734,
                "recall": 93.34001001502253
            },
            {
                "hf_subset": "hun_Latn-swa_Latn",
                "languages": [
                    "hun-Latn",
                    "swa-Latn"
                ],
                "accuracy": 40.76114171256886,
                "f1": 32.341475401874824,
                "main_score": 32.341475401874824,
                "precision": 29.515621549076144,
                "recall": 40.76114171256886
            },
            {
                "hf_subset": "hun_Latn-swe_Latn",
                "languages": [
                    "hun-Latn",
                    "swe-Latn"
                ],
                "accuracy": 93.44016024036054,
                "f1": 91.490569187114,
                "main_score": 91.490569187114,
                "precision": 90.56501418794859,
                "recall": 93.44016024036054
            },
            {
                "hf_subset": "hun_Latn-tam_Taml",
                "languages": [
                    "hun-Latn",
                    "tam-Taml"
                ],
                "accuracy": 27.591387080620933,
                "f1": 18.875023187991868,
                "main_score": 18.875023187991868,
                "precision": 16.43982939607956,
                "recall": 27.591387080620933
            },
            {
                "hf_subset": "hun_Latn-tur_Latn",
                "languages": [
                    "hun-Latn",
                    "tur-Latn"
                ],
                "accuracy": 91.3870806209314,
                "f1": 88.90836254381573,
                "main_score": 88.90836254381573,
                "precision": 87.72325154398266,
                "recall": 91.3870806209314
            },
            {
                "hf_subset": "hun_Latn-vie_Latn",
                "languages": [
                    "hun-Latn",
                    "vie-Latn"
                ],
                "accuracy": 91.13670505758637,
                "f1": 88.62054987242769,
                "main_score": 88.62054987242769,
                "precision": 87.41445501585711,
                "recall": 91.13670505758637
            },
            {
                "hf_subset": "hun_Latn-zho_Hant",
                "languages": [
                    "hun-Latn",
                    "zho-Hant"
                ],
                "accuracy": 90.33550325488233,
                "f1": 87.71574027708229,
                "main_score": 87.71574027708229,
                "precision": 86.53861744998451,
                "recall": 90.33550325488233
            },
            {
                "hf_subset": "hun_Latn-zul_Latn",
                "languages": [
                    "hun-Latn",
                    "zul-Latn"
                ],
                "accuracy": 17.626439659489236,
                "f1": 11.826546194507252,
                "main_score": 11.826546194507252,
                "precision": 10.340822386979896,
                "recall": 17.626439659489236
            },
            {
                "hf_subset": "ind_Latn-hun_Latn",
                "languages": [
                    "ind-Latn",
                    "hun-Latn"
                ],
                "accuracy": 92.93940911367051,
                "f1": 90.91470539142045,
                "main_score": 90.91470539142045,
                "precision": 89.96411283592055,
                "recall": 92.93940911367051
            },
            {
                "hf_subset": "jpn_Jpan-hun_Latn",
                "languages": [
                    "jpn-Jpan",
                    "hun-Latn"
                ],
                "accuracy": 88.33249874812218,
                "f1": 85.07260891337006,
                "main_score": 85.07260891337006,
                "precision": 83.54114505090969,
                "recall": 88.33249874812218
            },
            {
                "hf_subset": "kor_Hang-hun_Latn",
                "languages": [
                    "kor-Hang",
                    "hun-Latn"
                ],
                "accuracy": 86.07911867801702,
                "f1": 82.32348522784176,
                "main_score": 82.32348522784176,
                "precision": 80.59339008512768,
                "recall": 86.07911867801702
            },
            {
                "hf_subset": "lav_Latn-hun_Latn",
                "languages": [
                    "lav-Latn",
                    "hun-Latn"
                ],
                "accuracy": 90.73610415623435,
                "f1": 88.25833989078856,
                "main_score": 88.25833989078856,
                "precision": 87.09480887998664,
                "recall": 90.73610415623435
            },
            {
                "hf_subset": "lit_Latn-hun_Latn",
                "languages": [
                    "lit-Latn",
                    "hun-Latn"
                ],
                "accuracy": 91.88783174762143,
                "f1": 89.59105324653646,
                "main_score": 89.59105324653646,
                "precision": 88.49106993824068,
                "recall": 91.88783174762143
            },
            {
                "hf_subset": "nld_Latn-hun_Latn",
                "languages": [
                    "nld-Latn",
                    "hun-Latn"
                ],
                "accuracy": 92.98948422633951,
                "f1": 90.93139709564348,
                "main_score": 90.93139709564348,
                "precision": 89.93072942747456,
                "recall": 92.98948422633951
            },
            {
                "hf_subset": "pol_Latn-hun_Latn",
                "languages": [
                    "pol-Latn",
                    "hun-Latn"
                ],
                "accuracy": 91.4371557336004,
                "f1": 89.10699382406943,
                "main_score": 89.10699382406943,
                "precision": 88.00701051577366,
                "recall": 91.4371557336004
            },
            {
                "hf_subset": "por_Latn-hun_Latn",
                "languages": [
                    "por-Latn",
                    "hun-Latn"
                ],
                "accuracy": 92.98948422633951,
                "f1": 91.02320146886997,
                "main_score": 91.02320146886997,
                "precision": 90.09764646970456,
                "recall": 92.98948422633951
            },
            {
                "hf_subset": "rus_Cyrl-hun_Latn",
                "languages": [
                    "rus-Cyrl",
                    "hun-Latn"
                ],
                "accuracy": 90.98647971957938,
                "f1": 88.3942580537473,
                "main_score": 88.3942580537473,
                "precision": 87.16992154899015,
                "recall": 90.98647971957938
            },
            {
                "hf_subset": "spa_Latn-hun_Latn",
                "languages": [
                    "spa-Latn",
                    "hun-Latn"
                ],
                "accuracy": 93.13970956434652,
                "f1": 91.19846436321149,
                "main_score": 91.19846436321149,
                "precision": 90.26456351193457,
                "recall": 93.13970956434652
            },
            {
                "hf_subset": "swa_Latn-hun_Latn",
                "languages": [
                    "swa-Latn",
                    "hun-Latn"
                ],
                "accuracy": 39.05858788182273,
                "f1": 33.98323169908456,
                "main_score": 33.98323169908456,
                "precision": 32.41376425186998,
                "recall": 39.05858788182273
            },
            {
                "hf_subset": "swe_Latn-hun_Latn",
                "languages": [
                    "swe-Latn",
                    "hun-Latn"
                ],
                "accuracy": 93.03955933900852,
                "f1": 91.01485561675847,
                "main_score": 91.01485561675847,
                "precision": 90.04757135703555,
                "recall": 93.03955933900852
            },
            {
                "hf_subset": "tam_Taml-hun_Latn",
                "languages": [
                    "tam-Taml",
                    "hun-Latn"
                ],
                "accuracy": 27.341011517275916,
                "f1": 24.114490363365103,
                "main_score": 24.114490363365103,
                "precision": 23.01465131730559,
                "recall": 27.341011517275916
            },
            {
                "hf_subset": "tur_Latn-hun_Latn",
                "languages": [
                    "tur-Latn",
                    "hun-Latn"
                ],
                "accuracy": 91.03655483224837,
                "f1": 88.4843932565515,
                "main_score": 88.4843932565515,
                "precision": 87.31180103488568,
                "recall": 91.03655483224837
            },
            {
                "hf_subset": "vie_Latn-hun_Latn",
                "languages": [
                    "vie-Latn",
                    "hun-Latn"
                ],
                "accuracy": 90.38557836755132,
                "f1": 87.73493573693874,
                "main_score": 87.73493573693874,
                "precision": 86.5005842096478,
                "recall": 90.38557836755132
            },
            {
                "hf_subset": "zho_Hant-hun_Latn",
                "languages": [
                    "zho-Hant",
                    "hun-Latn"
                ],
                "accuracy": 90.33550325488233,
                "f1": 87.59806376231013,
                "main_score": 87.59806376231013,
                "precision": 86.3253213153063,
                "recall": 90.33550325488233
            },
            {
                "hf_subset": "zul_Latn-hun_Latn",
                "languages": [
                    "zul-Latn",
                    "hun-Latn"
                ],
                "accuracy": 17.676514772158235,
                "f1": 13.907186347256669,
                "main_score": 13.907186347256669,
                "precision": 12.923210518264245,
                "recall": 17.676514772158235
            }
        ]
    }
}