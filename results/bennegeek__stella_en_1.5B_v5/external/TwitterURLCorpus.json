{
    "dataset_revision": "8b6510b0b1fa4e4c4f879467980e9be563ec1cdf",
    "task_name": "TwitterURLCorpus",
    "evaluation_time": NaN,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "cosine_accuracy": 89.88628866379477,
                "cosine_accuracy_threshold": 80.8050274848938,
                "cosine_ap": 87.57594591596816,
                "cosine_f1": 80.0812257707218,
                "cosine_f1_threshold": 77.990061044693,
                "cosine_precision": 76.93126197063205,
                "cosine_recall": 83.50015398829689,
                "dot_accuracy": 89.87852679784221,
                "dot_accuracy_threshold": 80.84419965744019,
                "dot_ap": 87.56136742222151,
                "dot_f1": 80.05898617511521,
                "dot_f1_threshold": 77.92385816574097,
                "dot_precision": 76.80554573106035,
                "dot_recall": 83.60024638127503,
                "euclidean_accuracy": 89.86882446540149,
                "euclidean_accuracy_threshold": 62.08193898200989,
                "euclidean_ap": 87.57517549192228,
                "euclidean_f1": 80.05286925872892,
                "euclidean_f1_threshold": 66.65036082267761,
                "euclidean_precision": 76.51063232507545,
                "euclidean_recall": 83.93902063443178,
                "main_score": 87.64162614197194,
                "manhattan_accuracy": 89.8959909962355,
                "manhattan_accuracy_threshold": 4176.108169555664,
                "manhattan_ap": 87.64162614197194,
                "manhattan_f1": 80.17116279069768,
                "manhattan_f1_threshold": 4433.153533935547,
                "manhattan_precision": 77.57615035644848,
                "manhattan_recall": 82.94579611949491,
                "max_ap": 87.64162614197194,
                "max_f1": 80.17116279069768,
                "max_precision": 77.57615035644848,
                "max_recall": 83.93902063443178,
                "similarity_accuracy": 89.88628866379477,
                "similarity_accuracy_threshold": 80.8050274848938,
                "similarity_ap": 87.57594591596816,
                "similarity_f1": 80.0812257707218,
                "similarity_f1_threshold": 77.990061044693,
                "similarity_precision": 76.93126197063205,
                "similarity_recall": 83.50015398829689
            }
        ]
    }
}