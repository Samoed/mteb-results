{
    "dataset_revision": "9080400076fbadbb4c4dcb136ff4eddc40b42553",
    "task_name": "Tatoeba",
    "evaluation_time": NaN,
    "mteb_version": "unknown",
    "scores": {
        "test": [
            {
                "hf_subset": "sqi-eng",
                "languages": [
                    "sqi-Latn",
                    "eng-Latn"
                ],
                "accuracy": 91.0,
                "f1": 88.55666666666666,
                "precision": 87.46166666666667,
                "recall": 91.0,
                "main_score": 88.55666666666666
            },
            {
                "hf_subset": "fry-eng",
                "languages": [
                    "fry-Latn",
                    "eng-Latn"
                ],
                "accuracy": 57.22543352601156,
                "f1": 51.03220478943021,
                "precision": 48.8150289017341,
                "recall": 57.22543352601156,
                "main_score": 51.03220478943021
            },
            {
                "hf_subset": "kur-eng",
                "languages": [
                    "kur-Latn",
                    "eng-Latn"
                ],
                "accuracy": 46.58536585365854,
                "f1": 39.66870798578116,
                "precision": 37.416085946573745,
                "recall": 46.58536585365854,
                "main_score": 39.66870798578116
            },
            {
                "hf_subset": "tur-eng",
                "languages": [
                    "tur-Latn",
                    "eng-Latn"
                ],
                "accuracy": 89.7,
                "f1": 86.77999999999999,
                "precision": 85.45333333333332,
                "recall": 89.7,
                "main_score": 86.77999999999999
            },
            {
                "hf_subset": "deu-eng",
                "languages": [
                    "deu-Latn",
                    "eng-Latn"
                ],
                "accuracy": 97.39999999999999,
                "f1": 96.58333333333331,
                "precision": 96.2,
                "recall": 97.39999999999999,
                "main_score": 96.58333333333331
            },
            {
                "hf_subset": "nld-eng",
                "languages": [
                    "nld-Latn",
                    "eng-Latn"
                ],
                "accuracy": 92.4,
                "f1": 90.3,
                "precision": 89.31666666666668,
                "recall": 92.4,
                "main_score": 90.3
            },
            {
                "hf_subset": "ron-eng",
                "languages": [
                    "ron-Latn",
                    "eng-Latn"
                ],
                "accuracy": 86.9,
                "f1": 83.67190476190476,
                "precision": 82.23333333333332,
                "recall": 86.9,
                "main_score": 83.67190476190476
            },
            {
                "hf_subset": "ang-eng",
                "languages": [
                    "ang-Latn",
                    "eng-Latn"
                ],
                "accuracy": 50.0,
                "f1": 42.23229092632078,
                "precision": 39.851634683724235,
                "recall": 50.0,
                "main_score": 42.23229092632078
            },
            {
                "hf_subset": "ido-eng",
                "languages": [
                    "ido-Latn",
                    "eng-Latn"
                ],
                "accuracy": 76.3,
                "f1": 70.86190476190477,
                "precision": 68.68777777777777,
                "recall": 76.3,
                "main_score": 70.86190476190477
            },
            {
                "hf_subset": "jav-eng",
                "languages": [
                    "jav-Latn",
                    "eng-Latn"
                ],
                "accuracy": 57.073170731707314,
                "f1": 50.658958927251604,
                "precision": 48.26480836236933,
                "recall": 57.073170731707314,
                "main_score": 50.658958927251604
            },
            {
                "hf_subset": "isl-eng",
                "languages": [
                    "isl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 68.2,
                "f1": 62.156507936507936,
                "precision": 59.84964285714286,
                "recall": 68.2,
                "main_score": 62.156507936507936
            },
            {
                "hf_subset": "slv-eng",
                "languages": [
                    "slv-Latn",
                    "eng-Latn"
                ],
                "accuracy": 77.52126366950182,
                "f1": 72.8496210148701,
                "precision": 70.92171498003819,
                "recall": 77.52126366950182,
                "main_score": 72.8496210148701
            },
            {
                "hf_subset": "cym-eng",
                "languages": [
                    "cym-Latn",
                    "eng-Latn"
                ],
                "accuracy": 70.78260869565217,
                "f1": 65.32422360248447,
                "precision": 63.063067367415194,
                "recall": 70.78260869565217,
                "main_score": 65.32422360248447
            },
            {
                "hf_subset": "kaz-eng",
                "languages": [
                    "kaz-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 78.43478260869566,
                "f1": 73.02608695652172,
                "precision": 70.63768115942028,
                "recall": 78.43478260869566,
                "main_score": 73.02608695652172
            },
            {
                "hf_subset": "est-eng",
                "languages": [
                    "est-Latn",
                    "eng-Latn"
                ],
                "accuracy": 60.9,
                "f1": 55.309753694581275,
                "precision": 53.130476190476195,
                "recall": 60.9,
                "main_score": 55.309753694581275
            },
            {
                "hf_subset": "heb-eng",
                "languages": [
                    "heb-Hebr",
                    "eng-Latn"
                ],
                "accuracy": 72.89999999999999,
                "f1": 67.92023809523809,
                "precision": 65.82595238095237,
                "recall": 72.89999999999999,
                "main_score": 67.92023809523809
            },
            {
                "hf_subset": "gla-eng",
                "languages": [
                    "gla-Latn",
                    "eng-Latn"
                ],
                "accuracy": 46.80337756332931,
                "f1": 39.42174900558496,
                "precision": 36.97101116280851,
                "recall": 46.80337756332931,
                "main_score": 39.42174900558496
            },
            {
                "hf_subset": "mar-eng",
                "languages": [
                    "mar-Deva",
                    "eng-Latn"
                ],
                "accuracy": 89.8,
                "f1": 86.79,
                "precision": 85.375,
                "recall": 89.8,
                "main_score": 86.79
            },
            {
                "hf_subset": "lat-eng",
                "languages": [
                    "lat-Latn",
                    "eng-Latn"
                ],
                "accuracy": 47.199999999999996,
                "f1": 39.95484348984349,
                "precision": 37.561071428571424,
                "recall": 47.199999999999996,
                "main_score": 39.95484348984349
            },
            {
                "hf_subset": "bel-eng",
                "languages": [
                    "bel-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 87.8,
                "f1": 84.68190476190475,
                "precision": 83.275,
                "recall": 87.8,
                "main_score": 84.68190476190475
            },
            {
                "hf_subset": "pms-eng",
                "languages": [
                    "pms-Latn",
                    "eng-Latn"
                ],
                "accuracy": 48.76190476190476,
                "f1": 42.14965986394558,
                "precision": 39.96743626743626,
                "recall": 48.76190476190476,
                "main_score": 42.14965986394558
            },
            {
                "hf_subset": "gle-eng",
                "languages": [
                    "gle-Latn",
                    "eng-Latn"
                ],
                "accuracy": 66.10000000000001,
                "f1": 59.58580086580086,
                "precision": 57.150238095238095,
                "recall": 66.10000000000001,
                "main_score": 59.58580086580086
            },
            {
                "hf_subset": "pes-eng",
                "languages": [
                    "pes-Arab",
                    "eng-Latn"
                ],
                "accuracy": 87.3,
                "f1": 84.0,
                "precision": 82.48666666666666,
                "recall": 87.3,
                "main_score": 84.0
            },
            {
                "hf_subset": "nob-eng",
                "languages": [
                    "nob-Latn",
                    "eng-Latn"
                ],
                "accuracy": 90.4,
                "f1": 87.79523809523809,
                "precision": 86.6,
                "recall": 90.4,
                "main_score": 87.79523809523809
            },
            {
                "hf_subset": "bul-eng",
                "languages": [
                    "bul-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 87.0,
                "f1": 83.81,
                "precision": 82.36666666666666,
                "recall": 87.0,
                "main_score": 83.81
            },
            {
                "hf_subset": "cbk-eng",
                "languages": [
                    "cbk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 63.9,
                "f1": 57.76533189033189,
                "precision": 55.50595238095239,
                "recall": 63.9,
                "main_score": 57.76533189033189
            },
            {
                "hf_subset": "hun-eng",
                "languages": [
                    "hun-Latn",
                    "eng-Latn"
                ],
                "accuracy": 76.1,
                "f1": 71.83690476190478,
                "precision": 70.04928571428573,
                "recall": 76.1,
                "main_score": 71.83690476190478
            },
            {
                "hf_subset": "uig-eng",
                "languages": [
                    "uig-Arab",
                    "eng-Latn"
                ],
                "accuracy": 66.3,
                "f1": 59.32626984126984,
                "precision": 56.62535714285713,
                "recall": 66.3,
                "main_score": 59.32626984126984
            },
            {
                "hf_subset": "rus-eng",
                "languages": [
                    "rus-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 90.60000000000001,
                "f1": 87.96333333333334,
                "precision": 86.73333333333333,
                "recall": 90.60000000000001,
                "main_score": 87.96333333333334
            },
            {
                "hf_subset": "spa-eng",
                "languages": [
                    "spa-Latn",
                    "eng-Latn"
                ],
                "accuracy": 93.10000000000001,
                "f1": 91.10000000000001,
                "precision": 90.16666666666666,
                "recall": 93.10000000000001,
                "main_score": 91.10000000000001
            },
            {
                "hf_subset": "hye-eng",
                "languages": [
                    "hye-Armn",
                    "eng-Latn"
                ],
                "accuracy": 85.71428571428571,
                "f1": 82.29142600436403,
                "precision": 80.8076626877166,
                "recall": 85.71428571428571,
                "main_score": 82.29142600436403
            },
            {
                "hf_subset": "tel-eng",
                "languages": [
                    "tel-Telu",
                    "eng-Latn"
                ],
                "accuracy": 88.88888888888889,
                "f1": 85.7834757834758,
                "precision": 84.43732193732193,
                "recall": 88.88888888888889,
                "main_score": 85.7834757834758
            },
            {
                "hf_subset": "afr-eng",
                "languages": [
                    "afr-Latn",
                    "eng-Latn"
                ],
                "accuracy": 88.5,
                "f1": 85.67190476190476,
                "precision": 84.43333333333332,
                "recall": 88.5,
                "main_score": 85.67190476190476
            },
            {
                "hf_subset": "mon-eng",
                "languages": [
                    "mon-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 82.72727272727273,
                "f1": 78.21969696969695,
                "precision": 76.18181818181819,
                "recall": 82.72727272727273,
                "main_score": 78.21969696969695
            },
            {
                "hf_subset": "arz-eng",
                "languages": [
                    "arz-Arab",
                    "eng-Latn"
                ],
                "accuracy": 61.0062893081761,
                "f1": 55.13976240391334,
                "precision": 52.92112499659669,
                "recall": 61.0062893081761,
                "main_score": 55.13976240391334
            },
            {
                "hf_subset": "hrv-eng",
                "languages": [
                    "hrv-Latn",
                    "eng-Latn"
                ],
                "accuracy": 89.5,
                "f1": 86.86666666666666,
                "precision": 85.69166666666668,
                "recall": 89.5,
                "main_score": 86.86666666666666
            },
            {
                "hf_subset": "nov-eng",
                "languages": [
                    "nov-Latn",
                    "eng-Latn"
                ],
                "accuracy": 73.54085603112841,
                "f1": 68.56031128404669,
                "precision": 66.53047989623866,
                "recall": 73.54085603112841,
                "main_score": 68.56031128404669
            },
            {
                "hf_subset": "gsw-eng",
                "languages": [
                    "gsw-Latn",
                    "eng-Latn"
                ],
                "accuracy": 43.58974358974359,
                "f1": 36.45299145299145,
                "precision": 33.81155881155882,
                "recall": 43.58974358974359,
                "main_score": 36.45299145299145
            },
            {
                "hf_subset": "nds-eng",
                "languages": [
                    "nds-Latn",
                    "eng-Latn"
                ],
                "accuracy": 59.599999999999994,
                "f1": 53.264689754689755,
                "precision": 50.869166666666665,
                "recall": 59.599999999999994,
                "main_score": 53.264689754689755
            },
            {
                "hf_subset": "ukr-eng",
                "languages": [
                    "ukr-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 85.2,
                "f1": 81.61666666666665,
                "precision": 80.02833333333335,
                "recall": 85.2,
                "main_score": 81.61666666666665
            },
            {
                "hf_subset": "uzb-eng",
                "languages": [
                    "uzb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 63.78504672897196,
                "f1": 58.00029669188548,
                "precision": 55.815809968847354,
                "recall": 63.78504672897196,
                "main_score": 58.00029669188548
            },
            {
                "hf_subset": "lit-eng",
                "languages": [
                    "lit-Latn",
                    "eng-Latn"
                ],
                "accuracy": 66.5,
                "f1": 61.518333333333345,
                "precision": 59.622363699102834,
                "recall": 66.5,
                "main_score": 61.518333333333345
            },
            {
                "hf_subset": "ina-eng",
                "languages": [
                    "ina-Latn",
                    "eng-Latn"
                ],
                "accuracy": 88.6,
                "f1": 85.60222222222221,
                "precision": 84.27916666666665,
                "recall": 88.6,
                "main_score": 85.60222222222221
            },
            {
                "hf_subset": "lfn-eng",
                "languages": [
                    "lfn-Latn",
                    "eng-Latn"
                ],
                "accuracy": 58.699999999999996,
                "f1": 52.732375957375965,
                "precision": 50.63214035964035,
                "recall": 58.699999999999996,
                "main_score": 52.732375957375965
            },
            {
                "hf_subset": "zsm-eng",
                "languages": [
                    "zsm-Latn",
                    "eng-Latn"
                ],
                "accuracy": 92.10000000000001,
                "f1": 89.99666666666667,
                "precision": 89.03333333333333,
                "recall": 92.10000000000001,
                "main_score": 89.99666666666667
            },
            {
                "hf_subset": "ita-eng",
                "languages": [
                    "ita-Latn",
                    "eng-Latn"
                ],
                "accuracy": 90.10000000000001,
                "f1": 87.55666666666667,
                "precision": 86.36166666666668,
                "recall": 90.10000000000001,
                "main_score": 87.55666666666667
            },
            {
                "hf_subset": "cmn-eng",
                "languages": [
                    "cmn-Hans",
                    "eng-Latn"
                ],
                "accuracy": 91.4,
                "f1": 88.89000000000001,
                "precision": 87.71166666666666,
                "recall": 91.4,
                "main_score": 88.89000000000001
            },
            {
                "hf_subset": "lvs-eng",
                "languages": [
                    "lvs-Latn",
                    "eng-Latn"
                ],
                "accuracy": 65.7,
                "f1": 60.67427750410509,
                "precision": 58.71785714285714,
                "recall": 65.7,
                "main_score": 60.67427750410509
            },
            {
                "hf_subset": "glg-eng",
                "languages": [
                    "glg-Latn",
                    "eng-Latn"
                ],
                "accuracy": 85.39999999999999,
                "f1": 81.93190476190475,
                "precision": 80.37833333333333,
                "recall": 85.39999999999999,
                "main_score": 81.93190476190475
            },
            {
                "hf_subset": "ceb-eng",
                "languages": [
                    "ceb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 47.833333333333336,
                "f1": 42.006625781625786,
                "precision": 40.077380952380956,
                "recall": 47.833333333333336,
                "main_score": 42.006625781625786
            },
            {
                "hf_subset": "bre-eng",
                "languages": [
                    "bre-Latn",
                    "eng-Latn"
                ],
                "accuracy": 10.4,
                "f1": 8.24465007215007,
                "precision": 7.664597069597071,
                "recall": 10.4,
                "main_score": 8.24465007215007
            },
            {
                "hf_subset": "ben-eng",
                "languages": [
                    "ben-Beng",
                    "eng-Latn"
                ],
                "accuracy": 82.6,
                "f1": 77.76333333333334,
                "precision": 75.57833333333332,
                "recall": 82.6,
                "main_score": 77.76333333333334
            },
            {
                "hf_subset": "swg-eng",
                "languages": [
                    "swg-Latn",
                    "eng-Latn"
                ],
                "accuracy": 52.67857142857143,
                "f1": 44.302721088435376,
                "precision": 41.49801587301587,
                "recall": 52.67857142857143,
                "main_score": 44.302721088435376
            },
            {
                "hf_subset": "arq-eng",
                "languages": [
                    "arq-Arab",
                    "eng-Latn"
                ],
                "accuracy": 28.3205268935236,
                "f1": 22.426666605171157,
                "precision": 20.685900116470915,
                "recall": 28.3205268935236,
                "main_score": 22.426666605171157
            },
            {
                "hf_subset": "kab-eng",
                "languages": [
                    "kab-Latn",
                    "eng-Latn"
                ],
                "accuracy": 22.7,
                "f1": 17.833970473970474,
                "precision": 16.407335164835164,
                "recall": 22.7,
                "main_score": 17.833970473970474
            },
            {
                "hf_subset": "fra-eng",
                "languages": [
                    "fra-Latn",
                    "eng-Latn"
                ],
                "accuracy": 92.2,
                "f1": 89.92999999999999,
                "precision": 88.87,
                "recall": 92.2,
                "main_score": 89.92999999999999
            },
            {
                "hf_subset": "por-eng",
                "languages": [
                    "por-Latn",
                    "eng-Latn"
                ],
                "accuracy": 91.4,
                "f1": 89.25,
                "precision": 88.21666666666667,
                "recall": 91.4,
                "main_score": 89.25
            },
            {
                "hf_subset": "tat-eng",
                "languages": [
                    "tat-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 69.19999999999999,
                "f1": 63.38269841269841,
                "precision": 61.14773809523809,
                "recall": 69.19999999999999,
                "main_score": 63.38269841269841
            },
            {
                "hf_subset": "oci-eng",
                "languages": [
                    "oci-Latn",
                    "eng-Latn"
                ],
                "accuracy": 48.8,
                "f1": 42.839915639915645,
                "precision": 40.770287114845935,
                "recall": 48.8,
                "main_score": 42.839915639915645
            },
            {
                "hf_subset": "pol-eng",
                "languages": [
                    "pol-Latn",
                    "eng-Latn"
                ],
                "accuracy": 88.8,
                "f1": 85.90666666666668,
                "precision": 84.54166666666666,
                "recall": 88.8,
                "main_score": 85.90666666666668
            },
            {
                "hf_subset": "war-eng",
                "languages": [
                    "war-Latn",
                    "eng-Latn"
                ],
                "accuracy": 46.6,
                "f1": 40.85892920804686,
                "precision": 38.838223114604695,
                "recall": 46.6,
                "main_score": 40.85892920804686
            },
            {
                "hf_subset": "aze-eng",
                "languages": [
                    "aze-Latn",
                    "eng-Latn"
                ],
                "accuracy": 84.0,
                "f1": 80.14190476190475,
                "precision": 78.45333333333333,
                "recall": 84.0,
                "main_score": 80.14190476190475
            },
            {
                "hf_subset": "vie-eng",
                "languages": [
                    "vie-Latn",
                    "eng-Latn"
                ],
                "accuracy": 90.5,
                "f1": 87.78333333333333,
                "precision": 86.5,
                "recall": 90.5,
                "main_score": 87.78333333333333
            },
            {
                "hf_subset": "nno-eng",
                "languages": [
                    "nno-Latn",
                    "eng-Latn"
                ],
                "accuracy": 74.5,
                "f1": 69.48397546897547,
                "precision": 67.51869047619049,
                "recall": 74.5,
                "main_score": 69.48397546897547
            },
            {
                "hf_subset": "cha-eng",
                "languages": [
                    "cha-Latn",
                    "eng-Latn"
                ],
                "accuracy": 32.846715328467155,
                "f1": 27.828177499710343,
                "precision": 26.63451511991658,
                "recall": 32.846715328467155,
                "main_score": 27.828177499710343
            },
            {
                "hf_subset": "mhr-eng",
                "languages": [
                    "mhr-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 8.0,
                "f1": 6.07664116764988,
                "precision": 5.544177607179943,
                "recall": 8.0,
                "main_score": 6.07664116764988
            },
            {
                "hf_subset": "dan-eng",
                "languages": [
                    "dan-Latn",
                    "eng-Latn"
                ],
                "accuracy": 87.6,
                "f1": 84.38555555555554,
                "precision": 82.91583333333334,
                "recall": 87.6,
                "main_score": 84.38555555555554
            },
            {
                "hf_subset": "ell-eng",
                "languages": [
                    "ell-Grek",
                    "eng-Latn"
                ],
                "accuracy": 87.5,
                "f1": 84.08333333333331,
                "precision": 82.47333333333333,
                "recall": 87.5,
                "main_score": 84.08333333333331
            },
            {
                "hf_subset": "amh-eng",
                "languages": [
                    "amh-Ethi",
                    "eng-Latn"
                ],
                "accuracy": 80.95238095238095,
                "f1": 76.13095238095238,
                "precision": 74.05753968253967,
                "recall": 80.95238095238095,
                "main_score": 76.13095238095238
            },
            {
                "hf_subset": "pam-eng",
                "languages": [
                    "pam-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.799999999999999,
                "f1": 6.971422975172975,
                "precision": 6.557814916172301,
                "recall": 8.799999999999999,
                "main_score": 6.971422975172975
            },
            {
                "hf_subset": "hsb-eng",
                "languages": [
                    "hsb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 44.099378881987576,
                "f1": 37.01649742022413,
                "precision": 34.69420618488942,
                "recall": 44.099378881987576,
                "main_score": 37.01649742022413
            },
            {
                "hf_subset": "srp-eng",
                "languages": [
                    "srp-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 84.3,
                "f1": 80.32666666666667,
                "precision": 78.60666666666665,
                "recall": 84.3,
                "main_score": 80.32666666666667
            },
            {
                "hf_subset": "epo-eng",
                "languages": [
                    "epo-Latn",
                    "eng-Latn"
                ],
                "accuracy": 92.5,
                "f1": 90.49666666666666,
                "precision": 89.56666666666668,
                "recall": 92.5,
                "main_score": 90.49666666666666
            },
            {
                "hf_subset": "kzj-eng",
                "languages": [
                    "kzj-Latn",
                    "eng-Latn"
                ],
                "accuracy": 10.0,
                "f1": 8.268423529875141,
                "precision": 7.878118605532398,
                "recall": 10.0,
                "main_score": 8.268423529875141
            },
            {
                "hf_subset": "awa-eng",
                "languages": [
                    "awa-Deva",
                    "eng-Latn"
                ],
                "accuracy": 79.22077922077922,
                "f1": 74.27128427128426,
                "precision": 72.28715728715729,
                "recall": 79.22077922077922,
                "main_score": 74.27128427128426
            },
            {
                "hf_subset": "fao-eng",
                "languages": [
                    "fao-Latn",
                    "eng-Latn"
                ],
                "accuracy": 65.64885496183206,
                "f1": 58.87495456197747,
                "precision": 55.992366412213734,
                "recall": 65.64885496183206,
                "main_score": 58.87495456197747
            },
            {
                "hf_subset": "mal-eng",
                "languages": [
                    "mal-Mlym",
                    "eng-Latn"
                ],
                "accuracy": 96.06986899563319,
                "f1": 94.78408539543909,
                "precision": 94.15332362930616,
                "recall": 96.06986899563319,
                "main_score": 94.78408539543909
            },
            {
                "hf_subset": "ile-eng",
                "languages": [
                    "ile-Latn",
                    "eng-Latn"
                ],
                "accuracy": 77.2,
                "f1": 71.72571428571428,
                "precision": 69.41000000000001,
                "recall": 77.2,
                "main_score": 71.72571428571428
            },
            {
                "hf_subset": "bos-eng",
                "languages": [
                    "bos-Latn",
                    "eng-Latn"
                ],
                "accuracy": 86.4406779661017,
                "f1": 83.2391713747646,
                "precision": 81.74199623352166,
                "recall": 86.4406779661017,
                "main_score": 83.2391713747646
            },
            {
                "hf_subset": "cor-eng",
                "languages": [
                    "cor-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.4,
                "f1": 6.017828743398003,
                "precision": 5.4829865484756795,
                "recall": 8.4,
                "main_score": 6.017828743398003
            },
            {
                "hf_subset": "cat-eng",
                "languages": [
                    "cat-Latn",
                    "eng-Latn"
                ],
                "accuracy": 83.5,
                "f1": 79.74833333333333,
                "precision": 78.04837662337664,
                "recall": 83.5,
                "main_score": 79.74833333333333
            },
            {
                "hf_subset": "eus-eng",
                "languages": [
                    "eus-Latn",
                    "eng-Latn"
                ],
                "accuracy": 60.4,
                "f1": 54.467301587301584,
                "precision": 52.23242424242424,
                "recall": 60.4,
                "main_score": 54.467301587301584
            },
            {
                "hf_subset": "yue-eng",
                "languages": [
                    "yue-Hant",
                    "eng-Latn"
                ],
                "accuracy": 74.9,
                "f1": 69.68699134199134,
                "precision": 67.59873015873016,
                "recall": 74.9,
                "main_score": 69.68699134199134
            },
            {
                "hf_subset": "swe-eng",
                "languages": [
                    "swe-Latn",
                    "eng-Latn"
                ],
                "accuracy": 88.0,
                "f1": 84.9652380952381,
                "precision": 83.66166666666666,
                "recall": 88.0,
                "main_score": 84.9652380952381
            },
            {
                "hf_subset": "dtp-eng",
                "languages": [
                    "dtp-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.1,
                "f1": 7.681244588744588,
                "precision": 7.370043290043291,
                "recall": 9.1,
                "main_score": 7.681244588744588
            },
            {
                "hf_subset": "kat-eng",
                "languages": [
                    "kat-Geor",
                    "eng-Latn"
                ],
                "accuracy": 80.9651474530831,
                "f1": 76.84220605132133,
                "precision": 75.19606398962966,
                "recall": 80.9651474530831,
                "main_score": 76.84220605132133
            },
            {
                "hf_subset": "jpn-eng",
                "languages": [
                    "jpn-Jpan",
                    "eng-Latn"
                ],
                "accuracy": 86.9,
                "f1": 83.705,
                "precision": 82.3120634920635,
                "recall": 86.9,
                "main_score": 83.705
            },
            {
                "hf_subset": "csb-eng",
                "languages": [
                    "csb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 29.64426877470356,
                "f1": 23.98763072676116,
                "precision": 22.506399397703746,
                "recall": 29.64426877470356,
                "main_score": 23.98763072676116
            },
            {
                "hf_subset": "xho-eng",
                "languages": [
                    "xho-Latn",
                    "eng-Latn"
                ],
                "accuracy": 70.4225352112676,
                "f1": 62.84037558685445,
                "precision": 59.56572769953053,
                "recall": 70.4225352112676,
                "main_score": 62.84037558685445
            },
            {
                "hf_subset": "orv-eng",
                "languages": [
                    "orv-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 19.64071856287425,
                "f1": 15.125271011207756,
                "precision": 13.865019261197494,
                "recall": 19.64071856287425,
                "main_score": 15.125271011207756
            },
            {
                "hf_subset": "ind-eng",
                "languages": [
                    "ind-Latn",
                    "eng-Latn"
                ],
                "accuracy": 90.2,
                "f1": 87.80666666666666,
                "precision": 86.70833333333331,
                "recall": 90.2,
                "main_score": 87.80666666666666
            },
            {
                "hf_subset": "tuk-eng",
                "languages": [
                    "tuk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 23.15270935960591,
                "f1": 18.407224958949097,
                "precision": 16.982385430661292,
                "recall": 23.15270935960591,
                "main_score": 18.407224958949097
            },
            {
                "hf_subset": "max-eng",
                "languages": [
                    "max-Deva",
                    "eng-Latn"
                ],
                "accuracy": 55.98591549295775,
                "f1": 49.94718309859154,
                "precision": 47.77864154624717,
                "recall": 55.98591549295775,
                "main_score": 49.94718309859154
            },
            {
                "hf_subset": "swh-eng",
                "languages": [
                    "swh-Latn",
                    "eng-Latn"
                ],
                "accuracy": 73.07692307692307,
                "f1": 66.74358974358974,
                "precision": 64.06837606837607,
                "recall": 73.07692307692307,
                "main_score": 66.74358974358974
            },
            {
                "hf_subset": "hin-eng",
                "languages": [
                    "hin-Deva",
                    "eng-Latn"
                ],
                "accuracy": 94.89999999999999,
                "f1": 93.25,
                "precision": 92.43333333333332,
                "recall": 94.89999999999999,
                "main_score": 93.25
            },
            {
                "hf_subset": "dsb-eng",
                "languages": [
                    "dsb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 37.78705636743215,
                "f1": 31.63899658680452,
                "precision": 29.72264397629742,
                "recall": 37.78705636743215,
                "main_score": 31.63899658680452
            },
            {
                "hf_subset": "ber-eng",
                "languages": [
                    "ber-Tfng",
                    "eng-Latn"
                ],
                "accuracy": 21.6,
                "f1": 16.91697302697303,
                "precision": 15.71225147075147,
                "recall": 21.6,
                "main_score": 16.91697302697303
            },
            {
                "hf_subset": "tam-eng",
                "languages": [
                    "tam-Taml",
                    "eng-Latn"
                ],
                "accuracy": 85.01628664495115,
                "f1": 81.38514037536838,
                "precision": 79.83170466883823,
                "recall": 85.01628664495115,
                "main_score": 81.38514037536838
            },
            {
                "hf_subset": "slk-eng",
                "languages": [
                    "slk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 83.39999999999999,
                "f1": 79.96380952380952,
                "precision": 78.48333333333333,
                "recall": 83.39999999999999,
                "main_score": 79.96380952380952
            },
            {
                "hf_subset": "tgl-eng",
                "languages": [
                    "tgl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 83.2,
                "f1": 79.26190476190476,
                "precision": 77.58833333333334,
                "recall": 83.2,
                "main_score": 79.26190476190476
            },
            {
                "hf_subset": "ast-eng",
                "languages": [
                    "ast-Latn",
                    "eng-Latn"
                ],
                "accuracy": 75.59055118110236,
                "f1": 71.66854143232096,
                "precision": 70.30183727034121,
                "recall": 75.59055118110236,
                "main_score": 71.66854143232096
            },
            {
                "hf_subset": "mkd-eng",
                "languages": [
                    "mkd-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 65.5,
                "f1": 59.26095238095238,
                "precision": 56.81909090909092,
                "recall": 65.5,
                "main_score": 59.26095238095238
            },
            {
                "hf_subset": "khm-eng",
                "languages": [
                    "khm-Khmr",
                    "eng-Latn"
                ],
                "accuracy": 55.26315789473685,
                "f1": 47.986523325858506,
                "precision": 45.33950006595436,
                "recall": 55.26315789473685,
                "main_score": 47.986523325858506
            },
            {
                "hf_subset": "ces-eng",
                "languages": [
                    "ces-Latn",
                    "eng-Latn"
                ],
                "accuracy": 82.89999999999999,
                "f1": 78.835,
                "precision": 77.04761904761905,
                "recall": 82.89999999999999,
                "main_score": 78.835
            },
            {
                "hf_subset": "tzl-eng",
                "languages": [
                    "tzl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 43.269230769230774,
                "f1": 36.20421245421245,
                "precision": 33.57371794871795,
                "recall": 43.269230769230774,
                "main_score": 36.20421245421245
            },
            {
                "hf_subset": "urd-eng",
                "languages": [
                    "urd-Arab",
                    "eng-Latn"
                ],
                "accuracy": 88.0,
                "f1": 84.70666666666666,
                "precision": 83.23166666666665,
                "recall": 88.0,
                "main_score": 84.70666666666666
            },
            {
                "hf_subset": "ara-eng",
                "languages": [
                    "ara-Arab",
                    "eng-Latn"
                ],
                "accuracy": 77.4,
                "f1": 72.54666666666667,
                "precision": 70.54318181818181,
                "recall": 77.4,
                "main_score": 72.54666666666667
            },
            {
                "hf_subset": "kor-eng",
                "languages": [
                    "kor-Hang",
                    "eng-Latn"
                ],
                "accuracy": 78.60000000000001,
                "f1": 74.1588888888889,
                "precision": 72.30250000000001,
                "recall": 78.60000000000001,
                "main_score": 74.1588888888889
            },
            {
                "hf_subset": "yid-eng",
                "languages": [
                    "yid-Hebr",
                    "eng-Latn"
                ],
                "accuracy": 72.40566037735849,
                "f1": 66.82587328813744,
                "precision": 64.75039308176099,
                "recall": 72.40566037735849,
                "main_score": 66.82587328813744
            },
            {
                "hf_subset": "fin-eng",
                "languages": [
                    "fin-Latn",
                    "eng-Latn"
                ],
                "accuracy": 73.8,
                "f1": 68.56357142857144,
                "precision": 66.3178822055138,
                "recall": 73.8,
                "main_score": 68.56357142857144
            },
            {
                "hf_subset": "tha-eng",
                "languages": [
                    "tha-Thai",
                    "eng-Latn"
                ],
                "accuracy": 91.78832116788321,
                "f1": 89.3552311435523,
                "precision": 88.20559610705597,
                "recall": 91.78832116788321,
                "main_score": 89.3552311435523
            },
            {
                "hf_subset": "wuu-eng",
                "languages": [
                    "wuu-Hans",
                    "eng-Latn"
                ],
                "accuracy": 74.3,
                "f1": 69.05085581085581,
                "precision": 66.955,
                "recall": 74.3,
                "main_score": 69.05085581085581
            }
        ]
    }
}