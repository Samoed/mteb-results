{
    "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": NaN,
    "mteb_version": "unknown",
    "scores": {
        "test": [
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 75.37323470073974,
                "f1": 71.1836877753734,
                "f1_weighted": 75.72073213955457,
                "main_score": 75.37323470073974
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 74.83523873570948,
                "f1": 70.72375821116886,
                "f1_weighted": 75.20800490010755,
                "main_score": 74.83523873570948
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 75.31607262945528,
                "f1": 72.06063554897662,
                "f1_weighted": 75.72438161355252,
                "main_score": 75.31607262945528
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 76.7955615332885,
                "f1": 73.08099648499756,
                "f1_weighted": 77.18482068239668,
                "main_score": 76.7955615332885
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 77.60591795561534,
                "f1": 74.46676705370395,
                "f1_weighted": 77.69888062336614,
                "main_score": 77.60591795561534
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 76.32145258910558,
                "f1": 72.89824154178328,
                "f1_weighted": 76.6539327979472,
                "main_score": 76.32145258910558
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 73.21788836583724,
                "f1": 70.45594512246377,
                "f1_weighted": 73.67862536499393,
                "main_score": 73.21788836583724
            }
        ]
    }
}