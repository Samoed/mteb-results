{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 37.22259583053128,
                "f1": 34.63013680947778,
                "main_score": 37.22259583053128
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 3.194351042367182,
                "f1": 1.2612010214639442,
                "main_score": 3.194351042367182
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 14.26361802286483,
                "f1": 13.70260406613821,
                "main_score": 14.26361802286483
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 37.21923335574983,
                "f1": 36.33553913878251,
                "main_score": 37.21923335574983
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 10.756556825823807,
                "f1": 9.676431920229374,
                "main_score": 10.756556825823807
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 32.49831876260928,
                "f1": 30.818895782691868,
                "main_score": 32.49831876260928
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 40.995292535305985,
                "f1": 37.68768183180129,
                "main_score": 40.995292535305985
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 42.780766644250164,
                "f1": 37.82194830667135,
                "main_score": 42.780766644250164
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 33.490248823133825,
                "f1": 29.71809045584527,
                "main_score": 33.490248823133825
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 73.8836583725622,
                "f1": 72.16381047416814,
                "main_score": 73.8836583725622
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 44.45191661062542,
                "f1": 43.46583297093683,
                "main_score": 44.45191661062542
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 26.738399462004036,
                "f1": 24.11896530001951,
                "main_score": 26.738399462004036
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 38.09683927370545,
                "f1": 35.34443269387154,
                "main_score": 38.09683927370545
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 46.89307330195024,
                "f1": 43.47164092514292,
                "main_score": 46.89307330195024
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 25.198386012104912,
                "f1": 22.446286736401916,
                "main_score": 25.198386012104912
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 13.940820443846672,
                "f1": 13.257747189396213,
                "main_score": 13.940820443846672
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 34.710827168796236,
                "f1": 32.036974696095996,
                "main_score": 34.710827168796236
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 6.711499663752522,
                "f1": 5.439441019096591,
                "main_score": 6.711499663752522
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 38.56758574310693,
                "f1": 36.83183505458304,
                "main_score": 38.56758574310693
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 32.22595830531271,
                "f1": 30.10972675771159,
                "main_score": 32.22595830531271
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 45.79690652320107,
                "f1": 44.37143784350453,
                "main_score": 45.79690652320107
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 29.189643577673163,
                "f1": 25.43718135312703,
                "main_score": 29.189643577673163
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 34.21990585070612,
                "f1": 32.333592263041396,
                "main_score": 34.21990585070612
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 8.890383322125084,
                "f1": 7.294310113130201,
                "main_score": 8.890383322125084
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 4.616677874915938,
                "f1": 1.5028537477535886,
                "main_score": 4.616677874915938
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 3.170813718897109,
                "f1": 1.5771411815826382,
                "main_score": 3.170813718897109
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 15.026899798251513,
                "f1": 14.077395255366183,
                "main_score": 15.026899798251513
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 36.0995292535306,
                "f1": 35.0877269083235,
                "main_score": 36.0995292535306
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 2.9959650302622727,
                "f1": 0.8064424547273695,
                "main_score": 2.9959650302622727
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 23.301950235373234,
                "f1": 22.477376205075853,
                "main_score": 23.301950235373234
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 36.13315400134499,
                "f1": 32.99623898888715,
                "main_score": 36.13315400134499
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 3.813046402151983,
                "f1": 1.1769597223141248,
                "main_score": 3.813046402151983
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 39.66711499663752,
                "f1": 35.921474753569214,
                "main_score": 39.66711499663752
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 41.079354404841965,
                "f1": 37.57739961852201,
                "main_score": 41.079354404841965
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 38.211163416274374,
                "f1": 34.89419275422068,
                "main_score": 38.211163416274374
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 45.19838601210491,
                "f1": 42.71660225307043,
                "main_score": 45.19838601210491
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 39.48554135843981,
                "f1": 37.47402102847154,
                "main_score": 39.48554135843981
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 31.819098856758576,
                "f1": 30.120158288509725,
                "main_score": 31.819098856758576
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 35.44720914593141,
                "f1": 33.74530063536304,
                "main_score": 35.44720914593141
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 36.89307330195024,
                "f1": 34.46971619696105,
                "main_score": 36.89307330195024
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 38.83322125084062,
                "f1": 36.050770344888264,
                "main_score": 38.83322125084062
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 37.535305985205106,
                "f1": 35.21395700670493,
                "main_score": 37.535305985205106
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 7.905178211163418,
                "f1": 6.163513326325246,
                "main_score": 7.905178211163418
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 2.8480161398789514,
                "f1": 1.0163931337986962,
                "main_score": 2.8480161398789514
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 10.501008742434433,
                "f1": 6.858549418430471,
                "main_score": 10.501008742434433
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 39.46536650975118,
                "f1": 34.96292597328575,
                "main_score": 39.46536650975118
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 37.50168123739071,
                "f1": 35.031097269820464,
                "main_score": 37.50168123739071
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 16.109616677874918,
                "f1": 15.884609726192519,
                "main_score": 16.109616677874918
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 36.11297915265636,
                "f1": 34.59918716321474,
                "main_score": 36.11297915265636
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 18.850033624747812,
                "f1": 15.09584388649328,
                "main_score": 18.850033624747812
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 17.219233355749832,
                "f1": 14.538046039008337,
                "main_score": 17.219233355749832
            }
        ]
    }
}