{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": NaN,
    "mteb_version": "unknown",
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 57.94552790854068,
                "main_score": 57.94552790854068
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 49.273705447209146,
                "main_score": 49.273705447209146
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 55.490921318090116,
                "main_score": 55.490921318090116
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 60.97511768661733,
                "main_score": 60.97511768661733
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 57.5689307330195,
                "main_score": 57.5689307330195
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 48.34902488231337,
                "main_score": 48.34902488231337
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 63.6684599865501,
                "main_score": 63.6684599865501
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 62.54539340954942,
                "main_score": 62.54539340954942
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 63.08675184936112,
                "main_score": 63.08675184936112
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 72.12508406186953,
                "main_score": 72.12508406186953
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 67.41425689307331,
                "main_score": 67.41425689307331
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 65.59515803631474,
                "main_score": 65.59515803631474
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 62.90517821116342,
                "main_score": 62.90517821116342
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 67.91526563550774,
                "main_score": 67.91526563550774
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 55.198386012104905,
                "main_score": 55.198386012104905
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 65.04371217215869,
                "main_score": 65.04371217215869
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 63.31203765971756,
                "main_score": 63.31203765971756
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 55.521183591123055,
                "main_score": 55.521183591123055
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 66.06254203093476,
                "main_score": 66.06254203093476
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 56.01546738399461,
                "main_score": 56.01546738399461
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 67.27975790181574,
                "main_score": 67.27975790181574
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 66.79556153328849,
                "main_score": 66.79556153328849
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 50.18493611297915,
                "main_score": 50.18493611297915
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 47.888365837256224,
                "main_score": 47.888365837256224
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 50.79690652320108,
                "main_score": 50.79690652320108
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 57.225958305312716,
                "main_score": 57.225958305312716
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 64.58641560188299,
                "main_score": 64.58641560188299
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 59.08204438466711,
                "main_score": 59.08204438466711
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 59.54606590450572,
                "main_score": 59.54606590450572
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 53.443174176193665,
                "main_score": 53.443174176193665
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 61.65097511768661,
                "main_score": 61.65097511768661
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 53.45662407531944,
                "main_score": 53.45662407531944
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 63.739071956960316,
                "main_score": 63.739071956960316
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 66.36180228648286,
                "main_score": 66.36180228648286
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 66.3920645595158,
                "main_score": 66.3920645595158
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 68.06993947545395,
                "main_score": 68.06993947545395
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 63.123739071956955,
                "main_score": 63.123739071956955
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 67.46133154001346,
                "main_score": 67.46133154001346
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 60.54472091459314,
                "main_score": 60.54472091459314
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 58.204438466711494,
                "main_score": 58.204438466711494
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 65.69603227975792,
                "main_score": 65.69603227975792
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 51.684599865501,
                "main_score": 51.684599865501
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 58.523873570948226,
                "main_score": 58.523873570948226
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 58.53396099529253,
                "main_score": 58.53396099529253
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 61.88298587760591,
                "main_score": 61.88298587760591
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 56.65097511768662,
                "main_score": 56.65097511768662
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 64.8453261600538,
                "main_score": 64.8453261600538
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 58.6247478143914,
                "main_score": 58.6247478143914
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 64.16274377942166,
                "main_score": 64.16274377942166
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 69.61667787491594,
                "main_score": 69.61667787491594
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 64.17283120376598,
                "main_score": 64.17283120376598
            }
        ]
    }
}