{
    "dataset_revision": "160c094312a0e1facb97e55eeddb698c0abe3571",
    "task_name": "CQADupstackWebmastersRetrieval",
    "evaluation_time": NaN,
    "mteb_version": "unknown",
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "map_at_1": 27.206999999999997,
                "map_at_10": 36.146,
                "map_at_100": 37.759,
                "map_at_1000": 37.979,
                "map_at_3": 32.967999999999996,
                "map_at_5": 34.809,
                "mrr_at_1": 32.806000000000004,
                "mrr_at_10": 40.449,
                "mrr_at_100": 41.404999999999994,
                "mrr_at_1000": 41.457,
                "mrr_at_3": 37.614999999999995,
                "mrr_at_5": 39.324999999999996,
                "ndcg_at_1": 32.806000000000004,
                "ndcg_at_10": 41.911,
                "ndcg_at_100": 47.576,
                "ndcg_at_1000": 50.072,
                "ndcg_at_3": 36.849,
                "ndcg_at_5": 39.475,
                "precision_at_1": 32.806000000000004,
                "precision_at_10": 8.103,
                "precision_at_100": 1.557,
                "precision_at_1000": 0.242,
                "precision_at_3": 17.26,
                "precision_at_5": 12.885,
                "recall_at_1": 27.206999999999997,
                "recall_at_10": 52.56999999999999,
                "recall_at_100": 78.302,
                "recall_at_1000": 94.121,
                "recall_at_3": 38.317,
                "recall_at_5": 45.410000000000004,
                "main_score": 41.911
            }
        ]
    }
}