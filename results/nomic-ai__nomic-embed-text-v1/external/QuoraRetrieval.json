{
    "dataset_revision": "None",
    "task_name": "QuoraRetrieval",
    "evaluation_time": NaN,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "map_at_1": 70.256,
                "map_at_10": 83.8,
                "map_at_100": 84.425,
                "map_at_1000": 84.444,
                "map_at_3": 80.906,
                "map_at_5": 82.717,
                "mrr_at_1": 80.97999999999999,
                "mrr_at_10": 87.161,
                "mrr_at_100": 87.262,
                "mrr_at_1000": 87.263,
                "mrr_at_3": 86.175,
                "mrr_at_5": 86.848,
                "ndcg_at_1": 80.97999999999999,
                "ndcg_at_10": 87.697,
                "ndcg_at_100": 88.959,
                "ndcg_at_1000": 89.09899999999999,
                "ndcg_at_3": 84.83800000000001,
                "ndcg_at_5": 86.401,
                "precision_at_1": 80.97999999999999,
                "precision_at_10": 13.261000000000001,
                "precision_at_100": 1.5150000000000001,
                "precision_at_1000": 0.156,
                "precision_at_3": 37.01,
                "precision_at_5": 24.298000000000002,
                "recall_at_1": 70.256,
                "recall_at_10": 94.935,
                "recall_at_100": 99.274,
                "recall_at_1000": 99.928,
                "recall_at_3": 86.602,
                "recall_at_5": 91.133,
                "main_score": 87.697
            }
        ]
    }
}