{
    "dataset_revision": "7d571f92784cd94a019292a1f45445077d0ef634",
    "task_name": "MassiveScenarioClassification",
    "evaluation_time": NaN,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 63.04303967720243,
                "f1": 60.3950085685985,
                "main_score": 63.04303967720243
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 56.83591123066578,
                "f1": 54.95059828830849,
                "main_score": 56.83591123066578
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 59.62340282447881,
                "f1": 59.525159996498225,
                "main_score": 59.62340282447881
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 60.85406859448555,
                "f1": 59.129299095681276,
                "main_score": 60.85406859448555
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 62.76731674512441,
                "f1": 61.159560612627715,
                "main_score": 62.76731674512441
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 50.181573638197705,
                "f1": 46.98422176289957,
                "main_score": 50.181573638197705
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 68.92737054472092,
                "f1": 67.69135611952979,
                "main_score": 68.92737054472092
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 69.18964357767318,
                "f1": 68.46106138186214,
                "main_score": 69.18964357767318
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 67.0712844653665,
                "f1": 66.75545422473901,
                "main_score": 67.0712844653665
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 74.4754539340955,
                "f1": 74.38427146553252,
                "main_score": 74.4754539340955
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 69.82515131136518,
                "f1": 69.63516462173847,
                "main_score": 69.82515131136518
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 68.70880968392737,
                "f1": 67.45420662567926,
                "main_score": 68.70880968392737
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 65.95494283792871,
                "f1": 65.06191009049222,
                "main_score": 65.95494283792871
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 68.75924680564896,
                "f1": 68.30833379585945,
                "main_score": 68.75924680564896
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 63.806321452589096,
                "f1": 63.273048243765054,
                "main_score": 63.806321452589096
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 67.68997982515133,
                "f1": 66.54703855381324,
                "main_score": 67.68997982515133
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 66.46940147948891,
                "f1": 65.91017343463396,
                "main_score": 66.46940147948891
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 59.49899125756556,
                "f1": 57.90333469917769,
                "main_score": 59.49899125756556
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 67.9219905850706,
                "f1": 67.23169403762938,
                "main_score": 67.9219905850706
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 56.486213853396094,
                "f1": 54.85282355583758,
                "main_score": 56.486213853396094
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 69.04169468728985,
                "f1": 68.83833333320462,
                "main_score": 69.04169468728985
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 73.88702084734365,
                "f1": 74.04474735232299,
                "main_score": 73.88702084734365
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 56.63416274377943,
                "f1": 55.11332211687954,
                "main_score": 56.63416274377943
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 52.23604572965702,
                "f1": 50.86529813991055,
                "main_score": 52.23604572965702
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 46.62407531943511,
                "f1": 43.63485467164535,
                "main_score": 46.62407531943511
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 59.15601882985878,
                "f1": 57.522837510959924,
                "main_score": 59.15601882985878
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 69.84532616005382,
                "f1": 69.60021127179697,
                "main_score": 69.84532616005382
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 56.65770006724949,
                "f1": 55.84219135523227,
                "main_score": 56.65770006724949
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 66.53665097511768,
                "f1": 65.09087787792639,
                "main_score": 66.53665097511768
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 59.31405514458642,
                "f1": 58.06135303831491,
                "main_score": 59.31405514458642
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 64.88231338264964,
                "f1": 62.751099407787926,
                "main_score": 64.88231338264964
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 58.86012104909213,
                "f1": 56.29118323058282,
                "main_score": 58.86012104909213
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 67.37390719569602,
                "f1": 66.27922244885102,
                "main_score": 67.37390719569602
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 70.8675184936113,
                "f1": 70.22146529932019,
                "main_score": 70.8675184936113
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 68.2212508406187,
                "f1": 67.77454802056282,
                "main_score": 68.2212508406187
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 68.18090114324143,
                "f1": 68.03737625431621,
                "main_score": 68.18090114324143
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 64.65030262273034,
                "f1": 63.792945486912856,
                "main_score": 64.65030262273034
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 63.772749631087066,
                "f1": 63.4539101720024,
                "f1_weighted": 62.778603897469566,
                "main_score": 63.772749631087066
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 60.17821116341627,
                "f1": 59.3935969827171,
                "main_score": 60.17821116341627
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 62.86146603900471,
                "f1": 60.133692735032376,
                "main_score": 62.86146603900471
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 70.89441829186282,
                "f1": 70.03064076194089,
                "main_score": 70.89441829186282
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 58.15063887020847,
                "f1": 56.23326278499678,
                "main_score": 58.15063887020847
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 59.43846671149966,
                "f1": 57.70440450281974,
                "main_score": 59.43846671149966
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 60.8507061197041,
                "f1": 59.22916396061171,
                "main_score": 60.8507061197041
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 70.65568258238063,
                "f1": 69.90736239440633,
                "main_score": 70.65568258238063
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 60.8843308675185,
                "f1": 59.30332663713599,
                "main_score": 60.8843308675185
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 68.05312710154674,
                "f1": 67.44024062594775,
                "main_score": 68.05312710154674
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 62.111634162743776,
                "f1": 60.89083013084519,
                "main_score": 62.111634162743776
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 67.44115669132482,
                "f1": 67.92227541674552,
                "main_score": 67.44115669132482
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 74.4687289845326,
                "f1": 74.16376793486025,
                "main_score": 74.4687289845326
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 68.31876260928043,
                "f1": 68.5246745215607,
                "main_score": 68.31876260928043
            }
        ]
    }
}