{
    "dataset_revision": "ed9a4403ed4adbfaf4aab56d5b2709e9f6c3ba33",
    "task_name": "NTREXBitextMining",
    "evaluation_time": -1,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "arb_Arab-rus_Cyrl",
                "languages": [
                    "arb-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 86.47971957936905,
                "f1": 82.79864240805654,
                "main_score": 82.79864240805654,
                "precision": 81.21485800128767,
                "recall": 86.47971957936905
            },
            {
                "hf_subset": "bel_Cyrl-rus_Cyrl",
                "languages": [
                    "bel-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 94.84226339509264,
                "f1": 93.56399067465667,
                "main_score": 93.56399067465667,
                "precision": 93.01619095309631,
                "recall": 94.84226339509264
            },
            {
                "hf_subset": "ben_Beng-rus_Cyrl",
                "languages": [
                    "ben-Beng",
                    "rus-Cyrl"
                ],
                "accuracy": 92.18828242363544,
                "f1": 90.42393889620612,
                "main_score": 90.42393889620612,
                "precision": 89.67904925153297,
                "recall": 92.18828242363544
            },
            {
                "hf_subset": "bos_Latn-rus_Cyrl",
                "languages": [
                    "bos-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 94.69203805708563,
                "f1": 93.37172425304624,
                "main_score": 93.37172425304624,
                "precision": 92.79204521067315,
                "recall": 94.69203805708563
            },
            {
                "hf_subset": "bul_Cyrl-rus_Cyrl",
                "languages": [
                    "bul-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 96.99549323985978,
                "f1": 96.13086296110833,
                "main_score": 96.13086296110833,
                "precision": 95.72441996327827,
                "recall": 96.99549323985978
            },
            {
                "hf_subset": "ces_Latn-rus_Cyrl",
                "languages": [
                    "ces-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 95.94391587381071,
                "f1": 94.90680465142157,
                "main_score": 94.90680465142157,
                "precision": 94.44541812719079,
                "recall": 95.94391587381071
            },
            {
                "hf_subset": "deu_Latn-rus_Cyrl",
                "languages": [
                    "deu-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 96.09414121181773,
                "f1": 94.94408279085295,
                "main_score": 94.94408279085295,
                "precision": 94.41245201135037,
                "recall": 96.09414121181773
            },
            {
                "hf_subset": "ell_Grek-rus_Cyrl",
                "languages": [
                    "ell-Grek",
                    "rus-Cyrl"
                ],
                "accuracy": 96.19429143715573,
                "f1": 95.12101485561676,
                "main_score": 95.12101485561676,
                "precision": 94.60440660991488,
                "recall": 96.19429143715573
            },
            {
                "hf_subset": "eng_Latn-rus_Cyrl",
                "languages": [
                    "eng-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 96.49474211316975,
                "f1": 95.46581777428045,
                "main_score": 95.46581777428045,
                "precision": 94.98414288098814,
                "recall": 96.49474211316975
            },
            {
                "hf_subset": "fas_Arab-rus_Cyrl",
                "languages": [
                    "fas-Arab",
                    "rus-Cyrl"
                ],
                "accuracy": 94.44166249374061,
                "f1": 92.92383018972905,
                "main_score": 92.92383018972905,
                "precision": 92.21957936905358,
                "recall": 94.44166249374061
            },
            {
                "hf_subset": "fin_Latn-rus_Cyrl",
                "languages": [
                    "fin-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 92.18828242363544,
                "f1": 90.2980661468393,
                "main_score": 90.2980661468393,
                "precision": 89.42580537472877,
                "recall": 92.18828242363544
            },
            {
                "hf_subset": "fra_Latn-rus_Cyrl",
                "languages": [
                    "fra-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 95.84376564847271,
                "f1": 94.81054915706895,
                "main_score": 94.81054915706895,
                "precision": 94.31369276136427,
                "recall": 95.84376564847271
            },
            {
                "hf_subset": "heb_Hebr-rus_Cyrl",
                "languages": [
                    "heb-Hebr",
                    "rus-Cyrl"
                ],
                "accuracy": 94.89233850776164,
                "f1": 93.42513770655985,
                "main_score": 93.42513770655985,
                "precision": 92.73493573693875,
                "recall": 94.89233850776164
            },
            {
                "hf_subset": "hin_Deva-rus_Cyrl",
                "languages": [
                    "hin-Deva",
                    "rus-Cyrl"
                ],
                "accuracy": 93.23985978968453,
                "f1": 91.52816526376867,
                "main_score": 91.52816526376867,
                "precision": 90.76745946425466,
                "recall": 93.23985978968453
            },
            {
                "hf_subset": "hrv_Latn-rus_Cyrl",
                "languages": [
                    "hrv-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 93.99098647971958,
                "f1": 92.36354531797697,
                "main_score": 92.36354531797697,
                "precision": 91.63228970439788,
                "recall": 93.99098647971958
            },
            {
                "hf_subset": "hun_Latn-rus_Cyrl",
                "languages": [
                    "hun-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 93.64046069103655,
                "f1": 92.05224503421799,
                "main_score": 92.05224503421799,
                "precision": 91.33998616973079,
                "recall": 93.64046069103655
            },
            {
                "hf_subset": "ind_Latn-rus_Cyrl",
                "languages": [
                    "ind-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 91.68753129694541,
                "f1": 89.26222667334335,
                "main_score": 89.26222667334335,
                "precision": 88.14638624603572,
                "recall": 91.68753129694541
            },
            {
                "hf_subset": "jpn_Jpan-rus_Cyrl",
                "languages": [
                    "jpn-Jpan",
                    "rus-Cyrl"
                ],
                "accuracy": 91.28693039559339,
                "f1": 89.21161763348957,
                "main_score": 89.21161763348957,
                "precision": 88.31188340952988,
                "recall": 91.28693039559339
            },
            {
                "hf_subset": "kor_Hang-rus_Cyrl",
                "languages": [
                    "kor-Hang",
                    "rus-Cyrl"
                ],
                "accuracy": 89.53430145217827,
                "f1": 86.88322165788365,
                "main_score": 86.88322165788365,
                "precision": 85.73950211030831,
                "recall": 89.53430145217827
            },
            {
                "hf_subset": "lit_Latn-rus_Cyrl",
                "languages": [
                    "lit-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 90.28542814221332,
                "f1": 88.10249103814452,
                "main_score": 88.10249103814452,
                "precision": 87.17689323973752,
                "recall": 90.28542814221332
            },
            {
                "hf_subset": "mkd_Cyrl-rus_Cyrl",
                "languages": [
                    "mkd-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 95.04256384576865,
                "f1": 93.65643703650713,
                "main_score": 93.65643703650713,
                "precision": 93.02036387915207,
                "recall": 95.04256384576865
            },
            {
                "hf_subset": "nld_Latn-rus_Cyrl",
                "languages": [
                    "nld-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 95.39308963445168,
                "f1": 94.16207644800535,
                "main_score": 94.16207644800535,
                "precision": 93.582516632091,
                "recall": 95.39308963445168
            },
            {
                "hf_subset": "pol_Latn-rus_Cyrl",
                "languages": [
                    "pol-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 95.7436154231347,
                "f1": 94.5067601402103,
                "main_score": 94.5067601402103,
                "precision": 93.91587381071608,
                "recall": 95.7436154231347
            },
            {
                "hf_subset": "por_Latn-rus_Cyrl",
                "languages": [
                    "por-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 65.89884827240861,
                "f1": 64.61805459419219,
                "main_score": 64.61805459419219,
                "precision": 64.07119451106485,
                "recall": 65.89884827240861
            },
            {
                "hf_subset": "rus_Cyrl-arb_Arab",
                "languages": [
                    "rus-Cyrl",
                    "arb-Arab"
                ],
                "accuracy": 94.2413620430646,
                "f1": 92.67663399861698,
                "main_score": 92.67663399861698,
                "precision": 91.94625271240193,
                "recall": 94.2413620430646
            },
            {
                "hf_subset": "rus_Cyrl-bel_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "bel-Cyrl"
                ],
                "accuracy": 94.89233850776164,
                "f1": 93.40343849106993,
                "main_score": 93.40343849106993,
                "precision": 92.74077783341679,
                "recall": 94.89233850776164
            },
            {
                "hf_subset": "rus_Cyrl-ben_Beng",
                "languages": [
                    "rus-Cyrl",
                    "ben-Beng"
                ],
                "accuracy": 94.2914371557336,
                "f1": 92.62226673343348,
                "main_score": 92.62226673343348,
                "precision": 91.84610248706393,
                "recall": 94.2914371557336
            },
            {
                "hf_subset": "rus_Cyrl-bos_Latn",
                "languages": [
                    "rus-Cyrl",
                    "bos-Latn"
                ],
                "accuracy": 95.69354031046569,
                "f1": 94.50418051319403,
                "main_score": 94.50418051319403,
                "precision": 93.95843765648473,
                "recall": 95.69354031046569
            },
            {
                "hf_subset": "rus_Cyrl-bul_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "bul-Cyrl"
                ],
                "accuracy": 95.89384076114172,
                "f1": 94.66199298948423,
                "main_score": 94.66199298948423,
                "precision": 94.08028709731263,
                "recall": 95.89384076114172
            },
            {
                "hf_subset": "rus_Cyrl-ces_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ces-Latn"
                ],
                "accuracy": 93.94091136705057,
                "f1": 92.3746731207923,
                "main_score": 92.3746731207923,
                "precision": 91.66207644800535,
                "recall": 93.94091136705057
            },
            {
                "hf_subset": "rus_Cyrl-deu_Latn",
                "languages": [
                    "rus-Cyrl",
                    "deu-Latn"
                ],
                "accuracy": 95.94391587381071,
                "f1": 94.76214321482223,
                "main_score": 94.76214321482223,
                "precision": 94.20380570856285,
                "recall": 95.94391587381071
            },
            {
                "hf_subset": "rus_Cyrl-ell_Grek",
                "languages": [
                    "rus-Cyrl",
                    "ell-Grek"
                ],
                "accuracy": 95.44316474712068,
                "f1": 94.14788849941579,
                "main_score": 94.14788849941579,
                "precision": 93.54197963612084,
                "recall": 95.44316474712068
            },
            {
                "hf_subset": "rus_Cyrl-eng_Latn",
                "languages": [
                    "rus-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 98.14722083124687,
                "f1": 97.57135703555333,
                "main_score": 97.57135703555333,
                "precision": 97.2959439158738,
                "recall": 98.14722083124687
            },
            {
                "hf_subset": "rus_Cyrl-fas_Arab",
                "languages": [
                    "rus-Cyrl",
                    "fas-Arab"
                ],
                "accuracy": 94.64196294441662,
                "f1": 93.24653647137372,
                "main_score": 93.24653647137372,
                "precision": 92.60724419963279,
                "recall": 94.64196294441662
            },
            {
                "hf_subset": "rus_Cyrl-fin_Latn",
                "languages": [
                    "rus-Cyrl",
                    "fin-Latn"
                ],
                "accuracy": 87.98197295943916,
                "f1": 85.23368385912201,
                "main_score": 85.23368385912201,
                "precision": 84.08159858835873,
                "recall": 87.98197295943916
            },
            {
                "hf_subset": "rus_Cyrl-fra_Latn",
                "languages": [
                    "rus-Cyrl",
                    "fra-Latn"
                ],
                "accuracy": 96.24436654982473,
                "f1": 95.07093974294774,
                "main_score": 95.07093974294774,
                "precision": 94.49591053246536,
                "recall": 96.24436654982473
            },
            {
                "hf_subset": "rus_Cyrl-heb_Hebr",
                "languages": [
                    "rus-Cyrl",
                    "heb-Hebr"
                ],
                "accuracy": 91.08662994491738,
                "f1": 88.5161074945752,
                "main_score": 88.5161074945752,
                "precision": 87.36187614755467,
                "recall": 91.08662994491738
            },
            {
                "hf_subset": "rus_Cyrl-hin_Deva",
                "languages": [
                    "rus-Cyrl",
                    "hin-Deva"
                ],
                "accuracy": 95.04256384576865,
                "f1": 93.66382907694876,
                "main_score": 93.66382907694876,
                "precision": 93.05291270238692,
                "recall": 95.04256384576865
            },
            {
                "hf_subset": "rus_Cyrl-hrv_Latn",
                "languages": [
                    "rus-Cyrl",
                    "hrv-Latn"
                ],
                "accuracy": 95.14271407110667,
                "f1": 93.7481221832749,
                "main_score": 93.7481221832749,
                "precision": 93.10930681736892,
                "recall": 95.14271407110667
            },
            {
                "hf_subset": "rus_Cyrl-hun_Latn",
                "languages": [
                    "rus-Cyrl",
                    "hun-Latn"
                ],
                "accuracy": 90.18527791687532,
                "f1": 87.61415933423946,
                "main_score": 87.61415933423946,
                "precision": 86.5166400394242,
                "recall": 90.18527791687532
            },
            {
                "hf_subset": "rus_Cyrl-ind_Latn",
                "languages": [
                    "rus-Cyrl",
                    "ind-Latn"
                ],
                "accuracy": 93.69053580370556,
                "f1": 91.83608746453012,
                "main_score": 91.83608746453012,
                "precision": 90.97145718577868,
                "recall": 93.69053580370556
            },
            {
                "hf_subset": "rus_Cyrl-jpn_Jpan",
                "languages": [
                    "rus-Cyrl",
                    "jpn-Jpan"
                ],
                "accuracy": 89.48422633950926,
                "f1": 86.91271033534429,
                "main_score": 86.91271033534429,
                "precision": 85.82671626487351,
                "recall": 89.48422633950926
            },
            {
                "hf_subset": "rus_Cyrl-kor_Hang",
                "languages": [
                    "rus-Cyrl",
                    "kor-Hang"
                ],
                "accuracy": 88.4827240861292,
                "f1": 85.35080398375342,
                "main_score": 85.35080398375342,
                "precision": 83.9588549490903,
                "recall": 88.4827240861292
            },
            {
                "hf_subset": "rus_Cyrl-lit_Latn",
                "languages": [
                    "rus-Cyrl",
                    "lit-Latn"
                ],
                "accuracy": 90.33550325488233,
                "f1": 87.68831819157307,
                "main_score": 87.68831819157307,
                "precision": 86.51524906407231,
                "recall": 90.33550325488233
            },
            {
                "hf_subset": "rus_Cyrl-mkd_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "mkd-Cyrl"
                ],
                "accuracy": 95.94391587381071,
                "f1": 94.90402270071775,
                "main_score": 94.90402270071775,
                "precision": 94.43915873810715,
                "recall": 95.94391587381071
            },
            {
                "hf_subset": "rus_Cyrl-nld_Latn",
                "languages": [
                    "rus-Cyrl",
                    "nld-Latn"
                ],
                "accuracy": 92.98948422633951,
                "f1": 91.04323151393756,
                "main_score": 91.04323151393756,
                "precision": 90.14688699716241,
                "recall": 92.98948422633951
            },
            {
                "hf_subset": "rus_Cyrl-pol_Latn",
                "languages": [
                    "rus-Cyrl",
                    "pol-Latn"
                ],
                "accuracy": 94.34151226840261,
                "f1": 92.8726422967785,
                "main_score": 92.8726422967785,
                "precision": 92.19829744616925,
                "recall": 94.34151226840261
            },
            {
                "hf_subset": "rus_Cyrl-por_Latn",
                "languages": [
                    "rus-Cyrl",
                    "por-Latn"
                ],
                "accuracy": 86.17926890335504,
                "f1": 82.7304882287356,
                "main_score": 82.7304882287356,
                "precision": 81.28162481817964,
                "recall": 86.17926890335504
            },
            {
                "hf_subset": "rus_Cyrl-slk_Latn",
                "languages": [
                    "rus-Cyrl",
                    "slk-Latn"
                ],
                "accuracy": 92.7391086629945,
                "f1": 90.75112669003506,
                "main_score": 90.75112669003506,
                "precision": 89.8564513436822,
                "recall": 92.7391086629945
            },
            {
                "hf_subset": "rus_Cyrl-slv_Latn",
                "languages": [
                    "rus-Cyrl",
                    "slv-Latn"
                ],
                "accuracy": 92.8893340010015,
                "f1": 91.05992321816058,
                "main_score": 91.05992321816058,
                "precision": 90.22589439715128,
                "recall": 92.8893340010015
            },
            {
                "hf_subset": "rus_Cyrl-spa_Latn",
                "languages": [
                    "rus-Cyrl",
                    "spa-Latn"
                ],
                "accuracy": 96.49474211316975,
                "f1": 95.4715406442998,
                "main_score": 95.4715406442998,
                "precision": 94.9799699549324,
                "recall": 96.49474211316975
            },
            {
                "hf_subset": "rus_Cyrl-srp_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "srp-Cyrl"
                ],
                "accuracy": 81.07160741111667,
                "f1": 76.55687285507015,
                "main_score": 76.55687285507015,
                "precision": 74.71886401030116,
                "recall": 81.07160741111667
            },
            {
                "hf_subset": "rus_Cyrl-srp_Latn",
                "languages": [
                    "rus-Cyrl",
                    "srp-Latn"
                ],
                "accuracy": 95.14271407110667,
                "f1": 93.73302377809138,
                "main_score": 93.73302377809138,
                "precision": 93.06960440660991,
                "recall": 95.14271407110667
            },
            {
                "hf_subset": "rus_Cyrl-swa_Latn",
                "languages": [
                    "rus-Cyrl",
                    "swa-Latn"
                ],
                "accuracy": 94.79218828242364,
                "f1": 93.25988983475212,
                "main_score": 93.25988983475212,
                "precision": 92.53463528626273,
                "recall": 94.79218828242364
            },
            {
                "hf_subset": "rus_Cyrl-swe_Latn",
                "languages": [
                    "rus-Cyrl",
                    "swe-Latn"
                ],
                "accuracy": 95.04256384576865,
                "f1": 93.58704723752295,
                "main_score": 93.58704723752295,
                "precision": 92.91437155733601,
                "recall": 95.04256384576865
            },
            {
                "hf_subset": "rus_Cyrl-tam_Taml",
                "languages": [
                    "rus-Cyrl",
                    "tam-Taml"
                ],
                "accuracy": 93.28993490235354,
                "f1": 91.63912535469872,
                "main_score": 91.63912535469872,
                "precision": 90.87738750983617,
                "recall": 93.28993490235354
            },
            {
                "hf_subset": "rus_Cyrl-tur_Latn",
                "languages": [
                    "rus-Cyrl",
                    "tur-Latn"
                ],
                "accuracy": 93.74061091637456,
                "f1": 91.96628275746953,
                "main_score": 91.96628275746953,
                "precision": 91.15923885828742,
                "recall": 93.74061091637456
            },
            {
                "hf_subset": "rus_Cyrl-ukr_Cyrl",
                "languages": [
                    "rus-Cyrl",
                    "ukr-Cyrl"
                ],
                "accuracy": 95.99399098647972,
                "f1": 94.89567684860624,
                "main_score": 94.89567684860624,
                "precision": 94.37072275079286,
                "recall": 95.99399098647972
            },
            {
                "hf_subset": "rus_Cyrl-vie_Latn",
                "languages": [
                    "rus-Cyrl",
                    "vie-Latn"
                ],
                "accuracy": 91.4371557336004,
                "f1": 88.98681355366382,
                "main_score": 88.98681355366382,
                "precision": 87.89183775663496,
                "recall": 91.4371557336004
            },
            {
                "hf_subset": "rus_Cyrl-zho_Hant",
                "languages": [
                    "rus-Cyrl",
                    "zho-Hant"
                ],
                "accuracy": 92.7891837756635,
                "f1": 90.79047142141783,
                "main_score": 90.79047142141783,
                "precision": 89.86980470706058,
                "recall": 92.7891837756635
            },
            {
                "hf_subset": "rus_Cyrl-zul_Latn",
                "languages": [
                    "rus-Cyrl",
                    "zul-Latn"
                ],
                "accuracy": 87.43114672008012,
                "f1": 84.04618833011422,
                "main_score": 84.04618833011422,
                "precision": 82.52259341393041,
                "recall": 87.43114672008012
            },
            {
                "hf_subset": "slk_Latn-rus_Cyrl",
                "languages": [
                    "slk-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 95.34301452178268,
                "f1": 94.20392493502158,
                "main_score": 94.20392493502158,
                "precision": 93.67384409948257,
                "recall": 95.34301452178268
            },
            {
                "hf_subset": "slv_Latn-rus_Cyrl",
                "languages": [
                    "slv-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 92.23835753630446,
                "f1": 90.5061759305625,
                "main_score": 90.5061759305625,
                "precision": 89.74231188051918,
                "recall": 92.23835753630446
            },
            {
                "hf_subset": "spa_Latn-rus_Cyrl",
                "languages": [
                    "spa-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 96.54481722583876,
                "f1": 95.54665331330328,
                "main_score": 95.54665331330328,
                "precision": 95.06342847604739,
                "recall": 96.54481722583876
            },
            {
                "hf_subset": "srp_Cyrl-rus_Cyrl",
                "languages": [
                    "srp-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 83.62543815723585,
                "f1": 80.77095672699816,
                "main_score": 80.77095672699816,
                "precision": 79.74674313056886,
                "recall": 83.62543815723585
            },
            {
                "hf_subset": "srp_Latn-rus_Cyrl",
                "languages": [
                    "srp-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 94.44166249374061,
                "f1": 93.00733206591994,
                "main_score": 93.00733206591994,
                "precision": 92.37203026762366,
                "recall": 94.44166249374061
            },
            {
                "hf_subset": "swa_Latn-rus_Cyrl",
                "languages": [
                    "swa-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 90.23535302954431,
                "f1": 87.89596482636041,
                "main_score": 87.89596482636041,
                "precision": 86.87060227370694,
                "recall": 90.23535302954431
            },
            {
                "hf_subset": "swe_Latn-rus_Cyrl",
                "languages": [
                    "swe-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 95.44316474712068,
                "f1": 94.1896177599733,
                "main_score": 94.1896177599733,
                "precision": 93.61542313470206,
                "recall": 95.44316474712068
            },
            {
                "hf_subset": "tam_Taml-rus_Cyrl",
                "languages": [
                    "tam-Taml",
                    "rus-Cyrl"
                ],
                "accuracy": 89.68452679018529,
                "f1": 87.37341160650037,
                "main_score": 87.37341160650037,
                "precision": 86.38389402285247,
                "recall": 89.68452679018529
            },
            {
                "hf_subset": "tur_Latn-rus_Cyrl",
                "languages": [
                    "tur-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 93.89083625438157,
                "f1": 92.33892505424804,
                "main_score": 92.33892505424804,
                "precision": 91.63125640842216,
                "recall": 93.89083625438157
            },
            {
                "hf_subset": "ukr_Cyrl-rus_Cyrl",
                "languages": [
                    "ukr-Cyrl",
                    "rus-Cyrl"
                ],
                "accuracy": 96.14421632448673,
                "f1": 95.11028447433054,
                "main_score": 95.11028447433054,
                "precision": 94.62944416624937,
                "recall": 96.14421632448673
            },
            {
                "hf_subset": "vie_Latn-rus_Cyrl",
                "languages": [
                    "vie-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 93.79068602904357,
                "f1": 92.14989150392256,
                "main_score": 92.14989150392256,
                "precision": 91.39292271740945,
                "recall": 93.79068602904357
            },
            {
                "hf_subset": "zho_Hant-rus_Cyrl",
                "languages": [
                    "zho-Hant",
                    "rus-Cyrl"
                ],
                "accuracy": 89.13370055082625,
                "f1": 86.51514618639217,
                "main_score": 86.51514618639217,
                "precision": 85.383920035898,
                "recall": 89.13370055082625
            },
            {
                "hf_subset": "zul_Latn-rus_Cyrl",
                "languages": [
                    "zul-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 81.17175763645467,
                "f1": 77.72331766047338,
                "main_score": 77.72331766047338,
                "precision": 76.24629555848075,
                "recall": 81.17175763645467
            }
        ]
    }
}