{
    "dataset_revision": "6205996560df11e3a3da9ab4f926788fc30a7db4",
    "task_name": "QuoraRetrieval",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "map_at_1": 61.697,
                "map_at_10": 74.20400000000001,
                "map_at_100": 75.023,
                "map_at_1000": 75.059,
                "map_at_3": 71.265,
                "map_at_5": 73.001,
                "ndcg_at_1": 70.95,
                "ndcg_at_10": 78.96,
                "ndcg_at_100": 81.26,
                "ndcg_at_1000": 81.679,
                "ndcg_at_3": 75.246,
                "ndcg_at_5": 77.092,
                "precision_at_1": 70.95,
                "precision_at_10": 11.998000000000001,
                "precision_at_100": 1.451,
                "precision_at_1000": 0.154,
                "precision_at_3": 32.629999999999995,
                "precision_at_5": 21.573999999999998,
                "recall_at_1": 61.697,
                "recall_at_10": 88.23299999999999,
                "recall_at_100": 96.961,
                "recall_at_1000": 99.401,
                "recall_at_3": 77.689,
                "recall_at_5": 82.745,
                "main_score": 78.96
            }
        ]
    }
}