{
    "dataset_revision": "7d571f92784cd94a019292a1f45445077d0ef634",
    "task_name": "MassiveScenarioClassification",
    "evaluation_time": NaN,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 40.24546065904506,
                "f1": 38.79924050989544,
                "main_score": 40.24546065904506
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 25.68930733019502,
                "f1": 25.488166279162712,
                "main_score": 25.68930733019502
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 32.39744451916611,
                "f1": 31.863029579075775,
                "main_score": 32.39744451916611
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 40.53127101546738,
                "f1": 39.707079033948936,
                "main_score": 40.53127101546738
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 27.23268325487559,
                "f1": 26.443653281858793,
                "main_score": 27.23268325487559
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 38.69872225958305,
                "f1": 36.55930387892567,
                "main_score": 38.69872225958305
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 44.75453934095494,
                "f1": 42.87356484024154,
                "main_score": 44.75453934095494
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 41.355077336919976,
                "f1": 39.82365179458047,
                "main_score": 41.355077336919976
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 38.43981170141224,
                "f1": 37.02538368296387,
                "main_score": 38.43981170141224
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 66.33826496301278,
                "f1": 65.89634765029932,
                "main_score": 66.33826496301278
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 44.17955615332885,
                "f1": 43.10228811620319,
                "main_score": 44.17955615332885
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 34.82851378614661,
                "f1": 33.95952441502803,
                "main_score": 34.82851378614661
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 40.561533288500335,
                "f1": 38.04939011733627,
                "main_score": 40.561533288500335
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 45.917955615332886,
                "f1": 44.65741971572902,
                "main_score": 45.917955615332886
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 32.08473436449227,
                "f1": 29.53932929808133,
                "main_score": 32.08473436449227
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 28.369199731002016,
                "f1": 27.52902837981212,
                "main_score": 28.369199731002016
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 39.49226630800269,
                "f1": 37.3272340470504,
                "main_score": 39.49226630800269
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 25.904505716207133,
                "f1": 24.547396574853444,
                "main_score": 25.904505716207133
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 40.95830531271016,
                "f1": 40.177843177422226,
                "main_score": 40.95830531271016
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 38.564223268325485,
                "f1": 37.35307758495248,
                "main_score": 38.564223268325485
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 46.58708809683928,
                "f1": 44.103900526804985,
                "main_score": 46.58708809683928
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 46.24747814391393,
                "f1": 45.4107101796664,
                "main_score": 46.24747814391393
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 39.6570275722932,
                "f1": 38.82737576832412,
                "main_score": 39.6570275722932
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 25.279085406859448,
                "f1": 23.662661686788493,
                "main_score": 25.279085406859448
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 28.97108271687962,
                "f1": 27.195758324189246,
                "main_score": 28.97108271687962
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 19.27370544720915,
                "f1": 18.694271924323637,
                "main_score": 19.27370544720915
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 35.729657027572294,
                "f1": 34.38287006177308,
                "main_score": 35.729657027572294
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 39.57296570275723,
                "f1": 38.074945140886925,
                "main_score": 39.57296570275723
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 19.895763281775388,
                "f1": 20.00931364846829,
                "main_score": 19.895763281775388
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 32.431069266980494,
                "f1": 31.395958664782576,
                "main_score": 32.431069266980494
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 42.32347007397445,
                "f1": 40.81374026314701,
                "main_score": 42.32347007397445
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 20.864156018829856,
                "f1": 20.409870408935436,
                "main_score": 20.864156018829856
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 40.47074646940148,
                "f1": 39.19044149415904,
                "main_score": 40.47074646940148
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 43.591123066577,
                "f1": 41.43420363064241,
                "main_score": 43.591123066577
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 41.876260928043045,
                "f1": 41.192117676667614,
                "main_score": 41.876260928043045
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 46.30800268997983,
                "f1": 45.25536730126799,
                "main_score": 46.30800268997983
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 42.525218560860786,
                "f1": 41.02418109296485,
                "main_score": 42.525218560860786
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 35.94821788836584,
                "f1": 35.08598314806566,
                "main_score": 35.94821788836584
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 38.69199731002017,
                "f1": 37.68119408674127,
                "main_score": 38.69199731002017
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 40.474108944182916,
                "f1": 39.480530387013594,
                "main_score": 40.474108944182916
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 41.523201075991935,
                "f1": 40.20097996024383,
                "main_score": 41.523201075991935
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 39.54942837928716,
                "f1": 38.185561243338064,
                "main_score": 39.54942837928716
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 22.8782784129119,
                "f1": 22.239467186721456,
                "main_score": 22.8782784129119
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 20.51445864156019,
                "f1": 19.999047885530217,
                "main_score": 20.51445864156019
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 34.92602555480834,
                "f1": 33.24016717215723,
                "main_score": 34.92602555480834
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 40.74983187626093,
                "f1": 39.30274328728882,
                "main_score": 40.74983187626093
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 39.06859448554136,
                "f1": 39.21542039662971,
                "main_score": 39.06859448554136
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 29.747814391392062,
                "f1": 28.261836892220447,
                "main_score": 29.747814391392062
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 38.02286482851379,
                "f1": 37.8742438608697,
                "main_score": 38.02286482851379
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 48.550773369199725,
                "f1": 46.7399625882649,
                "main_score": 48.550773369199725
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 45.17821116341628,
                "f1": 44.84809741811729,
                "main_score": 45.17821116341628
            }
        ]
    }
}