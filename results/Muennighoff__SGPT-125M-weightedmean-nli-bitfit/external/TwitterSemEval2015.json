{
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
    "task_name": "TwitterSemEval2015",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "cos_sim_accuracy": 81.5640460153782,
                "cos_sim_ap": 57.094095366921536,
                "cos_sim_f1": 55.29607083563918,
                "cos_sim_precision": 47.62631077216397,
                "cos_sim_recall": 65.91029023746702,
                "dot_accuracy": 78.81623651427549,
                "dot_ap": 47.42989400382077,
                "dot_f1": 51.25944584382871,
                "dot_precision": 42.55838271174625,
                "dot_recall": 64.43271767810026,
                "euclidean_accuracy": 80.29445073612685,
                "euclidean_ap": 53.42012231336148,
                "euclidean_f1": 51.867783563504645,
                "euclidean_precision": 45.4203013481364,
                "euclidean_recall": 60.4485488126649,
                "manhattan_accuracy": 80.2884901949097,
                "manhattan_ap": 53.43205271323232,
                "manhattan_f1": 52.014165559982295,
                "manhattan_precision": 44.796035074342356,
                "manhattan_recall": 62.00527704485488,
                "max_accuracy": 81.5640460153782,
                "max_ap": 57.094095366921536,
                "max_f1": 55.29607083563918,
                "main_score": 57.094095366921536
            }
        ]
    }
}