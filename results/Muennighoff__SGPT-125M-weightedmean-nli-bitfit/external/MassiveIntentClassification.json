{
    "dataset_revision": "072a486a144adf7f4479a4a0dddb2152e161e1ea",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 37.79421654337593,
                "f1": 36.81580701507746,
                "main_score": 37.79421654337593
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 23.722259583053127,
                "f1": 23.235269695764273,
                "main_score": 23.722259583053127
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 29.64021519838601,
                "f1": 28.273175327650137,
                "main_score": 29.64021519838601
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 39.4754539340955,
                "f1": 39.25997361415121,
                "main_score": 39.4754539340955
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 26.550100874243444,
                "f1": 25.607924873522975,
                "main_score": 26.550100874243444
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 38.78278412911904,
                "f1": 37.64180582626517,
                "main_score": 38.78278412911904
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 43.557498318762605,
                "f1": 41.35305173800667,
                "main_score": 43.557498318762605
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 40.39340954942838,
                "f1": 38.33393219528934,
                "main_score": 40.39340954942838
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 37.28648285137861,
                "f1": 36.64005906680284,
                "main_score": 37.28648285137861
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 58.080026899798256,
                "f1": 56.49243881660991,
                "main_score": 58.080026899798256
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 41.176866173503704,
                "f1": 40.66779962225799,
                "main_score": 41.176866173503704
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 36.422326832548755,
                "f1": 34.6441738042885,
                "main_score": 36.422326832548755
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 38.75588433086752,
                "f1": 37.26725894668694,
                "main_score": 38.75588433086752
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 43.67182246133153,
                "f1": 42.351846624566605,
                "main_score": 43.67182246133153
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 31.980497646267658,
                "f1": 30.557928872809008,
                "main_score": 31.980497646267658
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 28.039677202420982,
                "f1": 28.428418145508306,
                "main_score": 28.039677202420982
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 38.13718897108272,
                "f1": 37.057406988196874,
                "main_score": 38.13718897108272
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 26.05245460659045,
                "f1": 25.25483953344816,
                "main_score": 26.05245460659045
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 41.156691324815064,
                "f1": 40.83715033247605,
                "main_score": 41.156691324815064
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 38.62811028917284,
                "f1": 37.67691901246032,
                "main_score": 38.62811028917284
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 44.0383322125084,
                "f1": 43.77259010877456,
                "main_score": 44.0383322125084
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 46.20712844653666,
                "f1": 44.66632875940824,
                "main_score": 46.20712844653666
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 37.60591795561533,
                "f1": 36.581071742378015,
                "main_score": 37.60591795561533
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 24.47209145931405,
                "f1": 24.238209697895606,
                "main_score": 24.47209145931405
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 26.23739071956961,
                "f1": 25.378783150845052,
                "main_score": 26.23739071956961
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 17.831203765971754,
                "f1": 17.275078420466343,
                "main_score": 17.831203765971754
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 37.266308002689975,
                "f1": 36.92473791708214,
                "main_score": 37.266308002689975
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 40.93140551445864,
                "f1": 40.825227889641965,
                "main_score": 40.93140551445864
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 17.88500336247478,
                "f1": 17.621569082971817,
                "main_score": 17.88500336247478
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 32.975790181573636,
                "f1": 33.402014633349665,
                "main_score": 32.975790181573636
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 40.91123066577001,
                "f1": 40.09538559124075,
                "main_score": 40.91123066577001
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 17.834566240753194,
                "f1": 17.006381849454314,
                "main_score": 17.834566240753194
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 39.47881640887693,
                "f1": 37.819934317839305,
                "main_score": 39.47881640887693
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 41.76193678547412,
                "f1": 40.281991759509694,
                "main_score": 41.76193678547412
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 42.61936785474109,
                "f1": 40.83673914649905,
                "main_score": 42.61936785474109
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 44.54270342972427,
                "f1": 43.45243164278448,
                "main_score": 44.54270342972427
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 39.96973772696705,
                "f1": 38.74209466530094,
                "main_score": 39.96973772696705
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 37.461331540013454,
                "f1": 36.91132021821187,
                "main_score": 37.461331540013454
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 38.28850033624748,
                "f1": 37.37259394049676,
                "main_score": 38.28850033624748
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 40.95494283792872,
                "f1": 39.767707902869084,
                "main_score": 40.95494283792872
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 41.85272360457296,
                "f1": 40.42848260365438,
                "main_score": 41.85272360457296
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 38.328850033624754,
                "f1": 36.90334596675622,
                "main_score": 38.328850033624754
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 19.031607262945528,
                "f1": 18.66510306325761,
                "main_score": 19.031607262945528
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 19.38466711499664,
                "f1": 19.186399376652535,
                "main_score": 19.38466711499664
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 34.088769334229994,
                "f1": 34.20383086009429,
                "main_score": 34.088769334229994
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 40.285810356422324,
                "f1": 39.361500249640414,
                "main_score": 40.285810356422324
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 38.860121049092136,
                "f1": 37.81916859627235,
                "main_score": 38.860121049092136
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 27.834566240753194,
                "f1": 26.898389386106487,
                "main_score": 27.834566240753194
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 38.70544720914593,
                "f1": 38.280026442024415,
                "main_score": 38.70544720914593
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 45.78009414929387,
                "f1": 44.21526778674136,
                "main_score": 45.78009414929387
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 42.32010759919301,
                "f1": 42.25772977490916,
                "main_score": 42.32010759919301
            }
        ]
    }
}