{
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
    "task_name": "TwitterSemEval2015",
    "evaluation_time": -1,
    "mteb_version": "0.0.0",
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "cos_sim_accuracy": 84.19860523335518,
                "cos_sim_ap": 67.98183780223552,
                "cos_sim_f1": 63.287574797606474,
                "cos_sim_precision": 56.98288611874076,
                "cos_sim_recall": 71.16094986807387,
                "dot_accuracy": 81.0872027180068,
                "dot_ap": 57.080616165589994,
                "dot_f1": 57.184056030487184,
                "dot_precision": 46.899814157796925,
                "dot_recall": 73.24538258575198,
                "euclidean_accuracy": 84.10919711509806,
                "euclidean_ap": 68.02422564958268,
                "euclidean_f1": 63.76539589442815,
                "euclidean_precision": 57.40232312565998,
                "euclidean_recall": 71.71503957783642,
                "manhattan_accuracy": 84.06747332657805,
                "manhattan_ap": 67.74186393843273,
                "manhattan_f1": 63.57935359382538,
                "manhattan_precision": 58.55175477565526,
                "manhattan_recall": 69.55145118733509,
                "max_accuracy": 84.19860523335518,
                "max_ap": 68.02422564958268,
                "max_f1": 63.76539589442815,
                "main_score": 68.02422564958268
            }
        ]
    }
}