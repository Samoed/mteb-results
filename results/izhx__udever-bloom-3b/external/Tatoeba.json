{
    "dataset_revision": "9080400076fbadbb4c4dcb136ff4eddc40b42553",
    "task_name": "Tatoeba",
    "evaluation_time": NaN,
    "mteb_version": "unknown",
    "scores": {
        "test": [
            {
                "hf_subset": "sqi-eng",
                "languages": [
                    "sqi-Latn",
                    "eng-Latn"
                ],
                "accuracy": 16.8,
                "f1": 13.168299935527422,
                "precision": 12.209559281760876,
                "recall": 16.8,
                "main_score": 13.168299935527422
            },
            {
                "hf_subset": "fry-eng",
                "languages": [
                    "fry-Latn",
                    "eng-Latn"
                ],
                "accuracy": 35.83815028901734,
                "f1": 29.0852500101055,
                "precision": 26.965317919075147,
                "recall": 35.83815028901734,
                "main_score": 29.0852500101055
            },
            {
                "hf_subset": "kur-eng",
                "languages": [
                    "kur-Latn",
                    "eng-Latn"
                ],
                "accuracy": 15.121951219512194,
                "f1": 11.844149203614325,
                "precision": 11.042929292929294,
                "recall": 15.121951219512194,
                "main_score": 11.844149203614325
            },
            {
                "hf_subset": "tur-eng",
                "languages": [
                    "tur-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.9,
                "f1": 7.1396348187007215,
                "precision": 6.501835713997978,
                "recall": 9.9,
                "main_score": 7.1396348187007215
            },
            {
                "hf_subset": "deu-eng",
                "languages": [
                    "deu-Latn",
                    "eng-Latn"
                ],
                "accuracy": 76.6,
                "f1": 72.73241758241758,
                "precision": 71.18867647058823,
                "recall": 76.6,
                "main_score": 72.73241758241758
            },
            {
                "hf_subset": "nld-eng",
                "languages": [
                    "nld-Latn",
                    "eng-Latn"
                ],
                "accuracy": 42.0,
                "f1": 36.81003102453103,
                "precision": 35.19870269535562,
                "recall": 42.0,
                "main_score": 36.81003102453103
            },
            {
                "hf_subset": "ron-eng",
                "languages": [
                    "ron-Latn",
                    "eng-Latn"
                ],
                "accuracy": 35.3,
                "f1": 30.353777056277053,
                "precision": 28.773956778515604,
                "recall": 35.3,
                "main_score": 30.353777056277053
            },
            {
                "hf_subset": "ang-eng",
                "languages": [
                    "ang-Latn",
                    "eng-Latn"
                ],
                "accuracy": 35.82089552238806,
                "f1": 27.44136460554371,
                "precision": 24.340796019900495,
                "recall": 35.82089552238806,
                "main_score": 27.44136460554371
            },
            {
                "hf_subset": "ido-eng",
                "languages": [
                    "ido-Latn",
                    "eng-Latn"
                ],
                "accuracy": 51.800000000000004,
                "f1": 45.82491836793846,
                "precision": 43.729303094622864,
                "recall": 51.800000000000004,
                "main_score": 45.82491836793846
            },
            {
                "hf_subset": "jav-eng",
                "languages": [
                    "jav-Latn",
                    "eng-Latn"
                ],
                "accuracy": 25.853658536585368,
                "f1": 19.79869362796192,
                "precision": 18.250680214094846,
                "recall": 25.853658536585368,
                "main_score": 19.79869362796192
            },
            {
                "hf_subset": "isl-eng",
                "languages": [
                    "isl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.0,
                "f1": 6.926590762281661,
                "precision": 6.507185696775364,
                "recall": 9.0,
                "main_score": 6.926590762281661
            },
            {
                "hf_subset": "slv-eng",
                "languages": [
                    "slv-Latn",
                    "eng-Latn"
                ],
                "accuracy": 14.33778857837181,
                "f1": 10.888963524130242,
                "precision": 10.189272116928368,
                "recall": 14.33778857837181,
                "main_score": 10.888963524130242
            },
            {
                "hf_subset": "cym-eng",
                "languages": [
                    "cym-Latn",
                    "eng-Latn"
                ],
                "accuracy": 11.304347826086957,
                "f1": 8.459121175343064,
                "precision": 7.7218644669759975,
                "recall": 11.304347826086957,
                "main_score": 8.459121175343064
            },
            {
                "hf_subset": "kaz-eng",
                "languages": [
                    "kaz-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 8.521739130434783,
                "f1": 6.751744703151353,
                "precision": 6.387004921960017,
                "recall": 8.521739130434783,
                "main_score": 6.751744703151353
            },
            {
                "hf_subset": "est-eng",
                "languages": [
                    "est-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.3,
                "f1": 5.626766011766011,
                "precision": 5.1270385799923,
                "recall": 7.3,
                "main_score": 5.626766011766011
            },
            {
                "hf_subset": "heb-eng",
                "languages": [
                    "heb-Hebr",
                    "eng-Latn"
                ],
                "accuracy": 3.2,
                "f1": 1.91950282507703,
                "precision": 1.6684431360304504,
                "recall": 3.2,
                "main_score": 1.91950282507703
            },
            {
                "hf_subset": "gla-eng",
                "languages": [
                    "gla-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.790108564535585,
                "f1": 4.128499324411468,
                "precision": 3.8151453928788914,
                "recall": 5.790108564535585,
                "main_score": 4.128499324411468
            },
            {
                "hf_subset": "mar-eng",
                "languages": [
                    "mar-Deva",
                    "eng-Latn"
                ],
                "accuracy": 70.3,
                "f1": 65.18318181818181,
                "precision": 63.126911976911984,
                "recall": 70.3,
                "main_score": 65.18318181818181
            },
            {
                "hf_subset": "lat-eng",
                "languages": [
                    "lat-Latn",
                    "eng-Latn"
                ],
                "accuracy": 45.300000000000004,
                "f1": 38.339152873270514,
                "precision": 36.130903304212126,
                "recall": 45.300000000000004,
                "main_score": 38.339152873270514
            },
            {
                "hf_subset": "bel-eng",
                "languages": [
                    "bel-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 16.0,
                "f1": 12.172850459161385,
                "precision": 11.27855570316309,
                "recall": 16.0,
                "main_score": 12.172850459161385
            },
            {
                "hf_subset": "pms-eng",
                "languages": [
                    "pms-Latn",
                    "eng-Latn"
                ],
                "accuracy": 37.714285714285715,
                "f1": 32.188793178089945,
                "precision": 30.457500778089013,
                "recall": 37.714285714285715,
                "main_score": 32.188793178089945
            },
            {
                "hf_subset": "gle-eng",
                "languages": [
                    "gle-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.5,
                "f1": 4.528544131928126,
                "precision": 4.171387799947767,
                "recall": 6.5,
                "main_score": 4.528544131928126
            },
            {
                "hf_subset": "pes-eng",
                "languages": [
                    "pes-Arab",
                    "eng-Latn"
                ],
                "accuracy": 21.0,
                "f1": 17.006564035803166,
                "precision": 15.844832112332114,
                "recall": 21.0,
                "main_score": 17.006564035803166
            },
            {
                "hf_subset": "nob-eng",
                "languages": [
                    "nob-Latn",
                    "eng-Latn"
                ],
                "accuracy": 25.5,
                "f1": 22.79430820164996,
                "precision": 21.938476924594045,
                "recall": 25.5,
                "main_score": 22.79430820164996
            },
            {
                "hf_subset": "bul-eng",
                "languages": [
                    "bul-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 33.7,
                "f1": 26.898922166422164,
                "precision": 24.939117884031678,
                "recall": 33.7,
                "main_score": 26.898922166422164
            },
            {
                "hf_subset": "cbk-eng",
                "languages": [
                    "cbk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 69.0,
                "f1": 63.68992285492286,
                "precision": 61.72837301587302,
                "recall": 69.0,
                "main_score": 63.68992285492286
            },
            {
                "hf_subset": "hun-eng",
                "languages": [
                    "hun-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.3999999999999995,
                "f1": 5.5655686223658565,
                "precision": 5.119921502146487,
                "recall": 7.3999999999999995,
                "main_score": 5.5655686223658565
            },
            {
                "hf_subset": "uig-eng",
                "languages": [
                    "uig-Arab",
                    "eng-Latn"
                ],
                "accuracy": 1.5,
                "f1": 1.001208686507139,
                "precision": 0.9683730903243098,
                "recall": 1.5,
                "main_score": 1.001208686507139
            },
            {
                "hf_subset": "rus-eng",
                "languages": [
                    "rus-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 69.0,
                "f1": 62.61056277056276,
                "precision": 59.96357142857143,
                "recall": 69.0,
                "main_score": 62.61056277056276
            },
            {
                "hf_subset": "spa-eng",
                "languages": [
                    "spa-Latn",
                    "eng-Latn"
                ],
                "accuracy": 98.3,
                "f1": 97.76666666666668,
                "precision": 97.51666666666668,
                "recall": 98.3,
                "main_score": 97.76666666666668
            },
            {
                "hf_subset": "hye-eng",
                "languages": [
                    "hye-Armn",
                    "eng-Latn"
                ],
                "accuracy": 2.0215633423180592,
                "f1": 1.5634923413129036,
                "precision": 1.4895885785373653,
                "recall": 2.0215633423180592,
                "main_score": 1.5634923413129036
            },
            {
                "hf_subset": "tel-eng",
                "languages": [
                    "tel-Telu",
                    "eng-Latn"
                ],
                "accuracy": 83.33333333333334,
                "f1": 79.3019943019943,
                "precision": 77.45726495726495,
                "recall": 83.33333333333334,
                "main_score": 79.3019943019943
            },
            {
                "hf_subset": "afr-eng",
                "languages": [
                    "afr-Latn",
                    "eng-Latn"
                ],
                "accuracy": 23.400000000000002,
                "f1": 18.655079988631996,
                "precision": 17.338269096494905,
                "recall": 23.400000000000002,
                "main_score": 18.655079988631996
            },
            {
                "hf_subset": "mon-eng",
                "languages": [
                    "mon-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 6.363636363636363,
                "f1": 4.48376251469035,
                "precision": 4.071778641679957,
                "recall": 6.363636363636363,
                "main_score": 4.48376251469035
            },
            {
                "hf_subset": "arz-eng",
                "languages": [
                    "arz-Arab",
                    "eng-Latn"
                ],
                "accuracy": 77.56813417190776,
                "f1": 73.16561844863732,
                "precision": 71.3440484509667,
                "recall": 77.56813417190776,
                "main_score": 73.16561844863732
            },
            {
                "hf_subset": "hrv-eng",
                "languages": [
                    "hrv-Latn",
                    "eng-Latn"
                ],
                "accuracy": 17.299999999999997,
                "f1": 13.693204564375854,
                "precision": 12.830651358081276,
                "recall": 17.299999999999997,
                "main_score": 13.693204564375854
            },
            {
                "hf_subset": "nov-eng",
                "languages": [
                    "nov-Latn",
                    "eng-Latn"
                ],
                "accuracy": 59.92217898832685,
                "f1": 53.29591938541354,
                "precision": 50.58736335000926,
                "recall": 59.92217898832685,
                "main_score": 53.29591938541354
            },
            {
                "hf_subset": "gsw-eng",
                "languages": [
                    "gsw-Latn",
                    "eng-Latn"
                ],
                "accuracy": 25.64102564102564,
                "f1": 19.31404777558624,
                "precision": 17.413105413105416,
                "recall": 25.64102564102564,
                "main_score": 19.31404777558624
            },
            {
                "hf_subset": "nds-eng",
                "languages": [
                    "nds-Latn",
                    "eng-Latn"
                ],
                "accuracy": 29.7,
                "f1": 24.44977050316952,
                "precision": 22.798075396825396,
                "recall": 29.7,
                "main_score": 24.44977050316952
            },
            {
                "hf_subset": "ukr-eng",
                "languages": [
                    "ukr-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 32.2,
                "f1": 25.423187804627435,
                "precision": 23.404003309492442,
                "recall": 32.2,
                "main_score": 25.423187804627435
            },
            {
                "hf_subset": "uzb-eng",
                "languages": [
                    "uzb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.11214953271028,
                "f1": 5.910063827286792,
                "precision": 5.296401380795872,
                "recall": 9.11214953271028,
                "main_score": 5.910063827286792
            },
            {
                "hf_subset": "lit-eng",
                "languages": [
                    "lit-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.199999999999999,
                "f1": 5.816726797396153,
                "precision": 5.508698718788661,
                "recall": 7.199999999999999,
                "main_score": 5.816726797396153
            },
            {
                "hf_subset": "ina-eng",
                "languages": [
                    "ina-Latn",
                    "eng-Latn"
                ],
                "accuracy": 87.2,
                "f1": 83.88333333333333,
                "precision": 82.42833333333333,
                "recall": 87.2,
                "main_score": 83.88333333333333
            },
            {
                "hf_subset": "lfn-eng",
                "languages": [
                    "lfn-Latn",
                    "eng-Latn"
                ],
                "accuracy": 53.7,
                "f1": 48.25312435500516,
                "precision": 46.34107401656314,
                "recall": 53.7,
                "main_score": 48.25312435500516
            },
            {
                "hf_subset": "zsm-eng",
                "languages": [
                    "zsm-Latn",
                    "eng-Latn"
                ],
                "accuracy": 88.1,
                "f1": 85.21690476190476,
                "precision": 83.96761904761905,
                "recall": 88.1,
                "main_score": 85.21690476190476
            },
            {
                "hf_subset": "ita-eng",
                "languages": [
                    "ita-Latn",
                    "eng-Latn"
                ],
                "accuracy": 78.10000000000001,
                "f1": 73.38746031746032,
                "precision": 71.47583333333334,
                "recall": 78.10000000000001,
                "main_score": 73.38746031746032
            },
            {
                "hf_subset": "cmn-eng",
                "languages": [
                    "cmn-Hans",
                    "eng-Latn"
                ],
                "accuracy": 96.1,
                "f1": 95.08333333333333,
                "precision": 94.58333333333334,
                "recall": 96.1,
                "main_score": 95.08333333333333
            },
            {
                "hf_subset": "lvs-eng",
                "languages": [
                    "lvs-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.0,
                "f1": 6.952605595133894,
                "precision": 6.457724621713984,
                "recall": 9.0,
                "main_score": 6.952605595133894
            },
            {
                "hf_subset": "glg-eng",
                "languages": [
                    "glg-Latn",
                    "eng-Latn"
                ],
                "accuracy": 84.7,
                "f1": 80.97880952380953,
                "precision": 79.36428571428571,
                "recall": 84.7,
                "main_score": 80.97880952380953
            },
            {
                "hf_subset": "ceb-eng",
                "languages": [
                    "ceb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 10.5,
                "f1": 8.146458694813958,
                "precision": 7.618942433110826,
                "recall": 10.5,
                "main_score": 8.146458694813958
            },
            {
                "hf_subset": "bre-eng",
                "languages": [
                    "bre-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.4,
                "f1": 6.144921607886653,
                "precision": 5.5261043562899586,
                "recall": 8.4,
                "main_score": 6.144921607886653
            },
            {
                "hf_subset": "ben-eng",
                "languages": [
                    "ben-Beng",
                    "eng-Latn"
                ],
                "accuracy": 84.39999999999999,
                "f1": 80.65333333333334,
                "precision": 78.97833333333332,
                "recall": 84.39999999999999,
                "main_score": 80.65333333333334
            },
            {
                "hf_subset": "swg-eng",
                "languages": [
                    "swg-Latn",
                    "eng-Latn"
                ],
                "accuracy": 28.57142857142857,
                "f1": 22.767379679144387,
                "precision": 21.2016369047619,
                "recall": 28.57142857142857,
                "main_score": 22.767379679144387
            },
            {
                "hf_subset": "arq-eng",
                "languages": [
                    "arq-Arab",
                    "eng-Latn"
                ],
                "accuracy": 34.24807903402854,
                "f1": 29.241572730305222,
                "precision": 27.6428310072657,
                "recall": 34.24807903402854,
                "main_score": 29.241572730305222
            },
            {
                "hf_subset": "kab-eng",
                "languages": [
                    "kab-Latn",
                    "eng-Latn"
                ],
                "accuracy": 2.9000000000000004,
                "f1": 1.9156734696693711,
                "precision": 1.7528460881307182,
                "recall": 2.9000000000000004,
                "main_score": 1.9156734696693711
            },
            {
                "hf_subset": "fra-eng",
                "languages": [
                    "fra-Latn",
                    "eng-Latn"
                ],
                "accuracy": 94.89999999999999,
                "f1": 93.53333333333332,
                "precision": 92.90666666666667,
                "recall": 94.89999999999999,
                "main_score": 93.53333333333332
            },
            {
                "hf_subset": "por-eng",
                "languages": [
                    "por-Latn",
                    "eng-Latn"
                ],
                "accuracy": 95.0,
                "f1": 93.61666666666666,
                "precision": 92.93333333333332,
                "recall": 95.0,
                "main_score": 93.61666666666666
            },
            {
                "hf_subset": "tat-eng",
                "languages": [
                    "tat-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 6.3,
                "f1": 4.920070356472795,
                "precision": 4.565811270125224,
                "recall": 6.3,
                "main_score": 4.920070356472795
            },
            {
                "hf_subset": "oci-eng",
                "languages": [
                    "oci-Latn",
                    "eng-Latn"
                ],
                "accuracy": 47.4,
                "f1": 41.08392857142857,
                "precision": 38.999704968944094,
                "recall": 47.4,
                "main_score": 41.08392857142857
            },
            {
                "hf_subset": "pol-eng",
                "languages": [
                    "pol-Latn",
                    "eng-Latn"
                ],
                "accuracy": 18.2,
                "f1": 14.826165036734295,
                "precision": 13.988559330454489,
                "recall": 18.2,
                "main_score": 14.826165036734295
            },
            {
                "hf_subset": "war-eng",
                "languages": [
                    "war-Latn",
                    "eng-Latn"
                ],
                "accuracy": 13.3,
                "f1": 10.73451225789461,
                "precision": 10.06524508030025,
                "recall": 13.3,
                "main_score": 10.73451225789461
            },
            {
                "hf_subset": "aze-eng",
                "languages": [
                    "aze-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.3,
                "f1": 7.613044370901514,
                "precision": 7.184100384035204,
                "recall": 9.3,
                "main_score": 7.613044370901514
            },
            {
                "hf_subset": "vie-eng",
                "languages": [
                    "vie-Latn",
                    "eng-Latn"
                ],
                "accuracy": 97.0,
                "f1": 96.05,
                "precision": 95.58333333333334,
                "recall": 97.0,
                "main_score": 96.05
            },
            {
                "hf_subset": "nno-eng",
                "languages": [
                    "nno-Latn",
                    "eng-Latn"
                ],
                "accuracy": 19.8,
                "f1": 16.070523504273503,
                "precision": 14.848185626325227,
                "recall": 19.8,
                "main_score": 16.070523504273503
            },
            {
                "hf_subset": "cha-eng",
                "languages": [
                    "cha-Latn",
                    "eng-Latn"
                ],
                "accuracy": 29.1970802919708,
                "f1": 22.579707397225647,
                "precision": 20.792945550165477,
                "recall": 29.1970802919708,
                "main_score": 22.579707397225647
            },
            {
                "hf_subset": "mhr-eng",
                "languages": [
                    "mhr-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 4.3,
                "f1": 2.884495496452018,
                "precision": 2.6280916815877506,
                "recall": 4.3,
                "main_score": 2.884495496452018
            },
            {
                "hf_subset": "dan-eng",
                "languages": [
                    "dan-Latn",
                    "eng-Latn"
                ],
                "accuracy": 28.7,
                "f1": 24.9056519214062,
                "precision": 23.800155414494334,
                "recall": 28.7,
                "main_score": 24.9056519214062
            },
            {
                "hf_subset": "ell-eng",
                "languages": [
                    "ell-Grek",
                    "eng-Latn"
                ],
                "accuracy": 9.5,
                "f1": 6.723431537130878,
                "precision": 6.078266616597544,
                "recall": 9.5,
                "main_score": 6.723431537130878
            },
            {
                "hf_subset": "amh-eng",
                "languages": [
                    "amh-Ethi",
                    "eng-Latn"
                ],
                "accuracy": 1.7857142857142856,
                "f1": 0.4579590594653929,
                "precision": 0.32939943654229364,
                "recall": 1.7857142857142856,
                "main_score": 0.4579590594653929
            },
            {
                "hf_subset": "pam-eng",
                "languages": [
                    "pam-Latn",
                    "eng-Latn"
                ],
                "accuracy": 9.1,
                "f1": 7.1794182614770845,
                "precision": 6.81138018671376,
                "recall": 9.1,
                "main_score": 7.1794182614770845
            },
            {
                "hf_subset": "hsb-eng",
                "languages": [
                    "hsb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 15.113871635610765,
                "f1": 12.353104530336957,
                "precision": 11.66106754766342,
                "recall": 15.113871635610765,
                "main_score": 12.353104530336957
            },
            {
                "hf_subset": "srp-eng",
                "languages": [
                    "srp-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 18.4,
                "f1": 15.091645001025805,
                "precision": 14.200823959052217,
                "recall": 18.4,
                "main_score": 15.091645001025805
            },
            {
                "hf_subset": "epo-eng",
                "languages": [
                    "epo-Latn",
                    "eng-Latn"
                ],
                "accuracy": 33.2,
                "f1": 28.066634199134192,
                "precision": 26.54372717117398,
                "recall": 33.2,
                "main_score": 28.066634199134192
            },
            {
                "hf_subset": "kzj-eng",
                "languages": [
                    "kzj-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.6,
                "f1": 5.992580343865051,
                "precision": 5.7409125738839055,
                "recall": 7.6,
                "main_score": 5.992580343865051
            },
            {
                "hf_subset": "awa-eng",
                "languages": [
                    "awa-Deva",
                    "eng-Latn"
                ],
                "accuracy": 52.81385281385281,
                "f1": 46.86834810211434,
                "precision": 45.13687899402185,
                "recall": 52.81385281385281,
                "main_score": 46.86834810211434
            },
            {
                "hf_subset": "fao-eng",
                "languages": [
                    "fao-Latn",
                    "eng-Latn"
                ],
                "accuracy": 16.030534351145036,
                "f1": 12.902313597194603,
                "precision": 12.19757977391565,
                "recall": 16.030534351145036,
                "main_score": 12.902313597194603
            },
            {
                "hf_subset": "mal-eng",
                "languages": [
                    "mal-Mlym",
                    "eng-Latn"
                ],
                "accuracy": 94.75982532751091,
                "f1": 93.11984473556527,
                "precision": 92.3216885007278,
                "recall": 94.75982532751091,
                "main_score": 93.11984473556527
            },
            {
                "hf_subset": "ile-eng",
                "languages": [
                    "ile-Latn",
                    "eng-Latn"
                ],
                "accuracy": 70.19999999999999,
                "f1": 64.41237595737596,
                "precision": 62.074285714285715,
                "recall": 70.19999999999999,
                "main_score": 64.41237595737596
            },
            {
                "hf_subset": "bos-eng",
                "languages": [
                    "bos-Latn",
                    "eng-Latn"
                ],
                "accuracy": 19.2090395480226,
                "f1": 14.986259497894084,
                "precision": 14.08083152750014,
                "recall": 19.2090395480226,
                "main_score": 14.986259497894084
            },
            {
                "hf_subset": "cor-eng",
                "languages": [
                    "cor-Latn",
                    "eng-Latn"
                ],
                "accuracy": 5.800000000000001,
                "f1": 4.004811414639001,
                "precision": 3.611296721493974,
                "recall": 5.800000000000001,
                "main_score": 4.004811414639001
            },
            {
                "hf_subset": "cat-eng",
                "languages": [
                    "cat-Latn",
                    "eng-Latn"
                ],
                "accuracy": 93.10000000000001,
                "f1": 91.17333333333335,
                "precision": 90.27833333333334,
                "recall": 93.10000000000001,
                "main_score": 91.17333333333335
            },
            {
                "hf_subset": "eus-eng",
                "languages": [
                    "eus-Latn",
                    "eng-Latn"
                ],
                "accuracy": 68.2,
                "f1": 63.805870279146134,
                "precision": 62.064924029458915,
                "recall": 68.2,
                "main_score": 63.805870279146134
            },
            {
                "hf_subset": "yue-eng",
                "languages": [
                    "yue-Hant",
                    "eng-Latn"
                ],
                "accuracy": 88.9,
                "f1": 86.38250000000001,
                "precision": 85.345,
                "recall": 88.9,
                "main_score": 86.38250000000001
            },
            {
                "hf_subset": "swe-eng",
                "languages": [
                    "swe-Latn",
                    "eng-Latn"
                ],
                "accuracy": 26.3,
                "f1": 21.72601907540825,
                "precision": 20.3161132602622,
                "recall": 26.3,
                "main_score": 21.72601907540825
            },
            {
                "hf_subset": "dtp-eng",
                "languages": [
                    "dtp-Latn",
                    "eng-Latn"
                ],
                "accuracy": 6.6000000000000005,
                "f1": 5.4107919446503585,
                "precision": 5.143205186348676,
                "recall": 6.6000000000000005,
                "main_score": 5.4107919446503585
            },
            {
                "hf_subset": "kat-eng",
                "languages": [
                    "kat-Geor",
                    "eng-Latn"
                ],
                "accuracy": 1.2064343163538873,
                "f1": 0.7118331023204635,
                "precision": 0.6930197065411955,
                "recall": 1.2064343163538873,
                "main_score": 0.7118331023204635
            },
            {
                "hf_subset": "jpn-eng",
                "languages": [
                    "jpn-Jpan",
                    "eng-Latn"
                ],
                "accuracy": 78.0,
                "f1": 73.95134920634919,
                "precision": 72.3770634920635,
                "recall": 78.0,
                "main_score": 73.95134920634919
            },
            {
                "hf_subset": "csb-eng",
                "languages": [
                    "csb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 12.648221343873518,
                "f1": 10.259994816302727,
                "precision": 9.677206851119895,
                "recall": 12.648221343873518,
                "main_score": 10.259994816302727
            },
            {
                "hf_subset": "xho-eng",
                "languages": [
                    "xho-Latn",
                    "eng-Latn"
                ],
                "accuracy": 10.56338028169014,
                "f1": 7.792644757433489,
                "precision": 7.299087316692951,
                "recall": 10.56338028169014,
                "main_score": 7.792644757433489
            },
            {
                "hf_subset": "orv-eng",
                "languages": [
                    "orv-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 8.1437125748503,
                "f1": 5.6113303405098724,
                "precision": 5.156075980223929,
                "recall": 8.1437125748503,
                "main_score": 5.6113303405098724
            },
            {
                "hf_subset": "ind-eng",
                "languages": [
                    "ind-Latn",
                    "eng-Latn"
                ],
                "accuracy": 92.5,
                "f1": 90.53999999999999,
                "precision": 89.64500000000001,
                "recall": 92.5,
                "main_score": 90.53999999999999
            },
            {
                "hf_subset": "tuk-eng",
                "languages": [
                    "tuk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 8.374384236453201,
                "f1": 5.831645092728836,
                "precision": 5.241568776051535,
                "recall": 8.374384236453201,
                "main_score": 5.831645092728836
            },
            {
                "hf_subset": "max-eng",
                "languages": [
                    "max-Deva",
                    "eng-Latn"
                ],
                "accuracy": 45.42253521126761,
                "f1": 40.878561970111264,
                "precision": 39.52681669728516,
                "recall": 45.42253521126761,
                "main_score": 40.878561970111264
            },
            {
                "hf_subset": "swh-eng",
                "languages": [
                    "swh-Latn",
                    "eng-Latn"
                ],
                "accuracy": 32.05128205128205,
                "f1": 25.433010420698523,
                "precision": 23.545685308843208,
                "recall": 32.05128205128205,
                "main_score": 25.433010420698523
            },
            {
                "hf_subset": "hin-eng",
                "languages": [
                    "hin-Deva",
                    "eng-Latn"
                ],
                "accuracy": 94.6,
                "f1": 92.86666666666666,
                "precision": 92.01666666666667,
                "recall": 94.6,
                "main_score": 92.86666666666666
            },
            {
                "hf_subset": "dsb-eng",
                "languages": [
                    "dsb-Latn",
                    "eng-Latn"
                ],
                "accuracy": 14.822546972860126,
                "f1": 12.439321820122155,
                "precision": 11.940341857811413,
                "recall": 14.822546972860126,
                "main_score": 12.439321820122155
            },
            {
                "hf_subset": "ber-eng",
                "languages": [
                    "ber-Tfng",
                    "eng-Latn"
                ],
                "accuracy": 6.7,
                "f1": 5.534443298607457,
                "precision": 5.299107273391812,
                "recall": 6.7,
                "main_score": 5.534443298607457
            },
            {
                "hf_subset": "tam-eng",
                "languages": [
                    "tam-Taml",
                    "eng-Latn"
                ],
                "accuracy": 87.94788273615634,
                "f1": 84.65798045602605,
                "precision": 83.2084690553746,
                "recall": 87.94788273615634,
                "main_score": 84.65798045602605
            },
            {
                "hf_subset": "slk-eng",
                "languages": [
                    "slk-Latn",
                    "eng-Latn"
                ],
                "accuracy": 13.8,
                "f1": 11.356912127897372,
                "precision": 10.778191051205624,
                "recall": 13.8,
                "main_score": 11.356912127897372
            },
            {
                "hf_subset": "tgl-eng",
                "languages": [
                    "tgl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 13.700000000000001,
                "f1": 10.74774895608627,
                "precision": 9.966243757837463,
                "recall": 13.700000000000001,
                "main_score": 10.74774895608627
            },
            {
                "hf_subset": "ast-eng",
                "languages": [
                    "ast-Latn",
                    "eng-Latn"
                ],
                "accuracy": 76.37795275590551,
                "f1": 71.24671916010499,
                "precision": 69.20697412823397,
                "recall": 76.37795275590551,
                "main_score": 71.24671916010499
            },
            {
                "hf_subset": "mkd-eng",
                "languages": [
                    "mkd-Cyrl",
                    "eng-Latn"
                ],
                "accuracy": 18.099999999999998,
                "f1": 13.934122253809159,
                "precision": 12.815974391105971,
                "recall": 18.099999999999998,
                "main_score": 13.934122253809159
            },
            {
                "hf_subset": "khm-eng",
                "languages": [
                    "khm-Khmr",
                    "eng-Latn"
                ],
                "accuracy": 0.6925207756232686,
                "f1": 0.08966600365830146,
                "precision": 0.05066184676394412,
                "recall": 0.6925207756232686,
                "main_score": 0.08966600365830146
            },
            {
                "hf_subset": "ces-eng",
                "languages": [
                    "ces-Latn",
                    "eng-Latn"
                ],
                "accuracy": 11.1,
                "f1": 8.28646043238052,
                "precision": 7.686198801198802,
                "recall": 11.1,
                "main_score": 8.28646043238052
            },
            {
                "hf_subset": "tzl-eng",
                "languages": [
                    "tzl-Latn",
                    "eng-Latn"
                ],
                "accuracy": 38.46153846153847,
                "f1": 31.640899949723472,
                "precision": 29.298878205128204,
                "recall": 38.46153846153847,
                "main_score": 31.640899949723472
            },
            {
                "hf_subset": "urd-eng",
                "languages": [
                    "urd-Arab",
                    "eng-Latn"
                ],
                "accuracy": 81.2,
                "f1": 76.77103174603175,
                "precision": 74.96511904761905,
                "recall": 81.2,
                "main_score": 76.77103174603175
            },
            {
                "hf_subset": "ara-eng",
                "languages": [
                    "ara-Arab",
                    "eng-Latn"
                ],
                "accuracy": 90.60000000000001,
                "f1": 88.20666666666665,
                "precision": 87.14833333333334,
                "recall": 90.60000000000001,
                "main_score": 88.20666666666665
            },
            {
                "hf_subset": "kor-eng",
                "languages": [
                    "kor-Hang",
                    "eng-Latn"
                ],
                "accuracy": 35.699999999999996,
                "f1": 29.159127620745267,
                "precision": 27.109529030910608,
                "recall": 35.699999999999996,
                "main_score": 29.159127620745267
            },
            {
                "hf_subset": "yid-eng",
                "languages": [
                    "yid-Hebr",
                    "eng-Latn"
                ],
                "accuracy": 0.9433962264150944,
                "f1": 0.28088681664921333,
                "precision": 0.22694150916099465,
                "recall": 0.9433962264150944,
                "main_score": 0.28088681664921333
            },
            {
                "hf_subset": "fin-eng",
                "languages": [
                    "fin-Latn",
                    "eng-Latn"
                ],
                "accuracy": 7.5,
                "f1": 5.825362182391272,
                "precision": 5.526187577939453,
                "recall": 7.5,
                "main_score": 5.825362182391272
            },
            {
                "hf_subset": "tha-eng",
                "languages": [
                    "tha-Thai",
                    "eng-Latn"
                ],
                "accuracy": 4.197080291970803,
                "f1": 3.079215618580677,
                "precision": 2.8501768792419,
                "recall": 4.197080291970803,
                "main_score": 3.079215618580677
            },
            {
                "hf_subset": "wuu-eng",
                "languages": [
                    "wuu-Hans",
                    "eng-Latn"
                ],
                "accuracy": 87.9,
                "f1": 84.60499999999999,
                "precision": 83.11428571428571,
                "recall": 87.9,
                "main_score": 84.60499999999999
            }
        ]
    }
}