{
    "dataset_revision": "90fceea13679c63fe563ded68f3b6f06e50061de",
    "task_name": "CQADupstackMathematicaRetrieval",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "map_at_1": 15.909999999999998,
                "map_at_10": 23.901,
                "map_at_100": 25.165,
                "map_at_1000": 25.291000000000004,
                "map_at_3": 21.356,
                "map_at_5": 22.816,
                "mrr_at_1": 20.025000000000002,
                "mrr_at_10": 28.382,
                "mrr_at_100": 29.465000000000003,
                "mrr_at_1000": 29.535,
                "mrr_at_3": 25.933,
                "mrr_at_5": 27.332,
                "ndcg_at_1": 20.025000000000002,
                "ndcg_at_10": 29.099000000000004,
                "ndcg_at_100": 35.127,
                "ndcg_at_1000": 38.096000000000004,
                "ndcg_at_3": 24.464,
                "ndcg_at_5": 26.709,
                "precision_at_1": 20.025000000000002,
                "precision_at_10": 5.398,
                "precision_at_100": 0.9690000000000001,
                "precision_at_1000": 0.13699999999999998,
                "precision_at_3": 11.774,
                "precision_at_5": 8.632,
                "recall_at_1": 15.909999999999998,
                "recall_at_10": 40.672000000000004,
                "recall_at_100": 66.855,
                "recall_at_1000": 87.922,
                "recall_at_3": 28.069,
                "recall_at_5": 33.812,
                "main_score": 29.099000000000004
            }
        ]
    }
}